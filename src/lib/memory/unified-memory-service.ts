'use client'

/**
 * Unified Memory Service
 * Combines all existing memory systems into a single comprehensive service
 * Features: Supabase persistence, semantic search, real-time updates, learning integration
 */

import { EventEmitter } from 'events'
import { supabase } from '@/lib/supabase/client'
import type { Database } from '@/types/database.types'
import { getWebSocketClient } from '@/lib/realtime/websocket'
import { getSemanticSearchService } from '@/lib/memory/semantic-search-service'
import { getPatternRecognitionService } from '@/lib/memory/pattern-recognition-service'

// Core memory interfaces
export interface UnifiedMemory {
  id: string
  agentId: string
  content: string
  memoryType: 'trade_decision' | 'market_insight' | 'strategy_learning' | 'risk_observation' | 'pattern_recognition' | 'performance_feedback'
  category: 'general' | 'success' | 'failure' | 'adaptation' | 'optimization' | 'warning'
  importanceScore: number
  relevanceDecay: number
  accessCount: number
  lastAccessedAt?: Date
  context: any
  tags: string[]
  relatedSymbols: string[]
  marketConditions: any
  tradeOutcome?: any
  strategyUsed?: string
  timeframe?: string
  confidenceLevel?: number
  embedding?: number[]
  embeddingModel?: string
  parentMemoryId?: string
  clusterId?: string
  similarityThreshold: number
  createdAt: Date
  updatedAt: Date
  expiresAt?: Date
  archivedAt?: Date
}

export interface MemoryCluster {
  id: string
  agentId: string
  clusterName: string
  clusterType: 'pattern' | 'strategy' | 'outcome' | 'temporal' | 'market_condition'
  description: string
  memoryCount: number
  avgImportance: number
  successRate?: number
  avgPnl?: number
  commonPatterns: any
  insights: any
  recommendations: string[]
  clusterEmbedding?: number[]
  isActive: boolean
  autoGenerated: boolean
  lastAnalyzedAt?: Date
  createdAt: Date
  updatedAt: Date
}

export interface MemoryInsight {
  id: string
  agentId: string
  insightType: 'pattern' | 'correlation' | 'optimization' | 'warning' | 'opportunity' | 'anomaly'
  insightCategory: 'trading' | 'risk' | 'strategy' | 'market' | 'performance' | 'adaptation'
  title: string
  description: string
  confidenceScore: number
  impactScore: number
  urgencyScore: number
  actionabilityScore: number
  supportingMemories: string[]
  evidenceData: any
  recommendations: string[]
  suggestedActions: any
  riskConsiderations: string[]
  isActionable: boolean
  actionTaken: boolean
  actionDetails?: any
  outcomeTracked: boolean
  generatedBy: string
  priorityLevel: 'low' | 'medium' | 'high' | 'critical'
  createdAt: Date
  updatedAt: Date
  expiresAt?: Date
}

export interface MemoryPerformanceData {
  memoryId: string
  tradeId?: string
  strategyExecutionId?: string
  decisionTimestamp: Date
  influenceScore: number
  influenceType: 'positive' | 'negative' | 'neutral' | 'preventive' | 'confirmatory'
  decisionType: 'entry' | 'exit' | 'hold' | 'size_adjustment' | 'risk_adjustment'
  marketContext: any
  pnlImpact?: number
  accuracyScore?: number
  timingScore?: number
  riskScore?: number
}

export interface MemoryCheckpoint {
  id: string
  agentId: string
  checkpointName: string
  checkpointType: 'manual' | 'automatic' | 'pre_trade' | 'post_trade' | 'error_recovery' | 'optimization'
  agentState: any
  memorySnapshot: any
  strategyParameters: any
  riskParameters: any
  performanceMetrics: any
  learningProgress: any
  adaptationHistory: any
  totalMemories: number
  memoryDistribution: any
  avgMemoryImportance: number
  isValid: boolean
  canRestore: boolean
  createdAt: Date
}

// Search and filtering options
export interface MemorySearchOptions {
  query?: string
  memoryTypes?: string[]
  symbols?: string[]
  strategies?: string[]
  importanceMin?: number
  importanceMax?: number
  dateFrom?: Date
  dateTo?: Date
  categories?: string[]
  tags?: string[]
  limit?: number
  offset?: number
  sortBy?: 'importance' | 'recency' | 'relevance' | 'access_count'
  includeArchived?: boolean
  semanticSearch?: boolean
}

export interface LearningMetrics {
  totalMemories: number
  avgImportance: number
  memoryTypes: Record<string, number>
  successRate: number
  adaptationScore: number
  learningProgress: number
  recentActivity: number
  clusterCount: number
  insightCount: number
  checkpointCount: number
}

class UnifiedMemoryService extends EventEmitter {
  private supabase = createClient()
  private embeddingCache = new Map<string, number[]>()
  private clusterCache = new Map<string, MemoryCluster[]>()
  
  constructor() {
    super()
    this.initializeService()
  }

  private async initializeService() {
    // Set up real-time subscriptions
    this.setupRealtimeSubscriptions()
    
    // Initialize embedding service (mock for now)
    console.log('Unified Memory Service initialized')
  }

  private setupRealtimeSubscriptions() {
    // Subscribe to memory changes
    this.supabase
      .channel('memory-changes')
      .on('postgres_changes', {
        event: '*',
        schema: 'public',
        table: 'agent_memories'
      }, (payload) => {
        this.emit('memoryChanged', payload)
      })
      .on('postgres_changes', {
        event: '*',
        schema: 'public',
        table: 'memory_insights'
      }, (payload) => {
        this.emit('insightChanged', payload)
      })
      .subscribe()
  }

  // ============================================
  // CORE MEMORY OPERATIONS
  // ============================================

  async storeMemory(
    agentId: string,
    content: string,
    memoryType: UnifiedMemory['memoryType'],
    context: any = {},
    options: {
      importance?: number
      category?: UnifiedMemory['category']
      symbols?: string[]
      strategy?: string
      tradeOutcome?: any
      tags?: string[]
      generateEmbedding?: boolean
    } = {}
  ): Promise<string> {
    try {
      const memoryData = {
        agent_id: agentId,
        content,
        memory_type: memoryType,
        category: options.category || 'general',
        importance_score: options.importance || this.calculateImportance(content, memoryType, context),
        context,
        related_symbols: options.symbols || [],
        strategy_used: options.strategy,
        trade_outcome: options.tradeOutcome,
        tags: options.tags || [],
        confidence_level: context.confidence || 0.5,
        market_conditions: context.marketConditions || {}
      }

      // Generate embedding if requested or for important memories
      if (options.generateEmbedding || memoryData.importance_score > 0.6) {
        try {
          const semanticService = getSemanticSearchService()
          const embedding = await semanticService.generateEmbedding(content)
          // @ts-expect-error - embedding field may not exist in type
          memoryData.embedding = JSON.stringify(embedding)
          // @ts-expect-error - embedding_model field may not exist in type  
          memoryData.embedding_model = semanticService.getProviderInfo().modelName
        } catch (error) {
          console.warn('Failed to generate embedding:', error)
        }
      }

      const { data, error } = await this.supabase
        .from('agent_memories')
        .insert(memoryData)
        .select()
        .single()

      if (error) throw error

      const memoryId = data.id

      // Auto-cluster if we have enough memories
      this.autoClusterMemories(agentId)

      // Generate insights if this is a significant memory
      if (memoryData.importance_score > 0.7) {
        this.generateInsightsFromMemory(agentId, memoryId)
      }

      // Emit local event
      this.emit('memoryStored', { agentId, memoryId, memoryType })
      
      // Broadcast WebSocket update
      try {
        const wsClient = getWebSocketClient()
        if (wsClient.connected) {
          wsClient.emit('memory_update', {
            agentId,
            memoryId,
            memoryType,
            content,
            importanceScore: memoryData.importance_score,
            action: 'stored',
            timestamp: Date.now()
          })
        }
      } catch (error) {
        console.warn('Failed to send WebSocket memory update:', error)
      }
      
      return memoryId

    } catch (error) {
      console.error('Error storing memory:', error)
      throw error
    }
  }

  async retrieveMemories(
    agentId: string,
    options: MemorySearchOptions = {}
  ): Promise<UnifiedMemory[]> {
    try {
      let query = this.supabase
        .from('agent_memories')
        .select('*')
        .eq('agent_id', agentId)

      // Apply filters
      if (!options.includeArchived) {
        query = query.is('archived_at', null)
      }

      if (options.memoryTypes?.length) {
        query = query.in('memory_type', options.memoryTypes)
      }

      if (options.categories?.length) {
        query = query.in('category', options.categories)
      }

      if (options.symbols?.length) {
        query = query.overlaps('related_symbols', options.symbols)
      }

      if (options.importanceMin !== undefined) {
        query = query.gte('importance_score', options.importanceMin)
      }

      if (options.importanceMax !== undefined) {
        query = query.lte('importance_score', options.importanceMax)
      }

      if (options.dateFrom) {
        query = query.gte('created_at', options.dateFrom.toISOString())
      }

      if (options.dateTo) {
        query = query.lte('created_at', options.dateTo.toISOString())
      }

      // Text search
      if (options.query) {
        query = query.textSearch('content', options.query)
      }

      // Sorting
      switch (options.sortBy) {
        case 'importance':
          query = query.order('importance_score', { ascending: false })
          break
        case 'recency':
          query = query.order('created_at', { ascending: false })
          break
        case 'access_count':
          query = query.order('access_count', { ascending: false })
          break
        default:
          query = query.order('importance_score', { ascending: false })
          break
      }

      // Pagination
      if (options.limit) {
        query = query.limit(options.limit)
      }
      if (options.offset) {
        query = query.range(options.offset, (options.offset + (options.limit || 50)) - 1)
      }

      const { data, error } = await query

      if (error) throw error

      // Update access counts for retrieved memories
      if (data?.length) {
        const memoryIds = data.map(m => m.id)
        await this.updateAccessCounts(memoryIds)
      }

      return this.transformMemoryData(data || [])

    } catch (error) {
      console.error('Error retrieving memories:', error)
      return []
    }
  }

  async semanticSearch(
    agentId: string,
    query: string,
    limit: number = 10,
    threshold: number = 0.7
  ): Promise<UnifiedMemory[]> {
    try {
      const semanticService = getSemanticSearchService()
      
      // Get all memories for the agent (with reasonable limit for performance)
      const allMemories = await this.retrieveMemories(agentId, { 
        limit: 1000,
        includeArchived: false
      })

      if (allMemories.length === 0) {
        return []
      }

      // Perform semantic search
      const searchResults = await semanticService.searchMemories(query, allMemories, {
        threshold,
        limit,
        agentId,
        includeArchived: false
      })

      // Convert search results back to UnifiedMemory format
      const rankedMemories = searchResults.map(result => ({
        ...result.memory,
        relevanceScore: result.relevanceScore,
        similarity: result.similarity
      }))

      // Update access counts for retrieved memories
      if (rankedMemories.length > 0) {
        const memoryIds = rankedMemories.map(m => m.id)
        await this.updateAccessCounts(memoryIds)
      }

      // Emit search event for analytics
      this.emit('semanticSearchPerformed', { 
        agentId, 
        query, 
        resultsCount: rankedMemories.length,
        avgRelevance: rankedMemories.reduce((sum, m) => sum + (m.relevanceScore || 0), 0) / rankedMemories.length
      })

      return rankedMemories

    } catch (error) {
      console.error('Error in semantic search:', error)
      
      // Fallback to text search if semantic search fails
      return this.retrieveMemories(agentId, { query, limit })
    }
  }

  async updateMemory(
    memoryId: string,
    updates: Partial<UnifiedMemory>
  ): Promise<boolean> {
    try {
      const { error } = await this.supabase
        .from('agent_memories')
        .update({
          content: updates.content,
          importance_score: updates.importanceScore,
          context: updates.context,
          tags: updates.tags,
          related_symbols: updates.relatedSymbols,
          updated_at: new Date().toISOString()
        })
        .eq('id', memoryId)

      if (error) throw error

      this.emit('memoryUpdated', { memoryId, updates })
      return true

    } catch (error) {
      console.error('Error updating memory:', error)
      return false
    }
  }

  async deleteMemory(memoryId: string): Promise<boolean> {
    try {
      const { error } = await this.supabase
        .from('agent_memories')
        .delete()
        .eq('id', memoryId)

      if (error) throw error

      this.emit('memoryDeleted', { memoryId })
      return true

    } catch (error) {
      console.error('Error deleting memory:', error)
      return false
    }
  }

  async archiveMemory(memoryId: string): Promise<boolean> {
    try {
      const { error } = await this.supabase
        .from('agent_memories')
        .update({ archived_at: new Date().toISOString() })
        .eq('id', memoryId)

      if (error) throw error

      this.emit('memoryArchived', { memoryId })
      return true

    } catch (error) {
      console.error('Error archiving memory:', error)
      return false
    }
  }

  // ============================================
  // MEMORY CLUSTERING
  // ============================================

  async getMemoryClusters(agentId: string): Promise<MemoryCluster[]> {
    try {
      const cached = this.clusterCache.get(agentId)
      if (cached) return cached

      const { data, error } = await this.supabase
        .from('memory_clusters')
        .select('*')
        .eq('agent_id', agentId)
        .eq('is_active', true)
        .order('memory_count', { ascending: false })

      if (error) throw error

      const clusters = this.transformClusterData(data || [])
      this.clusterCache.set(agentId, clusters)
      
      return clusters

    } catch (error) {
      console.error('Error getting memory clusters:', error)
      return []
    }
  }

  async createCluster(
    agentId: string,
    name: string,
    type: MemoryCluster['clusterType'],
    memoryIds: string[],
    description?: string
  ): Promise<string | null> {
    try {
      const { data, error } = await this.supabase
        .from('memory_clusters')
        .insert({
          agent_id: agentId,
          cluster_name: name,
          cluster_type: type,
          description: description || `Auto-generated ${type} cluster`,
          memory_count: memoryIds.length,
          auto_generated: false
        })
        .select()
        .single()

      if (error) throw error

      const clusterId = data.id

      // Update memories to assign to cluster
      await this.supabase
        .from('agent_memories')
        .update({ cluster_id: clusterId })
        .in('id', memoryIds)

      // Clear cluster cache
      this.clusterCache.delete(agentId)

      this.emit('clusterCreated', { agentId, clusterId, memoryIds })
      return clusterId

    } catch (error) {
      console.error('Error creating cluster:', error)
      return null
    }
  }

  private async autoClusterMemories(agentId: string) {
    try {
      // Get recent unclustered memories
      const memories = await this.retrieveMemories(agentId, {
        limit: 100,
        sortBy: 'recency'
      })

      const unclustered = memories.filter(m => !m.clusterId)
      
      if (unclustered.length < 5) return // Need minimum memories for clustering

      const semanticService = getSemanticSearchService()

      // Perform semantic clustering
      try {
        const clusters = await semanticService.clusterMemories(unclustered, 5, 0.75)
        
        for (let i = 0; i < clusters.length; i++) {
          const cluster = clusters[i]
          if (cluster.memories.length >= 3) {
            // Determine cluster type based on memory types
            const memoryTypes = cluster.memories.map(m => m.memoryType)
            const dominantType = this.getMostFrequent(memoryTypes)
            const clusterType = this.mapMemoryTypeToClusterType(dominantType)
            
            // Generate cluster name based on content
            const clusterName = await this.generateClusterName(cluster.memories)
            
            await this.createCluster(
              agentId,
              clusterName,
              clusterType,
              cluster.memories.map(m => m.id),
              `Semantic cluster with ${(cluster.coherence * 100).toFixed(1)}% coherence`
            )
          }
        }
      } catch (semanticError) {
        console.warn('Semantic clustering failed, falling back to simple clustering:', semanticError)
        
        // Fallback to simple clustering by strategy and outcome
        const strategyGroups = this.groupMemoriesByStrategy(unclustered)
        
        for (const [strategy, group] of Object.entries(strategyGroups)) {
          if (group.length >= 3) {
            await this.createCluster(
              agentId,
              `${strategy} Pattern`,
              'strategy',
              group.map(m => m.id),
              `Auto-generated cluster for ${strategy} strategy memories`
            )
          }
        }
      }

    } catch (error) {
      console.error('Error in auto-clustering:', error)
    }
  }

  // ============================================
  // MEMORY INSIGHTS
  // ============================================

  async getMemoryInsights(agentId: string): Promise<MemoryInsight[]> {
    try {
      const { data, error } = await this.supabase
        .from('memory_insights')
        .select('*')
        .eq('agent_id', agentId)
        .eq('is_actionable', true)
        .order('confidence_score', { ascending: false })

      if (error) throw error

      return this.transformInsightData(data || [])

    } catch (error) {
      console.error('Error getting memory insights:', error)
      return []
    }
  }

  private async generateInsightsFromMemory(agentId: string, memoryId: string) {
    try {
      // Analyze patterns in recent memories
      const recentMemories = await this.retrieveMemories(agentId, {
        limit: 100,
        sortBy: 'recency'
      })

      // Use both simple pattern analysis and advanced pattern recognition
      const simpleInsights = this.analyzeMemoryPatterns(recentMemories)
      
      // Advanced pattern recognition
      const patternService = getPatternRecognitionService()
      const detectedPatterns = await patternService.analyzeMemoryPatterns(agentId, recentMemories, {
        minConfidence: 0.6,
        maxAge: 30,
        includeHistorical: true
      })
      
      const patternInsights = await patternService.generatePatternInsights(detectedPatterns)
      
      // Store simple insights
      for (const insight of simpleInsights) {
        await this.supabase
          .from('memory_insights')
          .insert({
            agent_id: agentId,
            insight_type: insight.type,
            insight_category: insight.category,
            title: insight.title,
            description: insight.description,
            confidence_score: insight.confidence,
            impact_score: insight.impact,
            recommendations: insight.recommendations,
            supporting_memories: [memoryId],
            generated_by: 'system'
          })
      }
      
      // Store pattern recognition insights
      for (const insight of patternInsights.slice(0, 5)) { // Limit to top 5 insights
        await this.supabase
          .from('memory_insights')
          .insert({
            agent_id: agentId,
            insight_type: insight.type,
            insight_category: 'pattern_analysis',
            title: insight.title,
            description: insight.description,
            confidence_score: insight.confidence,
            impact_score: Math.abs(insight.expectedImpact) / 100, // Normalize to 0-1
            recommendations: insight.recommendations,
            supporting_memories: [memoryId],
            generated_by: 'pattern_recognition',
            urgency_level: insight.urgency,
            is_actionable: insight.actionable
          })
      }

      // Emit pattern detection event for real-time updates
      if (detectedPatterns.length > 0) {
        this.emit('patternsDetected', { 
          agentId, 
          patterns: detectedPatterns,
          insights: patternInsights
        })
        
        // Broadcast via WebSocket
        try {
          const wsClient = getWebSocketClient()
          if (wsClient.connected) {
            wsClient.emit('memory_insight', {
              agentId,
              insightType: 'pattern_discovered',
              description: `${detectedPatterns.length} new patterns detected`,
              confidence: Math.max(...detectedPatterns.map(p => p.confidence)),
              memoryIds: [memoryId],
              impact: {
                performanceChange: patternInsights.reduce((sum, i) => sum + i.expectedImpact, 0) / patternInsights.length / 100,
                confidenceChange: 0.1
              },
              timestamp: Date.now()
            })
          }
        } catch (error) {
          console.warn('Failed to send WebSocket pattern insight:', error)
        }
      }

    } catch (error) {
      console.error('Error generating insights:', error)
    }
  }

  // ============================================
  // MEMORY CHECKPOINTS
  // ============================================

  async createCheckpoint(
    agentId: string,
    name: string,
    type: MemoryCheckpoint['checkpointType'],
    agentState: any,
    options: {
      triggerEvent?: string
      strategyParameters?: any
      riskParameters?: any
      performanceMetrics?: any
    } = {}
  ): Promise<string | null> {
    try {
      // Get current memory snapshot
      const memories = await this.retrieveMemories(agentId, { includeArchived: true })
      const memorySnapshot = {
        totalMemories: memories.length,
        memoryTypes: this.getMemoryTypeDistribution(memories),
        avgImportance: memories.reduce((sum, m) => sum + m.importanceScore, 0) / memories.length,
        clusters: await this.getMemoryClusters(agentId)
      }

      const { data, error } = await this.supabase
        .from('enhanced_memory_checkpoints')
        .insert({
          agent_id: agentId,
          checkpoint_name: name,
          checkpoint_type: type,
          trigger_event: options.triggerEvent,
          agent_state: agentState,
          memory_snapshot: memorySnapshot,
          strategy_parameters: options.strategyParameters || {},
          risk_parameters: options.riskParameters || {},
          performance_metrics: options.performanceMetrics || {},
          total_memories: memories.length,
          avg_memory_importance: memorySnapshot.avgImportance
        })
        .select()
        .single()

      if (error) throw error

      this.emit('checkpointCreated', { agentId, checkpointId: data.id })
      return data.id

    } catch (error) {
      console.error('Error creating checkpoint:', error)
      return null
    }
  }

  async restoreCheckpoint(checkpointId: string): Promise<boolean> {
    try {
      const { data, error } = await this.supabase
        .from('enhanced_memory_checkpoints')
        .select('*')
        .eq('id', checkpointId)
        .eq('can_restore', true)
        .single()

      if (error) throw error
      if (!data) return false

      // Update restore count
      await this.supabase
        .from('enhanced_memory_checkpoints')
        .update({ 
          restore_count: (data.restore_count || 0) + 1,
          last_restored_at: new Date().toISOString()
        })
        .eq('id', checkpointId)

      this.emit('checkpointRestored', { 
        agentId: data.agent_id, 
        checkpointId,
        agentState: data.agent_state
      })

      return true

    } catch (error) {
      console.error('Error restoring checkpoint:', error)
      return false
    }
  }

  // ============================================
  // LEARNING INTEGRATION
  // ============================================

  async recordTradeOutcome(
    agentId: string,
    memoryId: string,
    outcome: {
      tradeId?: string
      strategyExecutionId?: string
      pnl: number
      success: boolean
      executionTime: number
      slippage: number
      marketImpact: number
    }
  ): Promise<void> {
    try {
      // Update the original memory with outcome
      await this.supabase
        .from('agent_memories')
        .update({
          trade_outcome: JSON.stringify(outcome),
          updated_at: new Date().toISOString()
        })
        .eq('id', memoryId)

      // Record performance tracking
      await this.supabase
        .from('memory_performance_tracking')
        .insert({
          agent_id: agentId,
          memory_id: memoryId,
          trade_id: outcome.tradeId,
          strategy_execution_id: outcome.strategyExecutionId,
          decision_timestamp: new Date().toISOString(),
          influence_score: 0.8, // Would be calculated based on memory importance
          influence_type: outcome.success ? 'positive' : 'negative',
          decision_type: 'entry', // Would be determined from context
          pnl_impact: outcome.pnl,
          accuracy_score: outcome.success ? 1.0 : 0.0
        })

      // Create learning memory from outcome
      const learningContent = outcome.success
        ? `Successful trade outcome: ${outcome.pnl > 0 ? 'profit' : 'loss'} of $${Math.abs(outcome.pnl).toFixed(2)} with ${outcome.executionTime}ms execution`
        : `Failed trade outcome: Loss of $${Math.abs(outcome.pnl).toFixed(2)} with high slippage (${(outcome.slippage * 100).toFixed(2)}%)`

      await this.storeMemory(
        agentId,
        learningContent,
        'performance_feedback',
        {
          originalMemoryId: memoryId,
          tradeOutcome: outcome,
          learningType: outcome.success ? 'reinforcement' : 'correction'
        },
        {
          importance: outcome.success ? 0.7 : 0.9, // Failures are more important to remember
          category: outcome.success ? 'success' : 'failure'
        }
      )

      this.emit('tradeOutcomeRecorded', { agentId, memoryId, outcome })

    } catch (error) {
      console.error('Error recording trade outcome:', error)
    }
  }

  async getPatternRecommendations(
    agentId: string,
    context: any = {}
  ): Promise<Array<{
    type: 'replicate' | 'avoid' | 'optimize' | 'monitor'
    pattern: any
    action: string
    priority: number
    reasoning: string
  }>> {
    try {
      const patternService = getPatternRecognitionService()
      return await patternService.getPatternRecommendations(agentId, context)
    } catch (error) {
      console.error('Error getting pattern recommendations:', error)
      return []
    }
  }

  async getLearningMetrics(agentId: string): Promise<LearningMetrics> {
    try {
      const memories = await this.retrieveMemories(agentId, { includeArchived: false })
      const clusters = await this.getMemoryClusters(agentId)
      const insights = await this.getMemoryInsights(agentId)

      // Calculate success rate from trade outcomes
      const tradeMemories = memories.filter(m => m.tradeOutcome)
      const successfulTrades = tradeMemories.filter(m => m.tradeOutcome?.success)
      const successRate = tradeMemories.length > 0 ? successfulTrades.length / tradeMemories.length : 0

      return {
        totalMemories: memories.length,
        avgImportance: memories.reduce((sum, m) => sum + m.importanceScore, 0) / memories.length,
        memoryTypes: this.getMemoryTypeDistribution(memories),
        successRate,
        adaptationScore: this.calculateAdaptationScore(memories),
        learningProgress: this.calculateLearningProgress(memories),
        recentActivity: memories.filter(m => 
          new Date(m.createdAt).getTime() > Date.now() - 24 * 60 * 60 * 1000
        ).length,
        clusterCount: clusters.length,
        insightCount: insights.length,
        checkpointCount: await this.getCheckpointCount(agentId)
      }

    } catch (error) {
      console.error('Error getting learning metrics:', error)
      return {
        totalMemories: 0,
        avgImportance: 0,
        memoryTypes: {},
        successRate: 0,
        adaptationScore: 0,
        learningProgress: 0,
        recentActivity: 0,
        clusterCount: 0,
        insightCount: 0,
        checkpointCount: 0
      }
    }
  }

  // ============================================
  // UTILITY METHODS
  // ============================================

  private calculateImportance(content: string, type: string, context: any): number {
    let importance = 0.5 // Base importance

    // Type-based importance
    switch (type) {
      case 'risk_observation': importance += 0.3; break
      case 'strategy_learning': importance += 0.2; break
      case 'performance_feedback': importance += 0.25; break
      case 'trade_decision': importance += 0.1; break
      default: break
    }

    // Context-based adjustments
    if (context.pnl) {
      importance += Math.min(Math.abs(context.pnl) / 1000, 0.3)
    }

    if (context.confidence > 0.8) {
      importance += 0.1
    }

    return Math.min(importance, 1.0)
  }

  private calculateRelevanceScore(memory: UnifiedMemory, query: string): number {
    let score = 0

    // Text similarity (simple implementation)
    const contentWords = memory.content.toLowerCase().split(' ')
    const queryWords = query.toLowerCase().split(' ')
    const matches = queryWords.filter(word => contentWords.includes(word))
    score += (matches.length / queryWords.length) * 0.4

    // Importance factor
    score += memory.importanceScore * 0.3

    // Recency factor
    const daysSinceCreated = (Date.now() - new Date(memory.createdAt).getTime()) / (1000 * 60 * 60 * 24)
    score += Math.max(0, (30 - daysSinceCreated) / 30) * 0.2

    // Access frequency factor
    score += Math.min(memory.accessCount / 10, 1) * 0.1

    return score
  }

  private groupMemoriesByStrategy(memories: UnifiedMemory[]): Record<string, UnifiedMemory[]> {
    return memories.reduce((groups, memory) => {
      const strategy = memory.strategyUsed || 'unknown'
      if (!groups[strategy]) groups[strategy] = []
      groups[strategy].push(memory)
      return groups
    }, {} as Record<string, UnifiedMemory[]>)
  }

  private getMemoryTypeDistribution(memories: UnifiedMemory[]): Record<string, number> {
    return memories.reduce((dist, memory) => {
      dist[memory.memoryType] = (dist[memory.memoryType] || 0) + 1
      return dist
    }, {} as Record<string, number>)
  }

  private calculateAdaptationScore(memories: UnifiedMemory[]): number {
    // Calculate how well the agent adapts based on memory patterns
    const adaptationMemories = memories.filter(m => m.category === 'adaptation')
    const totalMemories = memories.length
    
    if (totalMemories === 0) return 0
    
    return adaptationMemories.length / totalMemories
  }

  private calculateLearningProgress(memories: UnifiedMemory[]): number {
    // Calculate learning progress based on memory diversity and quality
    const types = new Set(memories.map(m => m.memoryType))
    const avgImportance = memories.reduce((sum, m) => sum + m.importanceScore, 0) / memories.length
    
    return (types.size / 6) * 0.4 + avgImportance * 0.6 // 6 is max number of memory types
  }

  private async getCheckpointCount(agentId: string): Promise<number> {
    try {
      const { count } = await this.supabase
        .from('enhanced_memory_checkpoints')
        .select('id', { count: 'exact' })
        .eq('agent_id', agentId)

      return count || 0
    } catch (error) {
      return 0
    }
  }

  private analyzeMemoryPatterns(memories: UnifiedMemory[]): Array<{
    type: string
    category: string
    title: string
    description: string
    confidence: number
    impact: number
    recommendations: string[]
  }> {
    const insights = []

    // Pattern 1: Success rate by strategy
    const strategies = this.groupMemoriesByStrategy(memories)
    for (const [strategy, strategyMemories] of Object.entries(strategies)) {
      if (strategyMemories.length >= 5) {
        const successes = strategyMemories.filter(m => m.tradeOutcome?.success).length
        const successRate = successes / strategyMemories.length

        if (successRate > 0.7) {
          insights.push({
            type: 'pattern',
            category: 'trading',
            title: `High Success Rate with ${strategy} Strategy`,
            description: `${(successRate * 100).toFixed(1)}% success rate detected with ${strategy} strategy`,
            confidence: 0.8,
            impact: 0.7,
            recommendations: [`Increase allocation to ${strategy} strategy`, `Optimize ${strategy} parameters for better performance`]
          })
        }
      }
    }

    // Pattern 2: Risk warnings
    const riskMemories = memories.filter(m => m.memoryType === 'risk_observation')
    if (riskMemories.length > 5) {
      insights.push({
        type: 'warning',
        category: 'risk',
        title: 'Increased Risk Observations',
        description: `${riskMemories.length} risk observations in recent memory - consider risk parameter review`,
        confidence: 0.6,
        impact: 0.8,
        recommendations: ['Review current risk parameters', 'Consider reducing position sizes', 'Implement stricter stop losses']
      })
    }

    return insights
  }

  private async generateEmbedding(text: string): Promise<number[] | null> {
    // Mock embedding generation - in production would use OpenAI API
    try {
      // Simulate embedding with simple hash-based vector
      const hash = this.simpleHash(text)
      const embedding = Array.from({ length: 512 }, (_, i) => Math.sin(hash + i) * 0.1)
      return embedding
    } catch (error) {
      console.error('Error generating embedding:', error)
      return null
    }
  }

  private simpleHash(str: string): number {
    let hash = 0
    for (let i = 0; i < str.length; i++) {
      const char = str.charCodeAt(i)
      hash = ((hash << 5) - hash) + char
      hash = hash & hash // Convert to 32-bit integer
    }
    return hash
  }

  private getMostFrequent<T>(array: T[]): T {
    const frequency = new Map<T, number>()
    let maxCount = 0
    let mostFrequent = array[0]
    
    for (const item of array) {
      const count = (frequency.get(item) || 0) + 1
      frequency.set(item, count)
      
      if (count > maxCount) {
        maxCount = count
        mostFrequent = item
      }
    }
    
    return mostFrequent
  }

  private mapMemoryTypeToClusterType(memoryType: string): MemoryCluster['clusterType'] {
    switch (memoryType) {
      case 'trade_decision':
      case 'strategy_learning':
        return 'strategy'
      case 'market_insight':
        return 'market_condition'
      case 'performance_feedback':
        return 'outcome'
      case 'pattern_recognition':
        return 'pattern'
      default:
        return 'pattern'
    }
  }

  private async generateClusterName(memories: any[]): Promise<string> {
    // Extract common themes from memory content
    const allWords = memories
      .map(m => m.content.toLowerCase())
      .join(' ')
      .split(/\s+/)
      .filter(word => word.length > 3)
    
    const wordFreq = new Map<string, number>()
    for (const word of allWords) {
      wordFreq.set(word, (wordFreq.get(word) || 0) + 1)
    }
    
    // Get most frequent meaningful words
    const commonWords = Array.from(wordFreq.entries())
      .sort((a, b) => b[1] - a[1])
      .slice(0, 3)
      .map(([word]) => word)
    
    // Get dominant symbols if any
    const symbols = memories
      .flatMap(m => m.relatedSymbols || [])
      .filter(Boolean)
    
    const symbolFreq = new Map<string, number>()
    for (const symbol of symbols) {
      symbolFreq.set(symbol, (symbolFreq.get(symbol) || 0) + 1)
    }
    
    const topSymbol = symbolFreq.size > 0 
      ? Array.from(symbolFreq.entries()).sort((a, b) => b[1] - a[1])[0][0]
      : null
    
    // Generate name
    if (topSymbol && commonWords.length > 0) {
      return `${topSymbol} ${commonWords[0]} Pattern`
    } else if (commonWords.length > 1) {
      return `${commonWords[0]} ${commonWords[1]} Cluster`
    } else {
      return `Memory Cluster ${Date.now().toString().slice(-4)}`
    }
  }

  private async updateAccessCounts(memoryIds: string[]) {
    try {
      // Increment access count for retrieved memories
      await this.supabase.rpc('increment_memory_access', {
        memory_ids: memoryIds
      })
    } catch (error) {
      // Ignore errors in access count updates
    }
  }

  // Data transformation helpers
  private transformMemoryData(data: any[]): UnifiedMemory[] {
    return data.map(item => ({
      id: item.id,
      agentId: item.agent_id,
      content: item.content,
      memoryType: item.memory_type,
      category: item.category,
      importanceScore: item.importance_score,
      relevanceDecay: item.relevance_decay,
      accessCount: item.access_count,
      lastAccessedAt: item.last_accessed_at ? new Date(item.last_accessed_at) : undefined,
      context: item.context,
      tags: item.tags || [],
      relatedSymbols: item.related_symbols || [],
      marketConditions: item.market_conditions,
      tradeOutcome: item.trade_outcome,
      strategyUsed: item.strategy_used,
      timeframe: item.timeframe,
      confidenceLevel: item.confidence_level,
      embedding: item.embedding ? JSON.parse(item.embedding) : undefined,
      embeddingModel: item.embedding_model,
      parentMemoryId: item.parent_memory_id,
      clusterId: item.cluster_id,
      similarityThreshold: item.similarity_threshold,
      createdAt: new Date(item.created_at),
      updatedAt: new Date(item.updated_at),
      expiresAt: item.expires_at ? new Date(item.expires_at) : undefined,
      archivedAt: item.archived_at ? new Date(item.archived_at) : undefined
    }))
  }

  private transformClusterData(data: any[]): MemoryCluster[] {
    return data.map(item => ({
      id: item.id,
      agentId: item.agent_id,
      clusterName: item.cluster_name,
      clusterType: item.cluster_type,
      description: item.description,
      memoryCount: item.memory_count,
      avgImportance: item.avg_importance,
      successRate: item.success_rate,
      avgPnl: item.avg_pnl,
      commonPatterns: item.common_patterns,
      insights: item.insights,
      recommendations: item.recommendations || [],
      clusterEmbedding: item.cluster_embedding ? JSON.parse(item.cluster_embedding) : undefined,
      isActive: item.is_active,
      autoGenerated: item.auto_generated,
      lastAnalyzedAt: item.last_analyzed_at ? new Date(item.last_analyzed_at) : undefined,
      createdAt: new Date(item.created_at),
      updatedAt: new Date(item.updated_at)
    }))
  }

  private transformInsightData(data: any[]): MemoryInsight[] {
    return data.map(item => ({
      id: item.id,
      agentId: item.agent_id,
      insightType: item.insight_type,
      insightCategory: item.insight_category,
      title: item.title,
      description: item.description,
      confidenceScore: item.confidence_score,
      impactScore: item.impact_score,
      urgencyScore: item.urgency_score,
      actionabilityScore: item.actionability_score,
      supportingMemories: item.supporting_memories || [],
      evidenceData: item.evidence_data,
      recommendations: item.recommendations || [],
      suggestedActions: item.suggested_actions,
      riskConsiderations: item.risk_considerations || [],
      isActionable: item.is_actionable,
      actionTaken: item.action_taken,
      actionDetails: item.action_details,
      outcomeTracked: item.outcome_tracked,
      generatedBy: item.generated_by,
      priorityLevel: item.priority_level,
      createdAt: new Date(item.created_at),
      updatedAt: new Date(item.updated_at),
      expiresAt: item.expires_at ? new Date(item.expires_at) : undefined
    }))
  }
}

// Singleton instance with lazy initialization
let unifiedMemoryServiceInstance: UnifiedMemoryService | null = null

export function getUnifiedMemoryService(): UnifiedMemoryService {
  if (!unifiedMemoryServiceInstance) {
    unifiedMemoryServiceInstance = new UnifiedMemoryService()
  }
  return unifiedMemoryServiceInstance
}

// For backward compatibility - but use getUnifiedMemoryService() instead
export const unifiedMemoryService = {
  get instance() {
    return getUnifiedMemoryService()
  }
}

export type { UnifiedMemory, MemoryCluster, MemoryInsight, MemorySearchOptions, LearningMetrics }