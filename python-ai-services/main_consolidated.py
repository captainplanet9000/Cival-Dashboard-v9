#!/usr/bin/env python3
"""
MCP Trading Platform - Consolidated Monorepo Application v2.0.0
Unified FastAPI application with centralized service management and dependency injection
"""

import asyncio
import os
import json
import logging
import uuid
from datetime import datetime, timezone
from typing import Dict, List, Optional, Any
from contextlib import asynccontextmanager

# FastAPI and web framework imports
from fastapi import FastAPI, HTTPException, BackgroundTasks, Request, Depends, WebSocket, WebSocketDisconnect
from fastapi.responses import JSONResponse, StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, Field
import uvicorn

# SSE for real-time updates
from sse_starlette.sse import EventSourceResponse

# Load environment variables
from dotenv import load_dotenv
load_dotenv()

# Core system imports
from core import (
    registry, db_manager, service_initializer,
    get_service_dependency, get_connection_dependency
)

# Import models for API endpoints
from models.api_models import TradingAnalysisCrewRequest, CrewRunResponse
from models.agent_models import AgentConfigInput, AgentStatus
from models.trading_history_models import TradeRecord
from models.paper_trading_models import CreatePaperTradeOrderRequest
from models.execution_models import ExecutionRequest
from models.hyperliquid_models import HyperliquidAccountSnapshot

# Enhanced Database Service imports
from services.enhanced_database_service import (
    get_enhanced_database_service, EnhancedDatabaseService,
    BlockchainWalletModel, BlockchainTransactionModel, SystemEventModel,
    NotificationModel, MLPredictionModel, RealtimeMetricModel, AuditLogModel
)

# Trading Farm Brain imports
from services.trading_farm_brain_service import (
    get_trading_farm_brain_service,
    StrategyArchiveData,
    TradeArchiveData,
    AgentDecisionArchiveData,
    AgentMemoryData
)
from services.farm_data_ingestion_service import get_farm_ingestion_service

# Authentication
from auth.dependencies import get_current_active_user
from models.auth_models import AuthenticatedUser

# Logging configuration
logging.basicConfig(
    level=getattr(logging, os.getenv("LOG_LEVEL", "INFO")),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# WebSocket Connection Manager for Real-time Updates
class WebSocketManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []
        self.connection_info: Dict[WebSocket, Dict[str, Any]] = {}
    
    async def connect(self, websocket: WebSocket, client_info: Dict[str, Any] = None):
        await websocket.accept()
        self.active_connections.append(websocket)
        self.connection_info[websocket] = client_info or {}
        logger.info(f"WebSocket client connected. Total connections: {len(self.active_connections)}")
    
    def disconnect(self, websocket: WebSocket):
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)
            self.connection_info.pop(websocket, None)
            logger.info(f"WebSocket client disconnected. Total connections: {len(self.active_connections)}")
    
    async def send_personal_message(self, message: str, websocket: WebSocket):
        try:
            await websocket.send_text(message)
        except Exception as e:
            logger.error(f"Error sending personal message: {e}")
            self.disconnect(websocket)
    
    async def broadcast(self, message: str, message_type: str = "update"):
        """Broadcast message to all connected clients"""
        if not self.active_connections:
            return
        
        message_data = {
            "type": message_type,
            "data": json.loads(message) if isinstance(message, str) else message,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
        disconnected = []
        for connection in self.active_connections:
            try:
                await connection.send_text(json.dumps(message_data))
            except WebSocketDisconnect:
                disconnected.append(connection)
            except Exception as e:
                logger.error(f"Error broadcasting to client: {e}")
                disconnected.append(connection)
        
        # Clean up disconnected clients
        for connection in disconnected:
            self.disconnect(connection)
    
    async def broadcast_portfolio_update(self, portfolio_data: Dict[str, Any]):
        """Broadcast portfolio updates"""
        await self.broadcast(portfolio_data, "portfolio_update")
    
    async def broadcast_agent_update(self, agent_data: Dict[str, Any]):
        """Broadcast agent status updates"""
        await self.broadcast(agent_data, "agent_update")
    
    async def broadcast_market_update(self, market_data: Dict[str, Any]):
        """Broadcast market data updates"""
        await self.broadcast(market_data, "market_update")
    
    async def broadcast_trading_signal(self, signal_data: Dict[str, Any]):
        """Broadcast trading signals"""
        await self.broadcast(signal_data, "trading_signal")

# Global WebSocket manager instance
websocket_manager = WebSocketManager()

# Configuration
API_PORT = int(os.getenv("PORT", 8000))
ENVIRONMENT = os.getenv("ENVIRONMENT", "development")
DEBUG = ENVIRONMENT == "development"

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan manager for startup and shutdown"""
    logger.info("ðŸš€ Starting MCP Trading Platform (Consolidated Monorepo v2.0.0)")
    
    try:
        # Initialize database connections
        logger.info("Initializing database connections...")
        db_results = await db_manager.initialize_connections()
        logger.info(f"Database initialization results: {db_results}")
        
        # Initialize all platform services
        logger.info("Initializing platform services...")
        service_results = await service_initializer.initialize_all_services()
        logger.info(f"Service initialization results: {service_results}")
        
        # Register additional services (optional)
        try:
            logger.info("Registering Phase 2 agent trading services...")
            from core.service_registry import register_agent_trading_services
            register_agent_trading_services()
        except ImportError:
            logger.warning("Phase 2 agent trading services not available")
        
        try:
            logger.info("Registering Phase 5 advanced services...")
            from core.service_registry import register_phase5_services
            register_phase5_services()
        except ImportError:
            logger.warning("Phase 5 advanced services not available")
        
        try:
            logger.info("Registering Phase 6-8 autonomous services...")
            from core.service_registry import register_autonomous_services
            register_autonomous_services()
        except ImportError:
            logger.warning("Phase 6-8 autonomous services not available")
        
        # Verify core services are available (but don't fail if they're not)
        core_services = ["historical_data", "trading_engine", "portfolio_tracker", "order_management"]
        available_services = []
        for service_name in core_services:
            service = registry.get_service(service_name)
            if service:
                logger.info(f"âœ… Core service {service_name} ready")
                available_services.append(service_name)
            else:
                logger.warning(f"âš ï¸  Core service {service_name} not available")
        
        # Verify AI services
        ai_services = ["ai_prediction", "technical_analysis", "sentiment_analysis", "ml_portfolio_optimizer"]
        for service_name in ai_services:
            service = registry.get_service(service_name)
            if service:
                logger.info(f"âœ… AI service {service_name} ready")
                available_services.append(service_name)
            else:
                logger.warning(f"âš ï¸  AI service {service_name} not available")
        
        # Initialize Orchestration Services (Phase 18)
        orchestration_services = [
            "farm_agent_orchestrator",
            "goal_capital_manager", 
            "performance_attribution_engine",
            "enhanced_event_propagation"
        ]
        
        for service_name in orchestration_services:
            try:
                # Dynamically import orchestration services
                if service_name == "farm_agent_orchestrator":
                    from services.farm_agent_orchestrator import FarmAgentOrchestrator
                    orchestrator = FarmAgentOrchestrator()
                    await orchestrator.initialize()
                    registry.register_service("farm_agent_orchestrator", orchestrator)
                    logger.info(f"âœ… Orchestration service {service_name} ready")
                    
                elif service_name == "goal_capital_manager":
                    from services.goal_capital_manager import GoalCapitalManager
                    manager = GoalCapitalManager()
                    await manager.initialize()
                    registry.register_service("goal_capital_manager", manager)
                    logger.info(f"âœ… Orchestration service {service_name} ready")
                    
                elif service_name == "performance_attribution_engine":
                    from services.performance_attribution_engine import PerformanceAttributionEngine
                    engine = PerformanceAttributionEngine()
                    await engine.initialize()
                    registry.register_service("performance_attribution_engine", engine)
                    logger.info(f"âœ… Orchestration service {service_name} ready")
                    
                elif service_name == "enhanced_event_propagation":
                    from services.enhanced_event_propagation import EnhancedEventPropagation
                    event_system = EnhancedEventPropagation()
                    await event_system.initialize()
                    registry.register_service("enhanced_event_propagation", event_system)
                    logger.info(f"âœ… Orchestration service {service_name} ready")
                    
                available_services.append(service_name)
            except Exception as e:
                logger.warning(f"âš ï¸  Orchestration service {service_name} not available: {e}")
        
        logger.info("âœ… MCP Trading Platform ready for agent trading operations!")
        
        # Start real-time data broadcasting task
        logger.info("Starting real-time data broadcaster...")
        broadcaster_task = asyncio.create_task(real_time_data_broadcaster())
        
        # Store startup information in registry
        registry.register_service("startup_info", {
            "version": "2.0.0",
            "startup_time": datetime.now(timezone.utc).isoformat(),
            "environment": ENVIRONMENT,
            "services_initialized": len(registry.all_services),
            "connections_active": len(registry.all_connections),
            "websocket_broadcaster": "running"
        })
        
    except Exception as e:
        logger.error(f"Failed to start platform: {e}")
        raise e
    
    yield
    
    # Cleanup on shutdown
    logger.info("Shutting down real-time data broadcaster...")
    if 'broadcaster_task' in locals():
        broadcaster_task.cancel()
        try:
            await broadcaster_task
        except asyncio.CancelledError:
            pass
    
    # Cleanup on shutdown
    logger.info("ðŸ›‘ Shutting down MCP Trading Platform...")
    await registry.cleanup()
    await db_manager.cleanup()
    logger.info("Platform shutdown completed")

# Create FastAPI application with consolidated lifespan
app = FastAPI(
    title="MCP Trading Platform",
    description="Consolidated AI-Powered Algorithmic Trading Platform for Agent Operations",
    version="2.0.0",
    lifespan=lifespan,
    docs_url="/docs" if DEBUG else None,
    redoc_url="/redoc" if DEBUG else None
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"] if DEBUG else [os.getenv("FRONTEND_URL", "http://localhost:3000")],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Root and health endpoints
@app.get("/")
async def root():
    """Root endpoint with platform information"""
    startup_info = registry.get_service("startup_info") or {}
    
    return {
        "name": "MCP Trading Platform",
        "version": "2.0.0",
        "description": "Consolidated AI-Powered Algorithmic Trading Platform",
        "architecture": "monorepo",
        "environment": ENVIRONMENT,
        "startup_info": startup_info,
        "endpoints": {
            "health": "/health",
            "docs": "/docs",
            "market_data": "/api/v1/market-data/*",
            "trading": "/api/v1/trading/*",
            "agents": "/api/v1/agents/*",
            "portfolio": "/api/v1/portfolio/*",
            "risk": "/api/v1/risk/*",
            "ai_analytics": "/api/v1/ai/*",
            "agent_trading": "/api/v1/agent-trading/*",
            "autonomous_system": "/api/v1/autonomous/*",
            "orchestration": "/api/v1/orchestration/*",
            "dashboard": "/dashboard"
        }
    }

@app.get("/health")
async def health_check():
    """Comprehensive health check for all services and connections"""
    health_status = {
        "status": "healthy",
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "version": "2.0.0",
        "environment": ENVIRONMENT,
        "architecture": "consolidated_monorepo"
    }
    
    try:
        # Get detailed health from registry
        detailed_health = await registry.health_check()
        health_status.update(detailed_health)
        
        # Determine overall status
        unhealthy_services = [
            name for name, status in detailed_health.get("services", {}).items()
            if isinstance(status, str) and "error" in status.lower()
        ]
        
        unhealthy_connections = [
            name for name, status in detailed_health.get("connections", {}).items()
            if isinstance(status, str) and "error" in status.lower()
        ]
        
        if unhealthy_services or unhealthy_connections:
            health_status["status"] = "degraded"
            health_status["issues"] = {
                "unhealthy_services": unhealthy_services,
                "unhealthy_connections": unhealthy_connections
            }
        
    except Exception as e:
        health_status["status"] = "error"
        health_status["error"] = str(e)
        logger.error(f"Health check failed: {e}")
    
    return health_status

# Autonomous Health Monitor Endpoints
@app.get("/api/v1/health/autonomous")
async def get_autonomous_health_status():
    """Get detailed autonomous health monitoring status"""
    try:
        health_monitor = registry.get_service("autonomous_health_monitor")
        if health_monitor:
            health_summary = await health_monitor.get_system_health()
            return {
                "status": "success",
                "data": health_summary,
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
        else:
            return {
                "status": "error",
                "message": "Autonomous health monitor not available",
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
    except Exception as e:
        logger.error(f"Failed to get autonomous health status: {e}")
        raise HTTPException(status_code=500, detail=f"Health monitor error: {str(e)}")

@app.get("/api/v1/health/components")
async def get_component_health():
    """Get health status for all monitored components"""
    try:
        health_monitor = registry.get_service("autonomous_health_monitor")
        if health_monitor:
            health_summary = await health_monitor.get_health_summary()
            return {
                "status": "success",
                "data": health_summary,
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
        else:
            return {
                "status": "error",
                "message": "Autonomous health monitor not available",
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
    except Exception as e:
        logger.error(f"Failed to get component health: {e}")
        raise HTTPException(status_code=500, detail=f"Component health error: {str(e)}")

@app.get("/api/v1/health/component/{component_id}")
async def get_specific_component_health(component_id: str):
    """Get health status for a specific component"""
    try:
        health_monitor = registry.get_service("autonomous_health_monitor")
        if health_monitor:
            component_health = await health_monitor.get_component_health(component_id)
            if component_health:
                return {
                    "status": "success",
                    "data": component_health,
                    "timestamp": datetime.now(timezone.utc).isoformat()
                }
            else:
                raise HTTPException(status_code=404, detail=f"Component {component_id} not found")
        else:
            return {
                "status": "error",
                "message": "Autonomous health monitor not available",
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get component health for {component_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Component health error: {str(e)}")

@app.post("/api/v1/health/recovery/{component_id}")
async def trigger_component_recovery(component_id: str):
    """Manually trigger recovery for a specific component"""
    try:
        health_monitor = registry.get_service("autonomous_health_monitor")
        if health_monitor:
            success = await health_monitor.force_recovery(component_id)
            return {
                "status": "success" if success else "failed",
                "message": f"Recovery {'triggered' if success else 'failed'} for component {component_id}",
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
        else:
            return {
                "status": "error",
                "message": "Autonomous health monitor not available",
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
    except Exception as e:
        logger.error(f"Failed to trigger recovery for {component_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Recovery trigger error: {str(e)}")

@app.get("/api/v1/health/performance/{component_id}")
async def get_component_performance_history(component_id: str, limit: int = 100):
    """Get performance history for a specific component"""
    try:
        health_monitor = registry.get_service("autonomous_health_monitor")
        if health_monitor:
            performance_data = await health_monitor.get_performance_history(component_id, limit)
            return {
                "status": "success",
                "data": {
                    "component_id": component_id,
                    "performance_history": performance_data,
                    "count": len(performance_data)
                },
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
        else:
            return {
                "status": "error",
                "message": "Autonomous health monitor not available",
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
    except Exception as e:
        logger.error(f"Failed to get performance history for {component_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Performance history error: {str(e)}")

# Market Data Endpoints (Consolidated from ports 8001-8002)
@app.get("/api/v1/market-data/live/{symbol}")
async def get_live_market_data(
    symbol: str,
    market_data_service = Depends(get_service_dependency("market_data"))
):
    """Get real-time market data for a symbol"""
    try:
        data = await market_data_service.get_live_data(symbol)
        return {"symbol": symbol, "data": data, "timestamp": datetime.now(timezone.utc).isoformat()}
    except Exception as e:
        logger.error(f"Failed to get live data for {symbol}: {e}")
        raise HTTPException(status_code=500, detail=f"Market data error: {str(e)}")

@app.get("/api/v1/market-data/historical/{symbol}")
async def get_historical_data(
    symbol: str,
    period: str = "1d",
    interval: str = "1h",
    historical_data_service = Depends(get_service_dependency("historical_data"))
):
    """Get historical market data"""
    try:
        data = await historical_data_service.get_historical_data(symbol, period, interval)
        return {
            "symbol": symbol,
            "period": period,
            "interval": interval,
            "data": data,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
    except Exception as e:
        logger.error(f"Failed to get historical data for {symbol}: {e}")
        raise HTTPException(status_code=500, detail=f"Historical data error: {str(e)}")

# Trading Engine Endpoints (Consolidated from ports 8010-8013)
@app.post("/api/v1/trading/orders")
async def create_order(
    order_request: CreatePaperTradeOrderRequest,
    order_management_service = Depends(get_service_dependency("order_management"))
):
    """Create a new trading order"""
    try:
        # Use a default user ID for solo operator
        solo_user_id = "solo_operator"
        order = await order_management_service.create_order(order_request, solo_user_id)
        return order
    except Exception as e:
        logger.error(f"Failed to create order for solo operator: {e}")
        raise HTTPException(status_code=500, detail=f"Order creation error: {str(e)}")

@app.get("/api/v1/trading/orders")
async def get_orders(
    status: Optional[str] = None,
    order_management_service = Depends(get_service_dependency("order_management"))
):
    """Get trading orders"""
    try:
        solo_user_id = "solo_operator"
        orders = await order_management_service.get_user_orders(solo_user_id, status)
        return {"orders": orders, "user_id": solo_user_id}
    except Exception as e:
        logger.error(f"Failed to get orders for solo operator: {e}")
        raise HTTPException(status_code=500, detail=f"Order retrieval error: {str(e)}")

@app.get("/api/v1/portfolio/positions")
async def get_portfolio_positions(
    portfolio_service = Depends(get_service_dependency("portfolio_tracker"))
):
    """Get portfolio positions"""
    try:
        solo_user_id = "solo_operator"
        positions = await portfolio_service.get_positions(solo_user_id)
        return {"positions": positions, "user_id": solo_user_id}
    except Exception as e:
        logger.error(f"Failed to get positions for solo operator: {e}")
        raise HTTPException(status_code=500, detail=f"Portfolio error: {str(e)}")

@app.get("/api/v1/portfolio/performance")
async def get_portfolio_performance(
    portfolio_service = Depends(get_service_dependency("portfolio_tracker"))
):
    """Get portfolio performance metrics"""
    try:
        solo_user_id = "solo_operator"
        performance = await portfolio_service.get_performance_metrics(solo_user_id)
        return {"performance": performance, "user_id": solo_user_id}
    except Exception as e:
        logger.error(f"Failed to get performance for solo operator: {e}")
        raise HTTPException(status_code=500, detail=f"Performance error: {str(e)}")

@app.get("/api/v1/services")
async def get_services():
    """Get available services and their status"""
    try:
        services = {
            "portfolio_tracker": {"status": "running", "service": "Portfolio Management"},
            "trading_engine": {"status": "running", "service": "Trading Engine"},
            "risk_management": {"status": "running", "service": "Risk Management"},
            "agent_management": {"status": "running", "service": "Agent Coordination"},
            "market_data": {"status": "running", "service": "Market Data Feed"},
            "ai_prediction": {"status": "running", "service": "AI Prediction Engine"},
            "technical_analysis": {"status": "running", "service": "Technical Analysis"},
            "sentiment_analysis": {"status": "running", "service": "Sentiment Analysis"}
        }
        return {"services": services, "timestamp": "2025-06-14T15:30:00Z"}
    except Exception as e:
        logger.error(f"Failed to get services: {e}")
        raise HTTPException(status_code=500, detail=f"Services error: {str(e)}")

@app.get("/api/v1/portfolio/summary")
async def get_portfolio_summary():
    """Get portfolio summary with key metrics and real calculations"""
    try:
        calculation_service = registry.get_service("calculation")
        
        # Mock position data for calculation
        positions = [
            {"symbol": "BTC/USDT", "value": 68467.50, "pnl": 3247.85, "margin_used": 5000},
            {"symbol": "ETH/USDT", "value": 25234.17, "pnl": 1234.56, "margin_used": 2500},
            {"symbol": "SOL/USDT", "value": 13716.15, "pnl": 567.89, "margin_used": 1000},
            {"symbol": "USDT", "value": 18429.50, "pnl": 0, "margin_used": 0}
        ]
        
        total_equity = sum(pos["value"] for pos in positions)
        total_unrealized_pnl = sum(pos["pnl"] for pos in positions)
        cash_balance = next(pos["value"] for pos in positions if pos["symbol"] == "USDT")
        total_position_value = total_equity - cash_balance
        
        if calculation_service:
            # Calculate real performance metrics
            historical_values = [120000, 122000, 124000, total_equity]
            performance = await calculation_service.calculate_portfolio_performance(positions, historical_values)
            risk_metrics = await calculation_service.calculate_risk_metrics(positions)
            
            summary = {
                "total_equity": round(total_equity, 2),
                "cash_balance": round(cash_balance, 2),
                "total_position_value": round(total_position_value, 2),
                "total_unrealized_pnl": round(total_unrealized_pnl, 2),
                "total_realized_pnl": 1829.47,  # Mock realized P&L
                "total_pnl": round(total_unrealized_pnl + 1829.47, 2),
                "daily_pnl": round(total_equity * 0.007, 2),  # 0.7% daily gain
                "total_return_percent": round(performance.total_return, 2),
                "annualized_return": round(performance.annualized_return, 2),
                "volatility": round(performance.volatility, 2),
                "sharpe_ratio": round(performance.sharpe_ratio, 2),
                "max_drawdown": round(performance.max_drawdown, 2),
                "var_95": round(performance.var_95, 2),
                "risk_score": round((risk_metrics.concentration_risk + risk_metrics.correlation_risk) * 5, 1),
                "number_of_positions": len([p for p in positions if p["value"] > 0]),
                "long_positions": len([p for p in positions if p["value"] > 0 and p["symbol"] != "USDT"]),
                "short_positions": 0,  # No short positions in mock data
                "last_updated": datetime.now().isoformat()
            }
        else:
            # Fallback calculation without service
            summary = {
                "total_equity": round(total_equity, 2),
                "cash_balance": round(cash_balance, 2),
                "total_position_value": round(total_position_value, 2),
                "total_unrealized_pnl": round(total_unrealized_pnl, 2),
                "total_realized_pnl": 1829.47,
                "total_pnl": round(total_unrealized_pnl + 1829.47, 2),
                "daily_pnl": round(total_equity * 0.007, 2),
                "total_return_percent": round((total_unrealized_pnl / (total_equity - total_unrealized_pnl)) * 100, 2),
                "number_of_positions": len([p for p in positions if p["value"] > 0]),
                "long_positions": len([p for p in positions if p["value"] > 0 and p["symbol"] != "USDT"]),
                "short_positions": 0,
                "last_updated": datetime.now().isoformat()
            }
        
        return summary
    except Exception as e:
        logger.error(f"Failed to get portfolio summary: {e}")
        raise HTTPException(status_code=500, detail=f"Portfolio summary error: {str(e)}")

@app.get("/api/v1/market/overview")
async def get_market_overview():
    """Get market overview data"""
    try:
        # Mock market data for frontend integration
        overview = {
            "market_data": [
                {
                    "symbol": "BTC",
                    "price": 67234.85,
                    "change_pct": 2.34,
                    "volatility": 3.8,
                    "volume": 28947583920,
                    "market_cap": 1324500000000,
                    "last_updated": "2025-06-14T15:30:00Z"
                },
                {
                    "symbol": "ETH", 
                    "price": 3847.92,
                    "change_pct": -1.12,
                    "volatility": 4.2,
                    "volume": 15834729102,
                    "market_cap": 462800000000,
                    "last_updated": "2025-06-14T15:30:00Z"
                },
                {
                    "symbol": "SOL",
                    "price": 142.73,
                    "change_pct": 5.67,
                    "volatility": 6.1,
                    "volume": 3294857203,
                    "market_cap": 65400000000,
                    "last_updated": "2025-06-14T15:30:00Z"
                }
            ],
            "market_sentiment": {
                "overall": "bullish",
                "score": 72,
                "fear_greed_index": 68,
                "vix": 14.2
            },
            "timestamp": "2025-06-14T15:30:00Z"
        }
        return overview
    except Exception as e:
        logger.error(f"Failed to get market overview: {e}")
        raise HTTPException(status_code=500, detail=f"Market overview error: {str(e)}")

@app.get("/api/v1/trading/signals")
async def get_trading_signals():
    """Get AI trading signals"""
    try:
        # Mock trading signals for frontend integration
        signals = [
            {
                "symbol": "BTC",
                "signal": "buy",
                "strength": 0.78,
                "confidence": 0.85,
                "predicted_change_pct": 3.2,
                "reasoning": "Strong momentum with volume confirmation, breaking resistance at $66,800",
                "generated_at": "2025-06-14T15:25:00Z",
                "source": "momentum_analyzer"
            },
            {
                "symbol": "ETH",
                "signal": "hold",
                "strength": 0.45,
                "confidence": 0.62,
                "predicted_change_pct": -0.8,
                "reasoning": "Mixed signals with decreasing volume, waiting for clearer direction",
                "generated_at": "2025-06-14T15:24:00Z",
                "source": "pattern_recognition"
            },
            {
                "symbol": "SOL",
                "signal": "buy",
                "strength": 0.89,
                "confidence": 0.92,
                "predicted_change_pct": 8.1,
                "reasoning": "Breakout pattern confirmed with high volume and positive news flow",
                "generated_at": "2025-06-14T15:26:00Z",
                "source": "multi_factor_model"
            }
        ]
        return signals
    except Exception as e:
        logger.error(f"Failed to get trading signals: {e}")
        raise HTTPException(status_code=500, detail=f"Trading signals error: {str(e)}")

@app.get("/api/v1/agents/status")
async def get_all_agents_status():
    """Get status of all agents"""
    try:
        # Mock agent status data for frontend integration
        agents_status = [
            {
                "agent_id": "agent_marcus_momentum",
                "name": "Marcus Momentum",
                "status": "active",
                "strategy": "momentum_trading",
                "current_allocation": 25000.00,
                "pnl": 1247.85,
                "trades_today": 8,
                "win_rate": 0.72,
                "last_action": "Bought 0.15 BTC at $67,100",
                "last_updated": "2025-06-14T15:28:00Z"
            },
            {
                "agent_id": "agent_alex_arbitrage",
                "name": "Alex Arbitrage", 
                "status": "monitoring",
                "strategy": "arbitrage",
                "current_allocation": 30000.00,
                "pnl": 892.34,
                "trades_today": 12,
                "win_rate": 0.83,
                "last_action": "Monitoring price spreads across exchanges",
                "last_updated": "2025-06-14T15:29:00Z"
            },
            {
                "agent_id": "agent_sophia_reversion",
                "name": "Sophia Reversion",
                "status": "active",
                "strategy": "mean_reversion",
                "current_allocation": 20000.00,
                "pnl": -234.12,
                "trades_today": 5,
                "win_rate": 0.64,
                "last_action": "Sold 2.5 ETH at $3,850",
                "last_updated": "2025-06-14T15:27:00Z"
            }
        ]
        return agents_status
    except Exception as e:
        logger.error(f"Failed to get agents status: {e}")
        raise HTTPException(status_code=500, detail=f"Agents status error: {str(e)}")

# Enhanced Agent Management Endpoints
@app.post("/api/v1/agents/{agent_id}/execute-decision")
async def execute_agent_decision(agent_id: str, decision_params: dict):
    """Execute a trading decision for a specific agent"""
    try:
        # Simulate agent decision making
        decision_result = {
            "agent_id": agent_id,
            "decision": decision_params.get("action", "hold"),
            "symbol": decision_params.get("symbol", "BTC"),
            "confidence": 0.85,
            "reasoning": f"Agent {agent_id} analyzed market conditions and decided to {decision_params.get('action', 'hold')}",
            "risk_assessment": {
                "risk_level": "medium",
                "expected_return": 0.034,
                "max_loss": 0.021,
                "position_size": 0.1
            },
            "execution": {
                "status": "executed",
                "order_id": f"order_{agent_id}_{int(datetime.now().timestamp())}",
                "executed_price": 67234.85,
                "executed_quantity": 0.1,
                "execution_time": datetime.now(timezone.utc).isoformat()
            },
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
        # Broadcast agent decision via WebSocket
        await websocket_manager.broadcast_agent_update(decision_result)
        
        return decision_result
    except Exception as e:
        logger.error(f"Failed to execute agent decision for {agent_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Agent decision error: {str(e)}")

@app.post("/api/v1/agents/{agent_id}/start")
async def start_agent(agent_id: str):
    """Start an agent for trading"""
    try:
        agent_status = {
            "agent_id": agent_id,
            "status": "active",
            "started_at": datetime.now(timezone.utc).isoformat(),
            "message": f"Agent {agent_id} started successfully"
        }
        return agent_status
    except Exception as e:
        logger.error(f"Failed to start agent {agent_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Agent start error: {str(e)}")

@app.post("/api/v1/agents/{agent_id}/stop") 
async def stop_agent(agent_id: str):
    """Stop an agent from trading"""
    try:
        agent_status = {
            "agent_id": agent_id,
            "status": "stopped",
            "stopped_at": datetime.now(timezone.utc).isoformat(),
            "message": f"Agent {agent_id} stopped successfully"
        }
        return agent_status
    except Exception as e:
        logger.error(f"Failed to stop agent {agent_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Agent stop error: {str(e)}")

@app.get("/api/v1/agents/{agent_id}/decisions")
async def get_agent_decisions(agent_id: str, limit: int = 10):
    """Get recent decisions made by an agent"""
    try:
        decisions = [
            {
                "id": f"decision_{i}",
                "agent_id": agent_id,
                "action": "buy" if i % 3 == 0 else "sell" if i % 3 == 1 else "hold",
                "symbol": "BTC" if i % 2 == 0 else "ETH",
                "confidence": 0.75 + (i * 0.05) % 0.25,
                "reasoning": f"Decision {i}: Market analysis suggests favorable conditions",
                "executed": i < 7,
                "pnl": (i * 23.45) if i < 7 else None,
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
            for i in range(min(limit, 10))
        ]
        return {"decisions": decisions, "agent_id": agent_id}
    except Exception as e:
        logger.error(f"Failed to get decisions for agent {agent_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Agent decisions error: {str(e)}")

@app.post("/api/v1/agents/coordinate-decision")
async def coordinate_multi_agent_decision(coordination_params: dict):
    """Coordinate a decision between multiple agents"""
    try:
        participating_agents = coordination_params.get("agents", ["agent_marcus_momentum", "agent_alex_arbitrage"])
        decision_type = coordination_params.get("type", "collaborative")
        
        coordination_result = {
            "coordination_id": f"coord_{int(datetime.now().timestamp())}",
            "participating_agents": participating_agents,
            "decision_type": decision_type,
            "consensus": {
                "action": "buy",
                "symbol": "BTC",
                "confidence": 0.82,
                "agreement_level": 0.89
            },
            "individual_inputs": [
                {
                    "agent_id": "agent_marcus_momentum",
                    "recommendation": "buy",
                    "confidence": 0.85,
                    "reasoning": "Strong momentum signals detected"
                },
                {
                    "agent_id": "agent_alex_arbitrage", 
                    "recommendation": "buy",
                    "confidence": 0.78,
                    "reasoning": "Arbitrage opportunity identified"
                }
            ],
            "final_decision": {
                "action": "buy",
                "symbol": "BTC",
                "position_size": 0.15,
                "execution_plan": "immediate",
                "risk_controls": ["stop_loss_2%", "take_profit_4%"]
            },
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
        return coordination_result
    except Exception as e:
        logger.error(f"Failed to coordinate agent decision: {e}")
        raise HTTPException(status_code=500, detail=f"Agent coordination error: {str(e)}")

@app.get("/api/v1/performance/metrics")
async def get_performance_metrics():
    """Get detailed performance metrics"""
    try:
        # Mock performance metrics for frontend integration
        metrics = {
            "total_return_percent": 4.19,
            "total_pnl": 5077.32,
            "daily_pnl": 847.29,
            "win_rate": 0.73,
            "sharpe_ratio": 1.84,
            "volatility": 0.152,
            "max_drawdown": 0.087,
            "total_trades": 147,
            "total_equity": 125847.32,
            "initial_equity": 120000.00,
            "best_trade": 892.45,
            "worst_trade": -234.78,
            "avg_trade": 34.52,
            "last_updated": "2025-06-14T15:30:00Z"
        }
        return metrics
    except Exception as e:
        logger.error(f"Failed to get performance metrics: {e}")
        raise HTTPException(status_code=500, detail=f"Performance metrics error: {str(e)}")

# ==================== UNIVERSAL TRADING MODE ENDPOINTS ====================

class TradingModeRequest(BaseModel):
    mode: str
    config: Optional[Dict[str, Any]] = None

class ComponentRegistrationRequest(BaseModel):
    componentId: str
    componentType: str

@app.get("/api/v1/trading-mode/current")
async def get_current_trading_mode():
    """Get current system trading mode"""
    try:
        universal_mode_service = registry.get_service("universal_trading_mode_service")
        if universal_mode_service:
            current_mode = await universal_mode_service.get_trading_mode()
            return {"mode": current_mode.value}
        else:
            # Fallback to paper mode
            return {"mode": "paper"}
    except Exception as e:
        logger.error(f"Failed to get current trading mode: {e}")
        return {"mode": "paper"}  # Safe fallback

@app.get("/api/v1/trading-mode/config")
async def get_trading_mode_config():
    """Get trading mode configuration"""
    try:
        universal_mode_service = registry.get_service("universal_trading_mode_service")
        if universal_mode_service:
            config = await universal_mode_service.get_mode_config()
            return {
                "mode": config.mode.value,
                "enabledExchanges": config.enabled_exchanges,
                "riskLimits": config.risk_limits,
                "positionLimits": config.position_limits,
                "safetyChecks": config.safety_checks,
                "realFunds": config.real_funds,
                "liveData": config.live_data,
                "notifications": config.notifications,
                "auditLogging": config.audit_logging,
                "paperBalance": config.paper_balance
            }
        else:
            # Return default config
            return {
                "mode": "paper",
                "enabledExchanges": ["binance", "coinbase"],
                "riskLimits": {"maxPositionSize": 0.1, "maxDailyLoss": 0.05, "maxPortfolioRisk": 0.15},
                "positionLimits": {"maxSinglePosition": 0.05, "maxSectorAllocation": 0.3, "maxLeverage": 1.0},
                "safetyChecks": True,
                "realFunds": False,
                "liveData": False,
                "notifications": True,
                "auditLogging": True,
                "paperBalance": 100000.0
            }
    except Exception as e:
        logger.error(f"Failed to get trading mode config: {e}")
        raise HTTPException(status_code=500, detail=f"Config error: {str(e)}")

@app.get("/api/v1/trading-mode/status")
async def get_trading_mode_status():
    """Get comprehensive trading mode status"""
    try:
        universal_mode_service = registry.get_service("universal_trading_mode_service")
        if universal_mode_service:
            status = await universal_mode_service.get_mode_status()
            return status
        else:
            # Return basic status
            return {
                "service": "universal_trading_mode",
                "currentMode": "paper",
                "components": {},
                "totalComponents": 0,
                "syncedComponents": 0,
                "errorComponents": 0,
                "modeChangesToday": 0
            }
    except Exception as e:
        logger.error(f"Failed to get trading mode status: {e}")
        raise HTTPException(status_code=500, detail=f"Status error: {str(e)}")

@app.post("/api/v1/trading-mode/set")
async def set_trading_mode(request: TradingModeRequest):
    """Set system trading mode"""
    try:
        universal_mode_service = registry.get_service("universal_trading_mode_service")
        if universal_mode_service:
            from services.universal_trading_mode_service import TradingMode, TradingModeConfig
            
            # Convert string mode to enum
            mode = TradingMode(request.mode)
            
            # Create config if provided
            config = None
            if request.config:
                config = TradingModeConfig(
                    mode=mode,
                    enabled_exchanges=request.config.get('enabledExchanges', ['binance', 'coinbase']),
                    risk_limits=request.config.get('riskLimits', {}),
                    position_limits=request.config.get('positionLimits', {}),
                    safety_checks=request.config.get('safetyChecks', True),
                    real_funds=request.config.get('realFunds', False),
                    live_data=request.config.get('liveData', False),
                    notifications=request.config.get('notifications', True),
                    audit_logging=request.config.get('auditLogging', True),
                    paper_balance=request.config.get('paperBalance', 100000.0)
                )
            
            success = await universal_mode_service.set_trading_mode(mode, config)
            
            if success:
                return {"success": True, "mode": request.mode, "message": f"Trading mode set to {request.mode}"}
            else:
                raise HTTPException(status_code=400, detail="Failed to set trading mode")
        else:
            # Service not available - log but don't fail
            logger.warning("Universal trading mode service not available")
            return {"success": True, "mode": request.mode, "message": "Mode change recorded (service unavailable)"}
    except ValueError as e:
        raise HTTPException(status_code=400, detail=f"Invalid mode: {str(e)}")
    except Exception as e:
        logger.error(f"Failed to set trading mode: {e}")
        raise HTTPException(status_code=500, detail=f"Mode change error: {str(e)}")

@app.post("/api/v1/trading-mode/toggle")
async def toggle_trading_mode():
    """Toggle between paper and live trading mode"""
    try:
        universal_mode_service = registry.get_service("universal_trading_mode_service")
        if universal_mode_service:
            success = await universal_mode_service.toggle_trading_mode()
            if success:
                current_mode = await universal_mode_service.get_trading_mode()
                return {"success": True, "mode": current_mode.value, "message": f"Toggled to {current_mode.value} mode"}
            else:
                raise HTTPException(status_code=400, detail="Failed to toggle trading mode")
        else:
            return {"success": True, "mode": "paper", "message": "Toggle recorded (service unavailable)"}
    except Exception as e:
        logger.error(f"Failed to toggle trading mode: {e}")
        raise HTTPException(status_code=500, detail=f"Toggle error: {str(e)}")

@app.post("/api/v1/trading-mode/register-component")
async def register_component(request: ComponentRegistrationRequest):
    """Register component for trading mode coordination"""
    try:
        universal_mode_service = registry.get_service("universal_trading_mode_service")
        if universal_mode_service:
            from services.universal_trading_mode_service import ComponentType
            
            # Convert string to enum
            component_type = ComponentType(request.componentType.lower())
            
            success = await universal_mode_service.register_component(
                request.componentId, 
                component_type
            )
            
            if success:
                return {"success": True, "message": f"Component {request.componentId} registered"}
            else:
                raise HTTPException(status_code=400, detail="Failed to register component")
        else:
            return {"success": True, "message": "Component registration recorded (service unavailable)"}
    except ValueError as e:
        raise HTTPException(status_code=400, detail=f"Invalid component type: {str(e)}")
    except Exception as e:
        logger.error(f"Failed to register component: {e}")
        raise HTTPException(status_code=500, detail=f"Registration error: {str(e)}")

@app.post("/api/v1/trading-mode/unregister-component")
async def unregister_component(request: ComponentRegistrationRequest):
    """Unregister component from trading mode coordination"""
    try:
        universal_mode_service = registry.get_service("universal_trading_mode_service")
        if universal_mode_service:
            success = await universal_mode_service.unregister_component(request.componentId)
            if success:
                return {"success": True, "message": f"Component {request.componentId} unregistered"}
            else:
                raise HTTPException(status_code=400, detail="Failed to unregister component")
        else:
            return {"success": True, "message": "Component unregistration recorded (service unavailable)"}
    except Exception as e:
        logger.error(f"Failed to unregister component: {e}")
        raise HTTPException(status_code=500, detail=f"Unregistration error: {str(e)}")

# ==================== AGENT SCHEDULING ENDPOINTS ====================

class ScheduleTaskRequest(BaseModel):
    agentId: str
    taskName: str
    taskType: str
    scheduleConfig: Dict[str, Any]
    taskConfig: Optional[Dict[str, Any]] = None
    priority: Optional[str] = "normal"

@app.post("/api/v1/agents/schedule-task")
async def schedule_agent_task(request: ScheduleTaskRequest):
    """Schedule a new task for an agent"""
    try:
        apscheduler_service = registry.get_service("apscheduler_agent_service")
        if apscheduler_service:
            from services.apscheduler_agent_service import TaskPriority
            
            priority = TaskPriority(request.priority.lower())
            
            task_id = await apscheduler_service.schedule_agent_task(
                agent_id=request.agentId,
                task_name=request.taskName,
                task_type=request.taskType,
                schedule_config=request.scheduleConfig,
                task_config=request.taskConfig,
                priority=priority
            )
            
            return {"success": True, "taskId": task_id, "message": f"Task scheduled: {request.taskName}"}
        else:
            # Generate mock task ID
            task_id = f"task_{request.agentId}_{int(datetime.now().timestamp())}"
            return {"success": True, "taskId": task_id, "message": "Task scheduled (service unavailable)"}
    except Exception as e:
        logger.error(f"Failed to schedule task: {e}")
        raise HTTPException(status_code=500, detail=f"Scheduling error: {str(e)}")

@app.get("/api/v1/agents/{agent_id}/tasks")
async def get_agent_tasks(agent_id: str):
    """Get all scheduled tasks for an agent"""
    try:
        apscheduler_service = registry.get_service("apscheduler_agent_service")
        if apscheduler_service:
            tasks = await apscheduler_service.get_agent_tasks(agent_id)
            
            # Convert to API format
            task_list = []
            for task in tasks:
                task_list.append({
                    "taskId": task.task_id,
                    "agentId": task.agent_id,
                    "taskName": task.task_name,
                    "taskType": task.task_type,
                    "scheduleType": task.schedule_type.value,
                    "priority": task.priority.value,
                    "status": task.status.value,
                    "nextRun": task.next_run.isoformat() if task.next_run else None,
                    "lastRun": task.last_run.isoformat() if task.last_run else None,
                    "runCount": task.run_count,
                    "errorCount": task.error_count,
                    "createdAt": task.created_at.isoformat()
                })
            
            return {"tasks": task_list, "total": len(task_list)}
        else:
            # Return mock tasks
            return {
                "tasks": [
                    {
                        "taskId": f"task_{agent_id}_1",
                        "agentId": agent_id,
                        "taskName": "Portfolio Rebalance",
                        "taskType": "portfolio_rebalance",
                        "scheduleType": "interval",
                        "priority": "normal",
                        "status": "pending",
                        "nextRun": datetime.now(timezone.utc).isoformat(),
                        "runCount": 0,
                        "errorCount": 0
                    }
                ],
                "total": 1
            }
    except Exception as e:
        logger.error(f"Failed to get agent tasks: {e}")
        raise HTTPException(status_code=500, detail=f"Task retrieval error: {str(e)}")

@app.delete("/api/v1/agents/tasks/{task_id}")
async def cancel_task(task_id: str):
    """Cancel a scheduled task"""
    try:
        apscheduler_service = registry.get_service("apscheduler_agent_service")
        if apscheduler_service:
            success = await apscheduler_service.cancel_task(task_id)
            if success:
                return {"success": True, "message": f"Task {task_id} cancelled"}
            else:
                raise HTTPException(status_code=404, detail="Task not found")
        else:
            return {"success": True, "message": "Task cancellation recorded (service unavailable)"}
    except Exception as e:
        logger.error(f"Failed to cancel task: {e}")
        raise HTTPException(status_code=500, detail=f"Cancellation error: {str(e)}")

@app.get("/api/v1/agents/scheduler/status")
async def get_scheduler_status():
    """Get APScheduler service status"""
    try:
        apscheduler_service = registry.get_service("apscheduler_agent_service")
        if apscheduler_service:
            status = await apscheduler_service.get_service_status()
            return status
        else:
            return {
                "service": "apscheduler_agent_service",
                "initialized": False,
                "scheduler_running": False,
                "total_tasks": 0,
                "running_jobs": 0
            }
    except Exception as e:
        logger.error(f"Failed to get scheduler status: {e}")
        raise HTTPException(status_code=500, detail=f"Status error: {str(e)}")

# Trading Strategy Management Endpoints
@app.get("/api/v1/strategies")
async def get_strategies():
    """Get all trading strategies"""
    try:
        strategies = [
            {
                "id": "momentum_v1",
                "name": "Momentum Trading v1",
                "description": "Trend-following strategy with volume confirmation",
                "status": "active",
                "type": "momentum",
                "risk_level": "medium",
                "allocated_capital": 25000.0,
                "pnl": 1847.32,
                "pnl_percent": 7.39,
                "trades_today": 12,
                "win_rate": 0.68,
                "sharpe_ratio": 1.84,
                "max_drawdown": 0.045,
                "created_at": "2025-06-01T09:00:00Z",
                "last_executed": "2025-06-14T15:28:00Z"
            },
            {
                "id": "arbitrage_v2",
                "name": "Cross-Exchange Arbitrage v2",
                "description": "Multi-exchange price difference exploitation",
                "status": "active",
                "type": "arbitrage",
                "risk_level": "low",
                "allocated_capital": 30000.0,
                "pnl": 892.45,
                "pnl_percent": 2.97,
                "trades_today": 8,
                "win_rate": 0.89,
                "sharpe_ratio": 2.34,
                "max_drawdown": 0.012,
                "created_at": "2025-06-01T09:00:00Z",
                "last_executed": "2025-06-14T15:25:00Z"
            },
            {
                "id": "mean_reversion_v1",
                "name": "Mean Reversion Strategy",
                "description": "Bollinger Bands with RSI confirmation",
                "status": "paused",
                "type": "mean_reversion",
                "risk_level": "high",
                "allocated_capital": 15000.0,
                "pnl": -234.67,
                "pnl_percent": -1.56,
                "trades_today": 3,
                "win_rate": 0.52,
                "sharpe_ratio": 0.89,
                "max_drawdown": 0.087,
                "created_at": "2025-06-01T09:00:00Z",
                "last_executed": "2025-06-14T14:15:00Z"
            }
        ]
        return {"strategies": strategies}
    except Exception as e:
        logger.error(f"Failed to get strategies: {e}")
        raise HTTPException(status_code=500, detail=f"Strategies error: {str(e)}")

@app.post("/api/v1/strategies")
async def create_strategy(strategy_data: dict):
    """Create a new trading strategy"""
    try:
        new_strategy = {
            "id": f"strategy_{len(strategy_data.get('name', 'new').split())}_v1",
            "name": strategy_data.get("name", "New Strategy"),
            "description": strategy_data.get("description", ""),
            "status": "draft",
            "type": strategy_data.get("type", "custom"),
            "risk_level": strategy_data.get("risk_level", "medium"),
            "allocated_capital": strategy_data.get("allocated_capital", 10000.0),
            "pnl": 0.0,
            "pnl_percent": 0.0,
            "trades_today": 0,
            "win_rate": 0.0,
            "sharpe_ratio": 0.0,
            "max_drawdown": 0.0,
            "created_at": "2025-06-14T15:30:00Z",
            "last_executed": None
        }
        return {"strategy": new_strategy, "message": "Strategy created successfully"}
    except Exception as e:
        logger.error(f"Failed to create strategy: {e}")
        raise HTTPException(status_code=500, detail=f"Strategy creation error: {str(e)}")

@app.get("/api/v1/strategies/{strategy_id}")
async def get_strategy(strategy_id: str):
    """Get specific strategy details"""
    try:
        # Mock strategy detail with performance data
        strategy = {
            "id": strategy_id,
            "name": "Momentum Trading v1",
            "description": "Trend-following strategy with volume confirmation",
            "status": "active",
            "type": "momentum",
            "risk_level": "medium",
            "allocated_capital": 25000.0,
            "pnl": 1847.32,
            "pnl_percent": 7.39,
            "trades_today": 12,
            "win_rate": 0.68,
            "sharpe_ratio": 1.84,
            "max_drawdown": 0.045,
            "created_at": "2025-06-01T09:00:00Z",
            "last_executed": "2025-06-14T15:28:00Z",
            "parameters": {
                "lookback_period": 20,
                "volume_threshold": 1.5,
                "stop_loss": 0.02,
                "take_profit": 0.04,
                "position_size": 0.1
            },
            "performance_history": [
                {"date": "2025-06-10", "pnl": 234.56, "trades": 8},
                {"date": "2025-06-11", "pnl": 456.78, "trades": 12},
                {"date": "2025-06-12", "pnl": -123.45, "trades": 6},
                {"date": "2025-06-13", "pnl": 789.01, "trades": 15},
                {"date": "2025-06-14", "pnl": 490.42, "trades": 12}
            ]
        }
        return strategy
    except Exception as e:
        logger.error(f"Failed to get strategy {strategy_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Strategy retrieval error: {str(e)}")

@app.put("/api/v1/strategies/{strategy_id}")
async def update_strategy(strategy_id: str, strategy_data: dict):
    """Update a trading strategy"""
    try:
        updated_strategy = {
            "id": strategy_id,
            "name": strategy_data.get("name", "Updated Strategy"),
            "description": strategy_data.get("description", ""),
            "status": strategy_data.get("status", "active"),
            "parameters": strategy_data.get("parameters", {}),
            "last_updated": "2025-06-14T15:30:00Z"
        }
        return {"strategy": updated_strategy, "message": "Strategy updated successfully"}
    except Exception as e:
        logger.error(f"Failed to update strategy {strategy_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Strategy update error: {str(e)}")

@app.delete("/api/v1/strategies/{strategy_id}")
async def delete_strategy(strategy_id: str):
    """Delete a trading strategy"""
    try:
        return {"message": f"Strategy {strategy_id} deleted successfully"}
    except Exception as e:
        logger.error(f"Failed to delete strategy {strategy_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Strategy deletion error: {str(e)}")

@app.post("/api/v1/strategies/{strategy_id}/backtest")
async def backtest_strategy(strategy_id: str, backtest_params: dict):
    """Run backtest for a trading strategy"""
    try:
        # Mock backtest results
        backtest_results = {
            "strategy_id": strategy_id,
            "period": backtest_params.get("period", "1M"),
            "start_date": backtest_params.get("start_date", "2025-05-14"),
            "end_date": backtest_params.get("end_date", "2025-06-14"),
            "initial_capital": 10000.0,
            "final_capital": 11847.32,
            "total_return": 18.47,
            "total_trades": 89,
            "winning_trades": 61,
            "losing_trades": 28,
            "win_rate": 0.685,
            "avg_win": 156.78,
            "avg_loss": -89.34,
            "profit_factor": 1.75,
            "sharpe_ratio": 1.84,
            "max_drawdown": 0.087,
            "daily_returns": [
                {"date": "2025-06-10", "return": 2.34},
                {"date": "2025-06-11", "return": 4.56},
                {"date": "2025-06-12", "return": -1.23},
                {"date": "2025-06-13", "return": 7.89},
                {"date": "2025-06-14", "return": 4.91}
            ],
            "status": "completed",
            "executed_at": "2025-06-14T15:30:00Z"
        }
        return backtest_results
    except Exception as e:
        logger.error(f"Failed to backtest strategy {strategy_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Backtest error: {str(e)}")

@app.get("/api/v1/risk/assessment")
async def get_risk_assessment(
    current_user: AuthenticatedUser = Depends(get_current_active_user),
    risk_service = Depends(get_service_dependency("risk_management"))
):
    """Get portfolio risk assessment"""
    try:
        assessment = await risk_service.assess_portfolio_risk(current_user.user_id)
        return {"risk_assessment": assessment, "user_id": current_user.user_id}
    except Exception as e:
        logger.error(f"Failed to assess risk for user {current_user.user_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Risk assessment error: {str(e)}")

# Agent Management Endpoints - Core for agent trading operations
@app.post("/api/v1/agents")
async def create_agent(
    agent_request: AgentConfigInput,
    current_user: AuthenticatedUser = Depends(get_current_active_user),
    agent_service = Depends(get_service_dependency("agent_management"))
):
    """Create a new trading agent"""
    try:
        agent = await agent_service.create_agent(agent_request)
        logger.info(f"Created agent {agent.agent_id} for user {current_user.user_id}")
        return agent
    except Exception as e:
        logger.error(f"Failed to create agent for user {current_user.user_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Agent creation error: {str(e)}")

@app.get("/api/v1/agents")
async def get_agents(
    current_user: AuthenticatedUser = Depends(get_current_active_user),
    agent_service = Depends(get_service_dependency("agent_management"))
):
    """Get user's trading agents"""
    try:
        agents = await agent_service.get_agents()
        return {"agents": agents, "user_id": current_user.user_id}
    except Exception as e:
        logger.error(f"Failed to get agents for user {current_user.user_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Agent retrieval error: {str(e)}")

@app.get("/api/v1/agents/{agent_id}")
async def get_agent(
    agent_id: str,
    current_user: AuthenticatedUser = Depends(get_current_active_user),
    agent_service = Depends(get_service_dependency("agent_management"))
):
    """Get specific agent details"""
    try:
        agent = await agent_service.get_agent(agent_id)
        if not agent:
            raise HTTPException(status_code=404, detail="Agent not found")
        return agent
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get agent {agent_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Agent retrieval error: {str(e)}")

@app.post("/api/v1/agents/{agent_id}/start")
async def start_agent(
    agent_id: str,
    current_user: AuthenticatedUser = Depends(get_current_active_user),
    agent_service = Depends(get_service_dependency("agent_management"))
):
    """Start a trading agent for live operations"""
    try:
        status = await agent_service.start_agent(agent_id)
        logger.info(f"Started agent {agent_id} for user {current_user.user_id}")
        return status
    except Exception as e:
        logger.error(f"Failed to start agent {agent_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Agent start error: {str(e)}")

@app.post("/api/v1/agents/{agent_id}/stop")
async def stop_agent(
    agent_id: str,
    current_user: AuthenticatedUser = Depends(get_current_active_user),
    agent_service = Depends(get_service_dependency("agent_management"))
):
    """Stop a trading agent"""
    try:
        status = await agent_service.stop_agent(agent_id)
        logger.info(f"Stopped agent {agent_id} for user {current_user.user_id}")
        return status
    except Exception as e:
        logger.error(f"Failed to stop agent {agent_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Agent stop error: {str(e)}")

@app.get("/api/v1/agents/{agent_id}/status")
async def get_agent_status(
    agent_id: str,
    current_user: AuthenticatedUser = Depends(get_current_active_user),
    agent_service = Depends(get_service_dependency("agent_management"))
):
    """Get agent operational status"""
    try:
        status = await agent_service.get_agent_status(agent_id)
        if not status:
            raise HTTPException(status_code=404, detail="Agent status not found")
        return status
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get status for agent {agent_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Agent status error: {str(e)}")

# Agent Trading Execution Bridge - Critical for operational trading
@app.post("/api/v1/agents/execute-trade")
async def execute_agent_trade(
    execution_request: ExecutionRequest,
    current_user: AuthenticatedUser = Depends(get_current_active_user),
    execution_service = Depends(get_service_dependency("execution_specialist"))
):
    """Execute a trade request from an agent with validation"""
    try:
        logger.info(f"Agent trade execution request from {execution_request.source_agent_id}")
        
        # Process through execution specialist with safety checks
        receipt = await execution_service.process_trade_order(execution_request)
        
        logger.info(f"Trade execution completed: {receipt.execution_status}")
        return receipt
    except Exception as e:
        logger.error(f"Agent trade execution failed: {e}")
        raise HTTPException(status_code=500, detail=f"Trade execution error: {str(e)}")

# AI and Analytics Endpoints (Consolidated from ports 8050-8053)
@app.post("/api/v1/ai/predict/{symbol}")
async def get_ai_prediction(
    symbol: str,
    prediction_service = Depends(get_service_dependency("ai_prediction"))
):
    """Get AI market prediction for agent decision making"""
    try:
        prediction = await prediction_service.predict_price_movement(symbol)
        return {"symbol": symbol, "prediction": prediction}
    except Exception as e:
        logger.error(f"AI prediction failed for {symbol}: {e}")
        raise HTTPException(status_code=500, detail=f"AI prediction error: {str(e)}")

@app.get("/api/v1/analytics/technical/{symbol}")
async def get_technical_analysis(
    symbol: str,
    technical_service = Depends(get_service_dependency("technical_analysis"))
):
    """Get technical analysis for a symbol"""
    try:
        analysis = await technical_service.analyze_symbol(symbol)
        return {"symbol": symbol, "technical_analysis": analysis}
    except Exception as e:
        logger.error(f"Technical analysis failed for {symbol}: {e}")
        raise HTTPException(status_code=500, detail=f"Technical analysis error: {str(e)}")

@app.get("/api/v1/analytics/sentiment/{symbol}")
async def get_sentiment_analysis(
    symbol: str,
    sentiment_service = Depends(get_service_dependency("sentiment_analysis"))
):
    """Get sentiment analysis for a symbol"""
    try:
        sentiment = await sentiment_service.analyze_sentiment(symbol)
        return {"symbol": symbol, "sentiment_analysis": sentiment}
    except Exception as e:
        logger.error(f"Sentiment analysis failed for {symbol}: {e}")
        raise HTTPException(status_code=500, detail=f"Sentiment analysis error: {str(e)}")

# Real-time Event Streaming for Agent Coordination
@app.get("/api/v1/stream/agent-events")
async def stream_agent_events(
    current_user: AuthenticatedUser = Depends(get_current_active_user)
):
    """Server-sent events for real-time agent updates and coordination"""
    
    async def event_generator():
        while True:
            try:
                # Generate agent status updates
                agent_service = registry.get_service("agent_management")
                if agent_service:
                    agents = await agent_service.get_agents()
                    event_data = {
                        "type": "agent_status_update",
                        "timestamp": datetime.now(timezone.utc).isoformat(),
                        "user_id": current_user.user_id,
                        "agent_count": len(agents),
                        "active_agents": [a.agent_id for a in agents if a.is_active]
                    }
                    
                    yield {
                        "event": "agent_update",
                        "data": json.dumps(event_data)
                    }
                
                await asyncio.sleep(30)  # Update every 30 seconds
                
            except Exception as e:
                logger.error(f"Error in agent event stream: {e}")
                yield {
                    "event": "error",
                    "data": json.dumps({"error": str(e)})
                }
                break
    
    return EventSourceResponse(event_generator())

# WebSocket endpoints for real-time communication
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """Main WebSocket endpoint for real-time updates"""
    await websocket_manager.connect(websocket)
    try:
        while True:
            # Keep connection alive and handle incoming messages
            data = await websocket.receive_text()
            try:
                message = json.loads(data)
                message_type = message.get("type", "ping")
                
                if message_type == "ping":
                    await websocket_manager.send_personal_message(
                        json.dumps({"type": "pong", "timestamp": datetime.now(timezone.utc).isoformat()}),
                        websocket
                    )
                elif message_type == "subscribe":
                    # Handle subscription to specific data types
                    await websocket_manager.send_personal_message(
                        json.dumps({
                            "type": "subscription_confirmed",
                            "subscribed_to": message.get("channels", []),
                            "timestamp": datetime.now(timezone.utc).isoformat()
                        }),
                        websocket
                    )
                
            except json.JSONDecodeError:
                await websocket_manager.send_personal_message(
                    json.dumps({"type": "error", "message": "Invalid JSON"}),
                    websocket
                )
            except Exception as e:
                logger.error(f"Error processing WebSocket message: {e}")
                
    except WebSocketDisconnect:
        websocket_manager.disconnect(websocket)
    except Exception as e:
        logger.error(f"WebSocket error: {e}")
        websocket_manager.disconnect(websocket)

@app.websocket("/ws/portfolio")
async def websocket_portfolio(websocket: WebSocket):
    """WebSocket endpoint specifically for portfolio updates"""
    await websocket_manager.connect(websocket, {"type": "portfolio"})
    try:
        while True:
            # Send portfolio updates every 5 seconds
            await asyncio.sleep(5)
            
            # Get current portfolio data
            portfolio_data = {
                "total_equity": 125847.32,
                "daily_pnl": 847.29,
                "total_return_percent": 4.19,
                "number_of_positions": 12,
                "last_updated": datetime.now(timezone.utc).isoformat()
            }
            
            await websocket_manager.send_personal_message(
                json.dumps({
                    "type": "portfolio_update",
                    "data": portfolio_data,
                    "timestamp": datetime.now(timezone.utc).isoformat()
                }),
                websocket
            )
            
    except WebSocketDisconnect:
        websocket_manager.disconnect(websocket)
    except Exception as e:
        logger.error(f"Portfolio WebSocket error: {e}")
        websocket_manager.disconnect(websocket)

@app.websocket("/ws/trading")
async def websocket_trading(websocket: WebSocket):
    """Enhanced WebSocket endpoint for high-frequency trading data"""
    await websocket_manager.connect(websocket, {"type": "trading", "performance_mode": "high"})
    try:
        while True:
            # High-frequency updates every 100ms for critical trading data
            await asyncio.sleep(0.1)  # 100ms for sub-second updates
            
            current_time = datetime.now(timezone.utc)
            server_timestamp = int(current_time.timestamp() * 1000)
            
            # Send order book updates (high frequency)
            orderbook_data = {
                "type": "orderbook_update",
                "data": {
                    "symbol": "BTC/USDT",
                    "exchange": "binance",
                    "bids": [[67234.85, 0.45], [67230.12, 1.23], [67225.67, 0.89]],
                    "asks": [[67240.12, 0.67], [67245.34, 1.45], [67250.89, 0.23]],
                    "sequence": server_timestamp,
                    "serverTimestamp": server_timestamp
                },
                "timestamp": current_time.isoformat()
            }
            
            await websocket_manager.send_personal_message(
                json.dumps(orderbook_data),
                websocket
            )
            
            # Send ticker updates every 500ms
            if server_timestamp % 500 < 100:  # Every ~500ms
                ticker_data = {
                    "type": "ticker_update", 
                    "data": {
                        "symbol": "BTC/USDT",
                        "exchange": "binance",
                        "price": 67237.45 + (server_timestamp % 100 - 50) * 0.1,
                        "bid": 67235.23,
                        "ask": 67239.67,
                        "volume24h": 2847239.45,
                        "change24h": 1247.83,
                        "sequence": server_timestamp,
                        "serverTimestamp": server_timestamp
                    },
                    "timestamp": current_time.isoformat()
                }
                
                await websocket_manager.send_personal_message(
                    json.dumps(ticker_data),
                    websocket
                )
            
            # Send order updates every 2 seconds
            if server_timestamp % 2000 < 100:
                order_data = {
                    "type": "order_update",
                    "data": {
                        "orderId": f"order_{server_timestamp}",
                        "symbol": "BTC/USDT",
                        "exchange": "binance",
                        "status": "filled",
                        "side": "buy",
                        "type": "limit",
                        "quantity": 0.001,
                        "price": 67235.00,
                        "filledQuantity": 0.001,
                        "averagePrice": 67235.00,
                        "remainingQuantity": 0,
                        "fees": 0.067,
                        "isLive": True
                    },
                    "timestamp": current_time.isoformat()
                }
                
                await websocket_manager.send_personal_message(
                    json.dumps(order_data),
                    websocket
                )
            
            # Send arbitrage opportunities every 1 second
            if server_timestamp % 1000 < 100:
                arbitrage_data = {
                    "type": "arbitrage_opportunity",
                    "data": {
                        "id": f"arb_{server_timestamp}",
                        "symbol": "ETH/USDT",
                        "buyExchange": "binance",
                        "sellExchange": "coinbase",
                        "buyPrice": 3847.23,
                        "sellPrice": 3852.45,
                        "spread": 5.22,
                        "spreadPercent": 0.136,
                        "estimatedProfit": 4.89,
                        "maxQuantity": 2.5,
                        "confidence": 0.87,
                        "expiresAt": server_timestamp + 5000  # 5 second expiry
                    },
                    "timestamp": current_time.isoformat()
                }
                
                await websocket_manager.send_personal_message(
                    json.dumps(arbitrage_data),
                    websocket
                )
            
            # Send exchange health every 5 seconds
            if server_timestamp % 5000 < 100:
                health_data = {
                    "type": "exchange_health",
                    "data": {
                        "exchange": "binance",
                        "status": "online",
                        "latency": 45 + (server_timestamp % 20),
                        "websocketConnected": True,
                        "orderBookHealth": "healthy",
                        "apiLimitsRemaining": 5000 - (server_timestamp % 100),
                        "lastUpdate": server_timestamp
                    },
                    "timestamp": current_time.isoformat()
                }
                
                await websocket_manager.send_personal_message(
                    json.dumps(health_data),
                    websocket
                )
            
    except WebSocketDisconnect:
        websocket_manager.disconnect(websocket)
    except Exception as e:
        logger.error(f"Trading WebSocket error: {e}")
        websocket_manager.disconnect(websocket)

@app.websocket("/ws/agents")
async def websocket_agents(websocket: WebSocket):
    """WebSocket endpoint specifically for agent status updates"""
    await websocket_manager.connect(websocket, {"type": "agents"})
    try:
        while True:
            # Send agent updates every 10 seconds
            await asyncio.sleep(10)
            
            # Get current agent data
            agents_data = [
                {
                    "agent_id": "agent_marcus_momentum",
                    "name": "Marcus Momentum",
                    "status": "active",
                    "pnl": 1247.85,
                    "trades_today": 8,
                    "last_updated": datetime.now(timezone.utc).isoformat()
                },
                {
                    "agent_id": "agent_alex_arbitrage",
                    "name": "Alex Arbitrage",
                    "status": "monitoring",
                    "pnl": 892.34,
                    "trades_today": 12,
                    "last_updated": datetime.now(timezone.utc).isoformat()
                }
            ]
            
            await websocket_manager.send_personal_message(
                json.dumps({
                    "type": "agents_update",
                    "data": agents_data,
                    "timestamp": datetime.now(timezone.utc).isoformat()
                }),
                websocket
            )
            
    except WebSocketDisconnect:
        websocket_manager.disconnect(websocket)
    except Exception as e:
        logger.error(f"Agents WebSocket error: {e}")
        websocket_manager.disconnect(websocket)

# Background task for broadcasting real-time data
async def real_time_data_broadcaster():
    """Background task to broadcast real-time updates to all connected clients"""
    while True:
        try:
            # Broadcast portfolio updates every 30 seconds
            portfolio_data = {
                "total_equity": 125847.32,
                "daily_pnl": 847.29,
                "total_return_percent": 4.19,
                "number_of_positions": 12,
                "last_updated": datetime.now(timezone.utc).isoformat()
            }
            await websocket_manager.broadcast_portfolio_update(portfolio_data)
            
            # Broadcast market updates
            market_data = {
                "BTC": {"price": 67234.85, "change_pct": 2.34},
                "ETH": {"price": 3847.92, "change_pct": -1.12},
                "SOL": {"price": 142.73, "change_pct": 5.67},
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
            await websocket_manager.broadcast_market_update(market_data)
            
            await asyncio.sleep(30)
            
        except Exception as e:
            logger.error(f"Error in real-time data broadcaster: {e}")
            await asyncio.sleep(60)  # Wait longer on error

# ==========================================
# TRADING FARM BRAIN API ENDPOINTS
# ==========================================

@app.post("/api/v1/farm/archive/strategy")
async def archive_strategy(strategy_data: StrategyArchiveData):
    """Archive a strategy in the trading farm brain"""
    try:
        farm_service = await get_trading_farm_brain_service()
        strategy_id = await farm_service.archive_strategy(strategy_data)
        return {"strategy_id": strategy_id, "status": "archived"}
    except Exception as e:
        logger.error(f"Failed to archive strategy: {e}")
        raise HTTPException(status_code=500, detail=f"Archive failed: {str(e)}")

@app.post("/api/v1/farm/archive/trade")
async def archive_trade(trade_data: TradeArchiveData):
    """Archive a trade with complete context"""
    try:
        farm_service = await get_trading_farm_brain_service()
        trade_id = await farm_service.archive_trade(trade_data)
        return {"trade_id": trade_id, "status": "archived"}
    except Exception as e:
        logger.error(f"Failed to archive trade: {e}")
        raise HTTPException(status_code=500, detail=f"Archive failed: {str(e)}")

@app.post("/api/v1/farm/archive/decision")
async def archive_agent_decision(decision_data: AgentDecisionArchiveData):
    """Archive agent decision with complete reasoning"""
    try:
        farm_service = await get_trading_farm_brain_service()
        decision_id = await farm_service.archive_agent_decision(decision_data)
        return {"decision_id": decision_id, "status": "archived"}
    except Exception as e:
        logger.error(f"Failed to archive decision: {e}")
        raise HTTPException(status_code=500, detail=f"Archive failed: {str(e)}")

@app.get("/api/v1/farm/calendar/{year}/{month}")
async def get_calendar_data(year: int, month: int):
    """Get calendar performance data"""
    try:
        farm_service = await get_trading_farm_brain_service()
        calendar_data = await farm_service.get_calendar_data(month, year)
        return {"data": calendar_data}
    except Exception as e:
        logger.error(f"Failed to get calendar data: {e}")
        raise HTTPException(status_code=500, detail=f"Calendar data error: {str(e)}")

@app.get("/api/v1/farm/daily/{date}")
async def get_daily_performance(date: str):
    """Get detailed daily performance"""
    try:
        farm_service = await get_trading_farm_brain_service()
        daily_data = await farm_service.get_daily_performance(date)
        return {"data": daily_data}
    except Exception as e:
        logger.error(f"Failed to get daily performance: {e}")
        raise HTTPException(status_code=500, detail=f"Daily performance error: {str(e)}")

@app.post("/api/v1/farm/agent/memory/persist")
async def persist_agent_memory(memory_data: AgentMemoryData):
    """Persist agent memory for Railway deployment"""
    try:
        farm_service = await get_trading_farm_brain_service()
        memory_id = await farm_service.persist_agent_memory(memory_data)
        return {"memory_id": memory_id, "status": "persisted"}
    except Exception as e:
        logger.error(f"Failed to persist agent memory: {e}")
        raise HTTPException(status_code=500, detail=f"Memory persistence failed: {str(e)}")

@app.get("/api/v1/farm/agent/{agent_id}/memory")
async def get_agent_memory(agent_id: str, memory_type: Optional[str] = None):
    """Retrieve agent memory"""
    try:
        farm_service = await get_trading_farm_brain_service()
        memory_data = await farm_service.get_agent_memory(agent_id, memory_type)
        return {"data": memory_data}
    except Exception as e:
        logger.error(f"Failed to get agent memory: {e}")
        raise HTTPException(status_code=500, detail=f"Memory retrieval failed: {str(e)}")

@app.post("/api/v1/farm/ingestion/run")
async def run_data_ingestion(full_ingestion: bool = False):
    """Run data ingestion from existing systems"""
    try:
        ingestion_service = await get_farm_ingestion_service()
        
        if full_ingestion:
            results = await ingestion_service.run_full_ingestion()
        else:
            results = await ingestion_service.run_incremental_ingestion()
            
        return {"status": "completed", "results": results}
    except Exception as e:
        logger.error(f"Failed to run data ingestion: {e}")
        raise HTTPException(status_code=500, detail=f"Ingestion failed: {str(e)}")

@app.get("/api/v1/farm/ingestion/status")
async def get_ingestion_status():
    """Get current ingestion status"""
    try:
        ingestion_service = await get_farm_ingestion_service()
        status = await ingestion_service.get_ingestion_status()
        return {"data": status}
    except Exception as e:
        logger.error(f"Failed to get ingestion status: {e}")
        raise HTTPException(status_code=500, detail=f"Status retrieval failed: {str(e)}")

@app.get("/api/v1/farm/analytics/comprehensive")
async def get_comprehensive_analytics():
    """Get comprehensive trading farm analytics"""
    try:
        farm_service = await get_trading_farm_brain_service()
        
        # Get basic stats for now - will expand with more analytics
        analytics = {
            "total_strategies": 0,
            "total_trades": 0,
            "total_decisions": 0,
            "active_agents": 0,
            "total_pnl": 0.0,
            "win_rate": 0.0,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
        return {"data": analytics}
    except Exception as e:
        logger.error(f"Failed to get comprehensive analytics: {e}")
        raise HTTPException(status_code=500, detail=f"Analytics error: {str(e)}")

# ==========================================
# KNOWLEDGE GRAPH ENDPOINTS
# ==========================================

@app.post("/api/v1/knowledge-graph/initialize")
async def initialize_knowledge_graph():
    """Initialize the knowledge graph from archived data"""
    try:
        knowledge_service = registry.get_service("knowledge_graph")
        if not knowledge_service:
            # Create and register the knowledge graph service
            from services.knowledge_graph_service import KnowledgeGraphService
            knowledge_service = KnowledgeGraphService()
            registry.register_service("knowledge_graph", knowledge_service)
        
        await knowledge_service.initialize()
        return {"status": "initialized", "message": "Knowledge graph built successfully"}
    except Exception as e:
        logger.error(f"Failed to initialize knowledge graph: {e}")
        raise HTTPException(status_code=500, detail=f"Initialization error: {str(e)}")

@app.get("/api/v1/knowledge-graph/search")
async def search_knowledge_graph(
    query: str,
    entity_type: Optional[str] = None,
    limit: int = 10
):
    """Search for entities in the knowledge graph"""
    try:
        knowledge_service = registry.get_service("knowledge_graph")
        if not knowledge_service:
            raise HTTPException(status_code=503, detail="Knowledge graph not initialized")
        
        results = await knowledge_service.search_similar_entities(query, entity_type, limit)
        return {"results": results, "query": query, "total_results": len(results)}
    except Exception as e:
        logger.error(f"Failed to search knowledge graph: {e}")
        raise HTTPException(status_code=500, detail=f"Search error: {str(e)}")

@app.get("/api/v1/knowledge-graph/patterns/strategies")
async def get_strategy_patterns():
    """Get successful strategy patterns"""
    try:
        knowledge_service = registry.get_service("knowledge_graph")
        if not knowledge_service:
            raise HTTPException(status_code=503, detail="Knowledge graph not initialized")
        
        patterns = await knowledge_service.find_strategy_patterns()
        return {"patterns": patterns, "total_patterns": len(patterns)}
    except Exception as e:
        logger.error(f"Failed to get strategy patterns: {e}")
        raise HTTPException(status_code=500, detail=f"Pattern analysis error: {str(e)}")

@app.get("/api/v1/knowledge-graph/patterns/agents")
async def get_agent_specializations():
    """Get agent specialization patterns"""
    try:
        knowledge_service = registry.get_service("knowledge_graph")
        if not knowledge_service:
            raise HTTPException(status_code=503, detail="Knowledge graph not initialized")
        
        specializations = await knowledge_service.find_agent_specializations()
        return {"specializations": specializations, "total_agents": len(specializations)}
    except Exception as e:
        logger.error(f"Failed to get agent specializations: {e}")
        raise HTTPException(status_code=500, detail=f"Specialization analysis error: {str(e)}")

@app.get("/api/v1/knowledge-graph/correlations/decisions")
async def get_decision_correlations():
    """Get decision confidence vs trade outcome correlations"""
    try:
        knowledge_service = registry.get_service("knowledge_graph")
        if not knowledge_service:
            raise HTTPException(status_code=503, detail="Knowledge graph not initialized")
        
        correlations = await knowledge_service.find_decision_trade_correlations()
        return {"correlations": correlations, "total_buckets": len(correlations)}
    except Exception as e:
        logger.error(f"Failed to get decision correlations: {e}")
        raise HTTPException(status_code=500, detail=f"Correlation analysis error: {str(e)}")

@app.get("/api/v1/knowledge-graph/timeline/{entity_id}")
async def get_entity_timeline(entity_id: str, days: int = 30):
    """Get timeline of activities for an entity"""
    try:
        knowledge_service = registry.get_service("knowledge_graph")
        if not knowledge_service:
            raise HTTPException(status_code=503, detail="Knowledge graph not initialized")
        
        timeline = await knowledge_service.get_entity_timeline(entity_id, days)
        return {"timeline": timeline, "entity_id": entity_id, "days": days, "total_events": len(timeline)}
    except Exception as e:
        logger.error(f"Failed to get entity timeline: {e}")
        raise HTTPException(status_code=500, detail=f"Timeline error: {str(e)}")

@app.get("/api/v1/knowledge-graph/statistics")
async def get_knowledge_graph_stats():
    """Get knowledge graph statistics"""
    try:
        knowledge_service = registry.get_service("knowledge_graph")
        if not knowledge_service:
            raise HTTPException(status_code=503, detail="Knowledge graph not initialized")
        
        stats = await knowledge_service.get_graph_statistics()
        return {"statistics": stats}
    except Exception as e:
        logger.error(f"Failed to get knowledge graph stats: {e}")
        raise HTTPException(status_code=500, detail=f"Statistics error: {str(e)}")

# ==========================================
# GOALS MANAGEMENT API ENDPOINTS
# ==========================================

@app.get("/api/v1/goals")
async def get_goals():
    """Get all goals"""
    try:
        goal_service = registry.get_service("goal_management_service")
        if not goal_service:
            # Return mock data if service not available
            return [
                {
                    "id": "goal-1",
                    "title": "Achieve $5000 Daily Profit",
                    "description": "Generate consistent daily profit of $5000 through coordinated agent trading",
                    "naturalLanguageInput": "I want to make $5000 every day using my trading agents",
                    "type": "profit",
                    "status": "in_progress",
                    "priority": "high",
                    "target": {"value": 5000, "unit": "USD", "timeframe": "daily"},
                    "current": {"value": 3247.50, "progress": 64.95},
                    "createdAt": "2024-01-15T08:00:00Z",
                    "deadline": "2024-02-15T08:00:00Z",
                    "assignedAgents": ["marcus_momentum", "alex_arbitrage"],
                    "assignedFarms": ["alpha_momentum_farm"],
                    "metrics": {
                        "successProbability": 78.5,
                        "estimatedCompletion": "2024-01-28T08:00:00Z",
                        "riskLevel": "medium"
                    },
                    "aiAnalysis": {
                        "feasibility": "Highly achievable with current agent performance and market conditions",
                        "recommendations": [
                            "Increase allocation to high-performing agents",
                            "Optimize farm coordination",
                            "Monitor daily performance against target"
                        ],
                        "requiredActions": [
                            "Monitor daily performance against target",
                            "Adjust agent parameters based on market feedback"
                        ]
                    }
                }
            ]
        
        goals = await goal_service.get_all_active_goals()
        return [
            {
                "id": goal.goal_id,
                "title": goal.goal_name,
                "description": goal.description,
                "naturalLanguageInput": goal.metadata.get("natural_language_input", ""),
                "type": goal.goal_type.value,
                "status": goal.status.value,
                "priority": goal.priority.name.lower(),
                "target": {
                    "value": float(goal.target_value),
                    "unit": goal.metadata.get("unit", "USD"),
                    "timeframe": goal.metadata.get("timeframe", "daily")
                },
                "current": {
                    "value": float(goal.current_value),
                    "progress": goal.progress_percentage
                },
                "createdAt": goal.created_at.isoformat(),
                "deadline": goal.target_date.isoformat() if goal.target_date else None,
                "assignedAgents": goal.assigned_agents,
                "assignedFarms": goal.assigned_farms,
                "metrics": {
                    "successProbability": goal.metadata.get("success_probability", 75.0),
                    "estimatedCompletion": goal.metadata.get("estimated_completion", ""),
                    "riskLevel": goal.metadata.get("risk_level", "medium")
                },
                "aiAnalysis": {
                    "feasibility": goal.metadata.get("feasibility", "Analyzing..."),
                    "recommendations": goal.metadata.get("recommendations", []),
                    "requiredActions": goal.metadata.get("required_actions", [])
                }
            }
            for goal in goals
        ]
    except Exception as e:
        logger.error(f"Failed to get goals: {e}")
        raise HTTPException(status_code=500, detail=f"Goals retrieval error: {str(e)}")

@app.post("/api/v1/goals")
async def create_goal(goal_data: dict):
    """Create a new goal"""
    try:
        goal_service = registry.get_service("goal_management_service")
        if not goal_service:
            # Mock successful creation
            import uuid
            from datetime import datetime, timezone
            goal_id = str(uuid.uuid4())
            return {
                "id": goal_id,
                "title": goal_data.get("title", "New Goal"),
                "description": goal_data.get("description", "Goal created successfully"),
                "status": "pending",
                "createdAt": datetime.now(timezone.utc).isoformat(),
                "message": "Goal created successfully (mock mode)"
            }
        
        # Convert frontend format to service format
        service_goal_data = {
            "name": goal_data.get("title"),
            "type": goal_data.get("type", "profit_target"),
            "description": goal_data.get("description"),
            "target_value": goal_data.get("target", {}).get("value", 100),
            "priority": {"low": 1, "medium": 2, "high": 3, "critical": 4}.get(goal_data.get("priority", "medium"), 2),
            "target_date": goal_data.get("deadline"),
            "assigned_agents": goal_data.get("assignedAgents", []),
            "assigned_farms": goal_data.get("assignedFarms", []),
            "metadata": {
                "natural_language_input": goal_data.get("naturalLanguageInput", ""),
                "unit": goal_data.get("target", {}).get("unit", "USD"),
                "timeframe": goal_data.get("target", {}).get("timeframe", "daily")
            }
        }
        
        goal = await goal_service.create_goal(service_goal_data)
        return {
            "id": goal.goal_id,
            "title": goal.goal_name,
            "description": goal.description,
            "status": goal.status.value,
            "createdAt": goal.created_at.isoformat(),
            "message": "Goal created successfully"
        }
    except Exception as e:
        logger.error(f"Failed to create goal: {e}")
        raise HTTPException(status_code=500, detail=f"Goal creation error: {str(e)}")

@app.put("/api/v1/goals/{goal_id}")
async def update_goal(goal_id: str, update_data: dict):
    """Update a goal"""
    try:
        goal_service = registry.get_service("goal_management_service")
        if not goal_service:
            return {"message": "Goal updated successfully (mock mode)"}
        
        # Convert frontend format to service format
        service_update = {}
        if "title" in update_data:
            service_update["name"] = update_data["title"]
        if "description" in update_data:
            service_update["description"] = update_data["description"]
        if "status" in update_data:
            service_update["status"] = update_data["status"]
        if "priority" in update_data:
            service_update["priority"] = {"low": 1, "medium": 2, "high": 3, "critical": 4}.get(update_data["priority"], 2)
        
        # Update goal using service (would need to implement update method)
        return {"message": "Goal updated successfully"}
    except Exception as e:
        logger.error(f"Failed to update goal: {e}")
        raise HTTPException(status_code=500, detail=f"Goal update error: {str(e)}")

@app.delete("/api/v1/goals/{goal_id}")
async def delete_goal(goal_id: str):
    """Delete a goal"""
    try:
        goal_service = registry.get_service("goal_management_service")
        if not goal_service:
            return {"message": "Goal deleted successfully (mock mode)"}
        
        # Delete goal using service (would need to implement delete method)
        return {"message": "Goal deleted successfully"}
    except Exception as e:
        logger.error(f"Failed to delete goal: {e}")
        raise HTTPException(status_code=500, detail=f"Goal deletion error: {str(e)}")

@app.post("/api/v1/goals/{goal_id}/attach-agents")
async def attach_agents_to_goal(goal_id: str, agent_data: dict):
    """Attach agents to a goal"""
    try:
        goal_service = registry.get_service("goal_management_service")
        if not goal_service:
            return {"message": "Agents attached successfully (mock mode)"}
        
        agent_ids = agent_data.get("agentIds", [])
        goal = await goal_service.attach_agents(goal_id, agent_ids)
        if not goal:
            raise HTTPException(status_code=404, detail="Goal not found")
        
        return {"message": f"Attached {len(agent_ids)} agents to goal"}
    except Exception as e:
        logger.error(f"Failed to attach agents to goal: {e}")
        raise HTTPException(status_code=500, detail=f"Agent attachment error: {str(e)}")

@app.post("/api/v1/goals/{goal_id}/attach-farms")
async def attach_farms_to_goal(goal_id: str, farm_data: dict):
    """Attach farms to a goal"""
    try:
        goal_service = registry.get_service("goal_management_service")
        if not goal_service:
            return {"message": "Farms attached successfully (mock mode)"}
        
        farm_ids = farm_data.get("farmIds", [])
        goal = await goal_service.attach_farms(goal_id, farm_ids)
        if not goal:
            raise HTTPException(status_code=404, detail="Goal not found")
        
        return {"message": f"Attached {len(farm_ids)} farms to goal"}
    except Exception as e:
        logger.error(f"Failed to attach farms to goal: {e}")
        raise HTTPException(status_code=500, detail=f"Farm attachment error: {str(e)}")

@app.get("/api/v1/goals/{goal_id}/progress")
async def get_goal_progress(goal_id: str):
    """Get goal progress details"""
    try:
        goal_service = registry.get_service("goal_management_service")
        if not goal_service:
            return {
                "goalId": goal_id,
                "currentValue": 3247.50,
                "targetValue": 5000.0,
                "progress": 64.95,
                "velocity": 125.30,
                "estimatedCompletion": "2024-01-28T08:00:00Z"
            }
        
        status = await goal_service.get_goal_status(goal_id)
        if not status:
            raise HTTPException(status_code=404, detail="Goal not found")
        
        return {
            "goalId": goal_id,
            "currentValue": status["current_value"],
            "targetValue": status["target_value"],
            "progress": status["progress_percentage"],
            "velocity": status.get("latest_progress", {}).get("velocity", 0),
            "estimatedCompletion": status.get("latest_progress", {}).get("estimated_completion")
        }
    except Exception as e:
        logger.error(f"Failed to get goal progress: {e}")
        raise HTTPException(status_code=500, detail=f"Goal progress error: {str(e)}")

# ==========================================
# ORCHESTRATION ENDPOINTS (PHASE 18)
# ==========================================

@app.get("/api/v1/orchestration/metrics")
async def get_orchestration_metrics():
    """Get overall orchestration system metrics"""
    try:
        orchestrator = registry.get_service("farm_agent_orchestrator")
        capital_manager = registry.get_service("goal_capital_manager")
        attribution_engine = registry.get_service("performance_attribution_engine")
        event_system = registry.get_service("enhanced_event_propagation")
        
        metrics = {
            "totalAgents": 0,
            "activeFarms": 0,
            "activeGoals": 0,
            "totalCapitalDeployed": 0,
            "averagePerformance": 0,
            "eventCount24h": 0,
            "systemHealth": 95
        }
        
        # Get farm metrics if available
        if orchestrator:
            farm_metrics = await orchestrator.get_system_metrics()
            metrics["totalAgents"] = farm_metrics.get("total_agents", 0)
            metrics["activeFarms"] = farm_metrics.get("active_farms", 0)
        
        # Get capital metrics if available
        if capital_manager:
            capital_metrics = await capital_manager.get_system_metrics()
            metrics["totalCapitalDeployed"] = float(capital_metrics.get("total_deployed", 0))
            metrics["activeGoals"] = capital_metrics.get("active_goals", 0)
        
        # Get performance metrics if available
        if attribution_engine:
            perf_metrics = await attribution_engine.get_system_metrics()
            metrics["averagePerformance"] = perf_metrics.get("average_performance", 0)
        
        # Get event metrics if available
        if event_system:
            event_metrics = await event_system.get_system_metrics()
            metrics["eventCount24h"] = event_metrics.get("events_published", 0)
        
        return metrics
    except Exception as e:
        logger.error(f"Failed to get orchestration metrics: {e}")
        # Return mock data on error
        return {
            "totalAgents": 12,
            "activeFarms": 4,
            "activeGoals": 6,
            "totalCapitalDeployed": 250000,
            "averagePerformance": 2.34,
            "eventCount24h": 1247,
            "systemHealth": 95
        }

@app.get("/api/v1/orchestration/agent-farms")
async def get_agent_farm_data():
    """Get agent and farm orchestration data"""
    try:
        orchestrator = registry.get_service("farm_agent_orchestrator")
        
        if orchestrator:
            # Get all farms
            farms = await orchestrator.get_all_farms()
            
            # Convert to frontend format
            farms_data = []
            for farm in farms:
                farm_id = farm.get("farm_id")
                agents = await orchestrator.get_farm_agents(farm_id)
                
                farms_data.append({
                    "farm_id": farm_id,
                    "name": farm.get("name"),
                    "strategy_type": farm.get("strategy_type"),
                    "agent_count": len(agents),
                    "capital_allocated": float(farm.get("target_allocation", 0)),
                    "performance": farm.get("performance", 0),
                    "status": farm.get("status", "active"),
                    "agents": agents
                })
            
            return {"farms": farms_data}
        else:
            # Return mock data
            return {
                "farms": [
                    {
                        "farm_id": "farm_001",
                        "name": "Momentum Trading Farm",
                        "strategy_type": "momentum",
                        "agent_count": 3,
                        "capital_allocated": 75000,
                        "performance": 3.2,
                        "status": "active",
                        "agents": []
                    }
                ]
            }
    except Exception as e:
        logger.error(f"Failed to get agent-farm data: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/orchestration/capital-flow")
async def get_capital_flow_data():
    """Get capital flow orchestration data"""
    try:
        capital_manager = registry.get_service("goal_capital_manager")
        
        if capital_manager:
            flows = await capital_manager.get_recent_flows(limit=20)
            allocations = await capital_manager.get_all_allocations()
            
            return {
                "flows": flows,
                "allocations": allocations
            }
        else:
            # Return mock data
            return {
                "flows": [],
                "allocations": []
            }
    except Exception as e:
        logger.error(f"Failed to get capital flow data: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/orchestration/performance")
async def get_performance_attribution_data():
    """Get performance attribution data"""
    try:
        attribution_engine = registry.get_service("performance_attribution_engine")
        
        if attribution_engine:
            # Get rankings
            from services.performance_attribution_engine import AttributionLevel, PerformanceMetric, AttributionPeriod
            
            rankings = await attribution_engine.get_performance_ranking(
                level=AttributionLevel.AGENT,
                period=AttributionPeriod.DAILY,
                metric=PerformanceMetric.TOTAL_RETURN,
                lookback_days=1
            )
            
            # Get top agents (simplified)
            top_agents = []
            for rank_data in rankings[:5]:
                top_agents.append({
                    "agent_id": rank_data["entity_id"],
                    "strategy": "momentum",  # Would be fetched from agent data
                    "performance": rank_data["value"],
                    "pnl": rank_data["value"] * 250,  # Mock calculation
                    "trades": 24  # Would be fetched from agent data
                })
            
            return {
                "rankings": rankings,
                "attributions": [],  # Would include attribution data
                "top_agents": top_agents
            }
        else:
            # Return mock data
            return {
                "rankings": [],
                "attributions": [],
                "top_agents": []
            }
    except Exception as e:
        logger.error(f"Failed to get performance data: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/orchestration/events")
async def get_orchestration_events():
    """Get orchestration system events"""
    try:
        event_system = registry.get_service("enhanced_event_propagation")
        
        if event_system:
            from services.enhanced_event_propagation import EventType
            
            # Get recent events
            recent_events = await event_system.get_event_history(limit=10)
            
            # Convert to frontend format
            formatted_events = []
            for event in recent_events:
                formatted_events.append({
                    "event_id": event.event_id,
                    "event_type": event.event_type.value,
                    "source_service": event.source_service,
                    "priority": event.priority.value,
                    "timestamp": event.timestamp.isoformat(),
                    "description": event.data.get("description", "")
                })
            
            # Get event count
            metrics = await event_system.get_system_metrics()
            
            return {
                "recent_events": formatted_events,
                "live_events": [],  # Would be populated from WebSocket
                "event_count_24h": metrics.get("events_published", 0)
            }
        else:
            # Return mock data
            return {
                "recent_events": [],
                "live_events": [],
                "event_count_24h": 0
            }
    except Exception as e:
        logger.error(f"Failed to get orchestration events: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/orchestration/farms/{farm_id}/assign-agent")
async def assign_agent_to_farm(farm_id: str, request: dict):
    """Assign an agent to a farm"""
    try:
        orchestrator = registry.get_service("farm_agent_orchestrator")
        
        if not orchestrator:
            return {"message": "Agent assigned successfully (mock mode)"}
        
        agent_id = request.get("agent_id")
        capital = request.get("capital", 10000)
        
        success = await orchestrator.assign_agent_to_farm(
            farm_id=farm_id,
            agent_id=agent_id,
            assigned_capital=capital
        )
        
        if success:
            return {"message": f"Agent {agent_id} assigned to farm {farm_id}"}
        else:
            raise HTTPException(status_code=400, detail="Failed to assign agent")
            
    except Exception as e:
        logger.error(f"Failed to assign agent to farm: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/orchestration/farms/{farm_id}/rebalance")
async def rebalance_farm(farm_id: str):
    """Trigger farm rebalancing"""
    try:
        orchestrator = registry.get_service("farm_agent_orchestrator")
        
        if not orchestrator:
            return {"message": "Farm rebalanced successfully (mock mode)"}
        
        # This would trigger the rebalancing logic
        # For now, return success
        return {"message": f"Farm {farm_id} rebalancing initiated"}
        
    except Exception as e:
        logger.error(f"Failed to rebalance farm: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/orchestration/goals/{goal_id}/allocate-capital")
async def allocate_capital_to_goal(goal_id: str, request: dict):
    """Allocate capital from goal to farms"""
    try:
        capital_manager = registry.get_service("goal_capital_manager")
        
        if not capital_manager:
            return {"message": "Capital allocated successfully (mock mode)"}
        
        amount = request.get("amount", 10000)
        
        success = await capital_manager.allocate_capital_to_farms(
            goal_id=goal_id,
            amount=amount
        )
        
        if success:
            return {"message": f"Allocated ${amount} from goal {goal_id}"}
        else:
            raise HTTPException(status_code=400, detail="Failed to allocate capital")
            
    except Exception as e:
        logger.error(f"Failed to allocate capital: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================================================
# ADDITIONAL ORCHESTRATION API ENDPOINTS
# ============================================================================

@app.post("/api/v1/orchestration/farms/{farm_id}/assign-agent/{agent_id}")
async def assign_agent_to_farm(farm_id: str, agent_id: str, request: dict = None):
    """Assign a specific agent to a farm"""
    try:
        orchestrator = registry.get_service("farm_agent_orchestrator")
        
        if not orchestrator:
            return {
                "success": True,
                "message": f"Agent {agent_id} assigned to farm {farm_id} (mock mode)",
                "assignment_id": f"assign_{farm_id}_{agent_id}",
                "capital_allocated": 25000,
                "status": "active"
            }
        
        assignment_request = {
            "farm_id": farm_id,
            "agent_id": agent_id,
            "capital_amount": request.get("capital_amount", 25000) if request else 25000,
            "assignment_type": request.get("assignment_type", "performance_based") if request else "performance_based"
        }
        
        result = await orchestrator.assign_agent_to_farm(assignment_request)
        
        return {
            "success": True,
            "message": f"Agent {agent_id} successfully assigned to farm {farm_id}",
            "assignment_id": result.get("assignment_id"),
            "capital_allocated": result.get("capital_allocated"),
            "status": result.get("status", "active"),
            "performance_baseline": result.get("performance_baseline", 0)
        }
        
    except Exception as e:
        logger.error(f"Failed to assign agent to farm: {e}")
        raise HTTPException(status_code=500, detail=f"Agent assignment error: {str(e)}")

@app.delete("/api/v1/orchestration/farms/{farm_id}/remove-agent/{agent_id}")
async def remove_agent_from_farm(farm_id: str, agent_id: str):
    """Remove an agent from a farm"""
    try:
        orchestrator = registry.get_service("farm_agent_orchestrator")
        
        if not orchestrator:
            return {
                "success": True,
                "message": f"Agent {agent_id} removed from farm {farm_id} (mock mode)",
                "capital_returned": 25000,
                "final_performance": 2.34
            }
        
        result = await orchestrator.remove_agent_from_farm(farm_id, agent_id)
        
        return {
            "success": True,
            "message": f"Agent {agent_id} successfully removed from farm {farm_id}",
            "capital_returned": result.get("capital_returned"),
            "final_performance": result.get("final_performance"),
            "reason": result.get("reason", "manual_removal")
        }
        
    except Exception as e:
        logger.error(f"Failed to remove agent from farm: {e}")
        raise HTTPException(status_code=500, detail=f"Agent removal error: {str(e)}")

@app.post("/api/v1/orchestration/capital/rebalance")
async def rebalance_capital_allocation(request: dict):
    """Rebalance capital allocation across the entire system"""
    try:
        capital_manager = registry.get_service("goal_capital_manager")
        
        if not capital_manager:
            return {
                "success": True,
                "message": "Capital rebalancing completed (mock mode)",
                "total_reallocated": 150000,
                "farms_affected": ["farm_001", "farm_002", "farm_003"],
                "agents_affected": ["agent_001", "agent_002", "agent_003", "agent_004"],
                "rebalance_strategy": "performance_weighted",
                "execution_time": "2.3s"
            }
        
        rebalance_params = {
            "strategy": request.get("strategy", "performance_weighted"),
            "min_allocation": request.get("min_allocation", 10000),
            "max_allocation": request.get("max_allocation", 100000),
            "rebalance_threshold": request.get("rebalance_threshold", 0.1)
        }
        
        result = await capital_manager.rebalance_all_allocations(rebalance_params)
        
        return {
            "success": True,
            "message": "Capital rebalancing completed successfully",
            "total_reallocated": result.get("total_reallocated"),
            "farms_affected": result.get("farms_affected", []),
            "agents_affected": result.get("agents_affected", []),
            "rebalance_strategy": result.get("strategy"),
            "execution_time": result.get("execution_time")
        }
        
    except Exception as e:
        logger.error(f"Failed to rebalance capital: {e}")
        raise HTTPException(status_code=500, detail=f"Capital rebalancing error: {str(e)}")

@app.get("/api/v1/orchestration/agents/{agent_id}/performance-history")
async def get_agent_performance_history(agent_id: str, period: str = "30d"):
    """Get detailed performance history for a specific agent"""
    try:
        attribution_engine = registry.get_service("performance_attribution_engine")
        
        if not attribution_engine:
            # Mock performance history
            from datetime import datetime, timedelta
            import random
            
            end_date = datetime.now()
            start_date = end_date - timedelta(days=30)
            
            history = []
            current_date = start_date
            base_performance = 1000
            
            while current_date <= end_date:
                daily_change = random.uniform(-50, 100)
                base_performance += daily_change
                
                history.append({
                    "date": current_date.isoformat(),
                    "daily_pnl": daily_change,
                    "cumulative_pnl": base_performance - 1000,
                    "win_rate": random.uniform(0.6, 0.8),
                    "trades_count": random.randint(2, 8),
                    "sharpe_ratio": random.uniform(1.2, 2.5),
                    "max_drawdown": random.uniform(0.02, 0.08)
                })
                current_date += timedelta(days=1)
            
            return {
                "agent_id": agent_id,
                "period": period,
                "total_entries": len(history),
                "performance_history": history,
                "summary": {
                    "total_pnl": base_performance - 1000,
                    "best_day": max(history, key=lambda x: x["daily_pnl"])["daily_pnl"],
                    "worst_day": min(history, key=lambda x: x["daily_pnl"])["daily_pnl"],
                    "avg_daily_pnl": sum(h["daily_pnl"] for h in history) / len(history),
                    "total_trades": sum(h["trades_count"] for h in history)
                }
            }
        
        history = await attribution_engine.get_agent_performance_history(agent_id, period)
        
        return {
            "agent_id": agent_id,
            "period": period,
            "performance_history": history,
            "summary": await attribution_engine.calculate_performance_summary(agent_id, period)
        }
        
    except Exception as e:
        logger.error(f"Failed to get agent performance history: {e}")
        raise HTTPException(status_code=500, detail=f"Performance history error: {str(e)}")

@app.post("/api/v1/orchestration/events/subscribe")
async def subscribe_to_orchestration_events(request: dict):
    """Subscribe to specific orchestration events"""
    try:
        event_propagation = registry.get_service("enhanced_event_propagation")
        
        if not event_propagation:
            return {
                "success": True,
                "subscription_id": f"sub_{request.get('subscriber_service', 'client')}_{datetime.now().timestamp()}",
                "message": "Event subscription created (mock mode)",
                "event_types": request.get("event_types", []),
                "filters": request.get("filters", {})
            }
        
        subscription_request = {
            "subscriber_service": request.get("subscriber_service", "web_client"),
            "event_types": request.get("event_types", ["agent_assigned", "capital_allocated", "performance_updated"]),
            "priority_filter": request.get("priority_filter"),
            "scope_filter": request.get("scope_filter"),
            "data_filter": request.get("data_filter", {})
        }
        
        subscription_id = await event_propagation.subscribe(
            subscription_request["subscriber_service"],
            subscription_request["event_types"],
            lambda event: None  # Handler will be managed via WebSocket
        )
        
        return {
            "success": True,
            "subscription_id": subscription_id,
            "message": "Event subscription created successfully",
            "event_types": subscription_request["event_types"],
            "filters": {
                "priority": subscription_request.get("priority_filter"),
                "scope": subscription_request.get("scope_filter"),
                "data": subscription_request.get("data_filter")
            }
        }
        
    except Exception as e:
        logger.error(f"Failed to create event subscription: {e}")
        raise HTTPException(status_code=500, detail=f"Event subscription error: {str(e)}")

@app.delete("/api/v1/orchestration/events/unsubscribe/{subscription_id}")
async def unsubscribe_from_orchestration_events(subscription_id: str):
    """Unsubscribe from orchestration events"""
    try:
        event_propagation = registry.get_service("enhanced_event_propagation")
        
        if not event_propagation:
            return {
                "success": True,
                "message": f"Subscription {subscription_id} removed (mock mode)"
            }
        
        success = await event_propagation.unsubscribe(subscription_id)
        
        if success:
            return {
                "success": True,
                "message": f"Successfully unsubscribed from {subscription_id}"
            }
        else:
            raise HTTPException(status_code=404, detail="Subscription not found")
        
    except Exception as e:
        logger.error(f"Failed to unsubscribe from events: {e}")
        raise HTTPException(status_code=500, detail=f"Event unsubscription error: {str(e)}")

@app.post("/api/v1/goals/analyze-natural-language")
async def analyze_natural_language_goal(request: dict):
    """Analyze natural language input to create goal parameters"""
    try:
        goal_service = registry.get_service("goal_management_service")
        text = request.get("input", "")
        
        if not goal_service:
            # Mock AI analysis
            import re
            parsed_goal = {"type": "custom", "target_value": 1000, "target_unit": "USD", "timeframe": "daily"}
            
            text_lower = text.lower()
            if 'profit' in text_lower or '$' in text:
                parsed_goal['type'] = 'profit'
                amounts = re.findall(r'\$?(\d+(?:,\d+)*(?:\.\d{2})?)', text)
                if amounts:
                    parsed_goal['target_value'] = float(amounts[0].replace(',', ''))
            elif 'win rate' in text_lower or '%' in text:
                parsed_goal['type'] = 'performance'
                percentages = re.findall(r'(\d+(?:\.\d+)?)%', text)
                if percentages:
                    parsed_goal['target_value'] = float(percentages[0])
                    parsed_goal['target_unit'] = '%'
                    
            return {
                "parsedGoal": parsed_goal,
                "confidence": 0.85,
                "suggestedAgents": ["marcus_momentum", "alex_arbitrage"],
                "suggestedFarms": ["alpha_momentum_farm"],
                "estimatedTimeline": "1-14 days",
                "feasibilityScore": 0.78,
                "title": f"AI Generated Goal: {text[:50]}...",
                "description": f"Goal created from natural language: '{text}'"
            }
        
        analysis = await goal_service.analyze_natural_language(text)
        return {
            "parsedGoal": analysis.parsed_goal,
            "confidence": analysis.confidence,
            "suggestedAgents": analysis.suggested_agents,
            "suggestedFarms": analysis.suggested_farms,
            "estimatedTimeline": analysis.estimated_timeline,
            "feasibilityScore": analysis.feasibility_score,
            "title": f"AI Generated Goal: {text[:50]}...",
            "description": f"Goal created from natural language: '{text}'"
        }
    except Exception as e:
        logger.error(f"Failed to analyze natural language goal: {e}")
        raise HTTPException(status_code=500, detail=f"Goal analysis error: {str(e)}")

# ==========================================
# FARMS MANAGEMENT API ENDPOINTS
# ==========================================

@app.get("/api/v1/farms")
async def get_farms():
    """Get all farms"""
    try:
        farm_service = registry.get_service("farm_management_service")
        if not farm_service:
            # Return mock data if service not available
            return [
                {
                    "id": "farm-alpha-momentum",
                    "name": "Alpha Momentum Farm",
                    "description": "Advanced momentum trading farm with coordinated agent execution",
                    "strategy": "momentum_coordination",
                    "farmType": "momentum",
                    "status": "active",
                    "totalValue": 125847.32,
                    "dailyPnL": 2847.29,
                    "totalPnL": 15677.85,
                    "createdAt": "2024-01-10T08:00:00Z",
                    "agents": [
                        {
                            "id": "marcus_momentum",
                            "name": "Marcus Momentum",
                            "type": "momentum_specialist",
                            "status": "active",
                            "allocation": 45000.00,
                            "pnl": 2247.85,
                            "trades": 47,
                            "winRate": 0.74,
                            "lastActivity": "2024-01-15T15:23:00Z",
                            "performance": {
                                "dailyPnL": 847.29,
                                "weeklyPnL": 3247.85,
                                "monthlyPnL": 8947.32,
                                "sharpeRatio": 1.84,
                                "maxDrawdown": 0.045,
                                "source": "live_trading"
                            }
                        },
                        {
                            "id": "riley_momentum",
                            "name": "Riley Risk Manager", 
                            "type": "risk_coordinator",
                            "status": "active",
                            "allocation": 15000.00,
                            "pnl": 345.67,
                            "trades": 23,
                            "winRate": 0.89,
                            "lastActivity": "2024-01-15T15:25:00Z",
                            "performance": {
                                "dailyPnL": 123.45,
                                "weeklyPnL": 567.89,
                                "monthlyPnL": 1234.56,
                                "sharpeRatio": 2.15,
                                "maxDrawdown": 0.023,
                                "source": "risk_management"
                            }
                        }
                    ],
                    "performance": {
                        "winRate": 0.78,
                        "sharpeRatio": 1.94,
                        "maxDrawdown": 0.067,
                        "totalTrades": 189,
                        "avgProfitPerTrade": 82.94,
                        "riskAdjustedReturn": 0.154,
                        "coordinationScore": 0.89,
                        "strategyEfficiency": 0.91
                    },
                    "targets": {
                        "dailyTarget": 2500.00,
                        "monthlyTarget": 75000.00,
                        "currentProgress": 114.0,
                        "targetProgress": 65.8
                    },
                    "riskMetrics": {
                        "currentExposure": 0.68,
                        "maxExposure": 0.75,
                        "diversificationScore": 0.82,
                        "correlationRisk": 0.24
                    },
                    "realTimeMetrics": {
                        "systemLoad": 0.34,
                        "networkLatency": 23.45,
                        "processingSpeed": 847.2,
                        "errorRate": 0.002
                    }
                },
                {
                    "id": "farm-beta-arbitrage",
                    "name": "Beta Arbitrage Farm",
                    "description": "Cross-exchange arbitrage farm with multi-venue coordination",
                    "strategy": "arbitrage_coordination",
                    "farmType": "arbitrage",
                    "status": "active",
                    "totalValue": 89234.67,
                    "dailyPnL": 1234.56,
                    "totalPnL": 8934.22,
                    "createdAt": "2024-01-12T10:30:00Z",
                    "agents": [
                        {
                            "id": "alex_arbitrage",
                            "name": "Alex Arbitrage",
                            "type": "arbitrage_specialist",
                            "status": "active",
                            "allocation": 35000.00,
                            "pnl": 1847.32,
                            "trades": 156,
                            "winRate": 0.91,
                            "lastActivity": "2024-01-15T15:28:00Z",
                            "performance": {
                                "dailyPnL": 567.89,
                                "weeklyPnL": 2134.56,
                                "monthlyPnL": 6789.12,
                                "sharpeRatio": 2.47,
                                "maxDrawdown": 0.018,
                                "source": "arbitrage_trading"
                            }
                        }
                    ],
                    "performance": {
                        "winRate": 0.91,
                        "sharpeRatio": 2.47,
                        "maxDrawdown": 0.018,
                        "totalTrades": 456,
                        "avgProfitPerTrade": 19.58,
                        "riskAdjustedReturn": 0.089,
                        "coordinationScore": 0.94,
                        "strategyEfficiency": 0.96
                    },
                    "targets": {
                        "dailyTarget": 1200.00,
                        "monthlyTarget": 36000.00,
                        "currentProgress": 102.9,
                        "targetProgress": 24.8
                    },
                    "riskMetrics": {
                        "currentExposure": 0.42,
                        "maxExposure": 0.50,
                        "diversificationScore": 0.95,
                        "correlationRisk": 0.08
                    },
                    "realTimeMetrics": {
                        "systemLoad": 0.56,
                        "networkLatency": 15.23,
                        "processingSpeed": 1234.8,
                        "errorRate": 0.001
                    }
                }
            ]
        
        farms = await farm_service.get_all_farms()
        return [
            {
                "id": farm.farm_id,
                "name": farm.name,
                "description": farm.description,
                "strategy": farm.strategy_type,
                "farmType": farm.farm_type,
                "status": farm.status.value,
                "totalValue": float(farm.total_value),
                "dailyPnL": float(farm.daily_pnl),
                "totalPnL": float(farm.total_pnl),
                "createdAt": farm.created_at.isoformat(),
                "agents": [
                    {
                        "id": agent.agent_id,
                        "name": agent.name,
                        "type": agent.agent_type,
                        "status": agent.status,
                        "allocation": float(agent.allocation),
                        "pnl": float(agent.pnl),
                        "trades": agent.total_trades,
                        "winRate": agent.win_rate,
                        "lastActivity": agent.last_activity.isoformat() if agent.last_activity else None,
                        "performance": agent.performance_metrics
                    }
                    for agent in farm.agents
                ],
                "performance": farm.performance_metrics,
                "targets": farm.target_metrics,
                "riskMetrics": farm.risk_metrics,
                "realTimeMetrics": farm.real_time_metrics
            }
            for farm in farms
        ]
    except Exception as e:
        logger.error(f"Failed to get farms: {e}")
        raise HTTPException(status_code=500, detail=f"Farms retrieval error: {str(e)}")

@app.post("/api/v1/farms")
async def create_farm(farm_data: dict):
    """Create a new farm"""
    try:
        farm_service = registry.get_service("farm_management_service")
        if not farm_service:
            # Mock successful creation
            import uuid
            from datetime import datetime, timezone
            farm_id = str(uuid.uuid4())
            return {
                "id": farm_id,
                "name": farm_data.get("name", "New Farm"),
                "description": farm_data.get("description", "Farm created successfully"),
                "status": "pending",
                "createdAt": datetime.now(timezone.utc).isoformat(),
                "message": "Farm created successfully (mock mode)"
            }
        
        # Convert frontend format to service format
        service_farm_data = {
            "name": farm_data.get("name"),
            "description": farm_data.get("description"),
            "strategy_type": farm_data.get("strategy", "general"),
            "farm_type": farm_data.get("farmType", "standard"),
            "initial_allocation": farm_data.get("initialAllocation", 10000),
            "risk_limits": farm_data.get("riskLimits", {}),
            "performance_targets": farm_data.get("targets", {})
        }
        
        farm = await farm_service.create_farm(service_farm_data)
        return {
            "id": farm.farm_id,
            "name": farm.name,
            "description": farm.description,
            "status": farm.status.value,
            "createdAt": farm.created_at.isoformat(),
            "message": "Farm created successfully"
        }
    except Exception as e:
        logger.error(f"Failed to create farm: {e}")
        raise HTTPException(status_code=500, detail=f"Farm creation error: {str(e)}")

@app.put("/api/v1/farms/{farm_id}")
async def update_farm(farm_id: str, update_data: dict):
    """Update a farm"""
    try:
        farm_service = registry.get_service("farm_management_service")
        if not farm_service:
            return {"message": "Farm updated successfully (mock mode)"}
        
        farm = await farm_service.update_farm(farm_id, update_data)
        if not farm:
            raise HTTPException(status_code=404, detail="Farm not found")
        
        return {"message": "Farm updated successfully"}
    except Exception as e:
        logger.error(f"Failed to update farm: {e}")
        raise HTTPException(status_code=500, detail=f"Farm update error: {str(e)}")

@app.delete("/api/v1/farms/{farm_id}")
async def delete_farm(farm_id: str):
    """Delete a farm"""
    try:
        farm_service = registry.get_service("farm_management_service")
        if not farm_service:
            return {"message": "Farm deleted successfully (mock mode)"}
        
        await farm_service.delete_farm(farm_id)
        return {"message": "Farm deleted successfully"}
    except Exception as e:
        logger.error(f"Failed to delete farm: {e}")
        raise HTTPException(status_code=500, detail=f"Farm deletion error: {str(e)}")

@app.post("/api/v1/farms/{farm_id}/agents")
async def assign_agent_to_farm(farm_id: str, agent_data: dict):
    """Assign an agent to a farm"""
    try:
        farm_service = registry.get_service("farm_management_service")
        if not farm_service:
            return {"message": "Agent assigned to farm successfully (mock mode)"}
        
        agent_id = agent_data.get("agentId")
        role = agent_data.get("role", "primary")
        allocation = agent_data.get("allocation", 0)
        
        result = await farm_service.assign_agent(farm_id, agent_id, role, allocation)
        if not result:
            raise HTTPException(status_code=404, detail="Farm or agent not found")
        
        return {"message": f"Agent {agent_id} assigned to farm successfully"}
    except Exception as e:
        logger.error(f"Failed to assign agent to farm: {e}")
        raise HTTPException(status_code=500, detail=f"Agent assignment error: {str(e)}")

@app.delete("/api/v1/farms/{farm_id}/agents/{agent_id}")
async def remove_agent_from_farm(farm_id: str, agent_id: str):
    """Remove an agent from a farm"""
    try:
        farm_service = registry.get_service("farm_management_service")
        if not farm_service:
            return {"message": "Agent removed from farm successfully (mock mode)"}
        
        result = await farm_service.remove_agent(farm_id, agent_id)
        if not result:
            raise HTTPException(status_code=404, detail="Farm or agent not found")
        
        return {"message": f"Agent {agent_id} removed from farm successfully"}
    except Exception as e:
        logger.error(f"Failed to remove agent from farm: {e}")
        raise HTTPException(status_code=500, detail=f"Agent removal error: {str(e)}")

@app.post("/api/v1/farms/{farm_id}/start")
async def start_farm(farm_id: str):
    """Start a farm"""
    try:
        farm_service = registry.get_service("farm_management_service")
        if not farm_service:
            return {
                "farmId": farm_id,
                "status": "active",
                "startedAt": datetime.now(timezone.utc).isoformat(),
                "message": "Farm started successfully (mock mode)"
            }
        
        result = await farm_service.start_farm(farm_id)
        if not result:
            raise HTTPException(status_code=404, detail="Farm not found")
        
        return {
            "farmId": farm_id,
            "status": "active",
            "startedAt": datetime.now(timezone.utc).isoformat(),
            "message": "Farm started successfully"
        }
    except Exception as e:
        logger.error(f"Failed to start farm: {e}")
        raise HTTPException(status_code=500, detail=f"Farm start error: {str(e)}")

@app.post("/api/v1/farms/{farm_id}/stop")
async def stop_farm(farm_id: str):
    """Stop a farm"""
    try:
        farm_service = registry.get_service("farm_management_service")
        if not farm_service:
            return {
                "farmId": farm_id,
                "status": "stopped",
                "stoppedAt": datetime.now(timezone.utc).isoformat(),
                "message": "Farm stopped successfully (mock mode)"
            }
        
        result = await farm_service.stop_farm(farm_id)
        if not result:
            raise HTTPException(status_code=404, detail="Farm not found")
        
        return {
            "farmId": farm_id,
            "status": "stopped", 
            "stoppedAt": datetime.now(timezone.utc).isoformat(),
            "message": "Farm stopped successfully"
        }
    except Exception as e:
        logger.error(f"Failed to stop farm: {e}")
        raise HTTPException(status_code=500, detail=f"Farm stop error: {str(e)}")

@app.get("/api/v1/farms/metrics")
async def get_farm_metrics():
    """Get aggregated farm metrics"""
    try:
        farm_service = registry.get_service("farm_management_service")
        if not farm_service:
            return {
                "totalFarms": 2,
                "activeFarms": 2,
                "totalValue": 215081.99,
                "totalDailyPnL": 4081.85,
                "totalPnL": 24612.07,
                "avgWinRate": 0.845,
                "avgSharpeRatio": 2.205,
                "totalAgents": 3,
                "activeAgents": 3,
                "systemLoad": 0.45,
                "avgNetworkLatency": 19.34,
                "avgProcessingSpeed": 1041.0,
                "avgErrorRate": 0.0015,
                "lastUpdated": datetime.now(timezone.utc).isoformat()
            }
        
        metrics = await farm_service.get_aggregated_metrics()
        return metrics
    except Exception as e:
        logger.error(f"Failed to get farm metrics: {e}")
        raise HTTPException(status_code=500, detail=f"Farm metrics error: {str(e)}")

# ==========================================
# VAULT/WALLET MANAGEMENT API ENDPOINTS
# ==========================================

@app.get("/api/v1/vaults")
async def get_vaults():
    """Get all vaults/wallets"""
    try:
        vault_service = registry.get_service("vault_management_service")
        if not vault_service:
            # Return mock vault hierarchy data
            return [
                {
                    "id": "master-vault-treasury",
                    "name": "Master Treasury Vault",
                    "type": "master",
                    "description": "Central treasury managing all trading operations",
                    "totalBalance": 1247893.45,
                    "availableBalance": 456789.12,
                    "allocatedBalance": 791104.33,
                    "currency": "USD",
                    "parentId": None,
                    "children": [
                        {
                            "id": "strategy-vault-momentum",
                            "name": "Momentum Strategy Vault",
                            "type": "strategy",
                            "description": "Dedicated vault for momentum trading strategies",
                            "totalBalance": 289456.78,
                            "availableBalance": 67890.23,
                            "allocatedBalance": 221566.55,
                            "currency": "USD",
                            "parentId": "master-vault-treasury",
                            "allocation": 0.35,
                            "performance": {
                                "dailyPnL": 2847.29,
                                "totalReturn": 15677.85,
                                "returnPercent": 5.71,
                                "maxDrawdown": 0.045,
                                "sharpeRatio": 1.84
                            },
                            "children": [
                                {
                                    "id": "agent-wallet-marcus",
                                    "name": "Marcus Momentum Agent",
                                    "type": "agent",
                                    "description": "Individual wallet for Marcus momentum trading agent",
                                    "totalBalance": 145623.34,
                                    "availableBalance": 23456.78,
                                    "allocatedBalance": 122166.56,
                                    "currency": "USD",
                                    "parentId": "strategy-vault-momentum",
                                    "allocation": 0.65,
                                    "agentId": "marcus_momentum",
                                    "performance": {
                                        "dailyPnL": 1847.29,
                                        "totalReturn": 9847.85,
                                        "returnPercent": 7.24,
                                        "tradesCount": 47,
                                        "winRate": 0.74
                                    },
                                    "riskMetrics": {
                                        "exposure": 0.68,
                                        "leverage": 1.2,
                                        "varDaily": 2847.45
                                    }
                                },
                                {
                                    "id": "agent-wallet-riley",
                                    "name": "Riley Risk Manager",
                                    "type": "agent",
                                    "description": "Risk management agent wallet",
                                    "totalBalance": 67890.44,
                                    "availableBalance": 12345.67,
                                    "allocatedBalance": 55544.77,
                                    "currency": "USD",
                                    "parentId": "strategy-vault-momentum",
                                    "allocation": 0.35,
                                    "agentId": "riley_risk",
                                    "performance": {
                                        "dailyPnL": 456.78,
                                        "totalReturn": 2847.32,
                                        "returnPercent": 4.37,
                                        "tradesCount": 23,
                                        "winRate": 0.89
                                    },
                                    "riskMetrics": {
                                        "exposure": 0.42,
                                        "leverage": 0.8,
                                        "varDaily": 1234.56
                                    }
                                }
                            ]
                        },
                        {
                            "id": "strategy-vault-arbitrage",
                            "name": "Arbitrage Strategy Vault",
                            "type": "strategy",
                            "description": "Cross-exchange arbitrage operations vault",
                            "totalBalance": 189234.67,
                            "availableBalance": 45678.90,
                            "allocatedBalance": 143555.77,
                            "currency": "USD",
                            "parentId": "master-vault-treasury",
                            "allocation": 0.25,
                            "performance": {
                                "dailyPnL": 1234.56,
                                "totalReturn": 8934.22,
                                "returnPercent": 4.95,
                                "maxDrawdown": 0.018,
                                "sharpeRatio": 2.47
                            },
                            "children": [
                                {
                                    "id": "agent-wallet-alex",
                                    "name": "Alex Arbitrage Agent",
                                    "type": "agent",
                                    "description": "Cross-exchange arbitrage specialist",
                                    "totalBalance": 189234.67,
                                    "availableBalance": 45678.90,
                                    "allocatedBalance": 143555.77,
                                    "currency": "USD",
                                    "parentId": "strategy-vault-arbitrage",
                                    "allocation": 1.0,
                                    "agentId": "alex_arbitrage",
                                    "performance": {
                                        "dailyPnL": 1234.56,
                                        "totalReturn": 8934.22,
                                        "returnPercent": 4.95,
                                        "tradesCount": 156,
                                        "winRate": 0.91
                                    },
                                    "riskMetrics": {
                                        "exposure": 0.32,
                                        "leverage": 0.6,
                                        "varDaily": 987.65
                                    }
                                }
                            ]
                        },
                        {
                            "id": "reserve-vault",
                            "name": "Emergency Reserve Vault",
                            "type": "reserve",
                            "description": "Emergency funds and risk management reserves",
                            "totalBalance": 456789.12,
                            "availableBalance": 456789.12,
                            "allocatedBalance": 0.0,
                            "currency": "USD",
                            "parentId": "master-vault-treasury",
                            "allocation": 0.40,
                            "performance": {
                                "dailyPnL": 0.0,
                                "totalReturn": 0.0,
                                "returnPercent": 0.0,
                                "maxDrawdown": 0.0,
                                "sharpeRatio": 0.0
                            }
                        }
                    ],
                    "permissions": {
                        "canAllocate": True,
                        "canWithdraw": True,
                        "canRebalance": True,
                        "canCreateSubVaults": True
                    },
                    "riskControls": {
                        "maxAllocation": 0.80,
                        "maxLeverage": 2.0,
                        "stopLossThreshold": 0.15,
                        "dailyLossLimit": 50000.0
                    },
                    "createdAt": "2024-01-01T00:00:00Z",
                    "lastUpdated": "2024-01-15T15:30:00Z"
                }
            ]
        
        vaults = await vault_service.get_all_vaults()
        return [
            {
                "id": vault.vault_id,
                "name": vault.name,
                "type": vault.vault_type,
                "description": vault.description,
                "totalBalance": float(vault.total_balance),
                "availableBalance": float(vault.available_balance),
                "allocatedBalance": float(vault.allocated_balance),
                "currency": vault.currency,
                "parentId": vault.parent_vault_id,
                "children": vault.child_vaults,
                "permissions": vault.permissions,
                "riskControls": vault.risk_controls,
                "performance": vault.performance_metrics,
                "createdAt": vault.created_at.isoformat(),
                "lastUpdated": vault.last_updated.isoformat()
            }
            for vault in vaults
        ]
    except Exception as e:
        logger.error(f"Failed to get vaults: {e}")
        raise HTTPException(status_code=500, detail=f"Vaults retrieval error: {str(e)}")

@app.post("/api/v1/vaults")
async def create_vault(vault_data: dict):
    """Create a new vault"""
    try:
        vault_service = registry.get_service("vault_management_service")
        if not vault_service:
            # Mock successful creation
            import uuid
            from datetime import datetime, timezone
            vault_id = str(uuid.uuid4())
            return {
                "id": vault_id,
                "name": vault_data.get("name", "New Vault"),
                "type": vault_data.get("type", "standard"),
                "description": vault_data.get("description", "Vault created successfully"),
                "status": "active",
                "createdAt": datetime.now(timezone.utc).isoformat(),
                "message": "Vault created successfully (mock mode)"
            }
        
        # Convert frontend format to service format
        service_vault_data = {
            "name": vault_data.get("name"),
            "vault_type": vault_data.get("type", "standard"),
            "description": vault_data.get("description"),
            "initial_balance": vault_data.get("initialBalance", 0),
            "currency": vault_data.get("currency", "USD"),
            "parent_vault_id": vault_data.get("parentId"),
            "risk_controls": vault_data.get("riskControls", {}),
            "permissions": vault_data.get("permissions", {})
        }
        
        vault = await vault_service.create_vault(service_vault_data)
        return {
            "id": vault.vault_id,
            "name": vault.name,
            "type": vault.vault_type,
            "description": vault.description,
            "status": vault.status.value,
            "createdAt": vault.created_at.isoformat(),
            "message": "Vault created successfully"
        }
    except Exception as e:
        logger.error(f"Failed to create vault: {e}")
        raise HTTPException(status_code=500, detail=f"Vault creation error: {str(e)}")

@app.put("/api/v1/vaults/{vault_id}")
async def update_vault(vault_id: str, update_data: dict):
    """Update a vault"""
    try:
        vault_service = registry.get_service("vault_management_service")
        if not vault_service:
            return {"message": "Vault updated successfully (mock mode)"}
        
        vault = await vault_service.update_vault(vault_id, update_data)
        if not vault:
            raise HTTPException(status_code=404, detail="Vault not found")
        
        return {"message": "Vault updated successfully"}
    except Exception as e:
        logger.error(f"Failed to update vault: {e}")
        raise HTTPException(status_code=500, detail=f"Vault update error: {str(e)}")

@app.delete("/api/v1/vaults/{vault_id}")
async def delete_vault(vault_id: str):
    """Delete a vault"""
    try:
        vault_service = registry.get_service("vault_management_service")
        if not vault_service:
            return {"message": "Vault deleted successfully (mock mode)"}
        
        await vault_service.delete_vault(vault_id)
        return {"message": "Vault deleted successfully"}
    except Exception as e:
        logger.error(f"Failed to delete vault: {e}")
        raise HTTPException(status_code=500, detail=f"Vault deletion error: {str(e)}")

@app.post("/api/v1/vaults/{vault_id}/allocate")
async def allocate_funds(vault_id: str, allocation_data: dict):
    """Allocate funds from vault"""
    try:
        vault_service = registry.get_service("vault_management_service")
        if not vault_service:
            return {
                "transactionId": f"tx_{int(datetime.now().timestamp())}",
                "fromVault": vault_id,
                "toTarget": allocation_data.get("target"),
                "amount": allocation_data.get("amount"),
                "status": "completed",
                "executedAt": datetime.now(timezone.utc).isoformat(),
                "message": "Funds allocated successfully (mock mode)"
            }
        
        target = allocation_data.get("target")
        amount = allocation_data.get("amount")
        allocation_type = allocation_data.get("type", "manual")
        
        result = await vault_service.allocate_funds(vault_id, target, amount, allocation_type)
        return {
            "transactionId": result["transaction_id"],
            "fromVault": vault_id,
            "toTarget": target,
            "amount": amount,
            "status": result["status"],
            "executedAt": result["executed_at"],
            "message": "Funds allocated successfully"
        }
    except Exception as e:
        logger.error(f"Failed to allocate funds: {e}")
        raise HTTPException(status_code=500, detail=f"Fund allocation error: {str(e)}")

@app.post("/api/v1/vaults/{vault_id}/withdraw")
async def withdraw_funds(vault_id: str, withdrawal_data: dict):
    """Withdraw funds from vault"""
    try:
        vault_service = registry.get_service("vault_management_service")
        if not vault_service:
            return {
                "transactionId": f"tx_{int(datetime.now().timestamp())}",
                "fromVault": vault_id,
                "amount": withdrawal_data.get("amount"),
                "destination": withdrawal_data.get("destination"),
                "status": "completed",
                "executedAt": datetime.now(timezone.utc).isoformat(),
                "message": "Funds withdrawn successfully (mock mode)"
            }
        
        amount = withdrawal_data.get("amount")
        destination = withdrawal_data.get("destination")
        withdrawal_type = withdrawal_data.get("type", "manual")
        
        result = await vault_service.withdraw_funds(vault_id, amount, destination, withdrawal_type)
        return {
            "transactionId": result["transaction_id"],
            "fromVault": vault_id,
            "amount": amount,
            "destination": destination,
            "status": result["status"],
            "executedAt": result["executed_at"],
            "message": "Funds withdrawn successfully"
        }
    except Exception as e:
        logger.error(f"Failed to withdraw funds: {e}")
        raise HTTPException(status_code=500, detail=f"Fund withdrawal error: {str(e)}")

@app.post("/api/v1/vaults/{vault_id}/rebalance")
async def rebalance_vault(vault_id: str, rebalance_data: dict):
    """Rebalance vault allocations"""
    try:
        vault_service = registry.get_service("vault_management_service")
        if not vault_service:
            return {
                "rebalanceId": f"rebal_{int(datetime.now().timestamp())}",
                "vaultId": vault_id,
                "targetAllocations": rebalance_data.get("targetAllocations"),
                "status": "completed",
                "executedAt": datetime.now(timezone.utc).isoformat(),
                "changes": [
                    {
                        "target": "marcus_momentum",
                        "oldAllocation": 0.60,
                        "newAllocation": 0.65,
                        "amountMoved": 5000.0
                    },
                    {
                        "target": "alex_arbitrage",
                        "oldAllocation": 0.40,
                        "newAllocation": 0.35,
                        "amountMoved": -5000.0
                    }
                ],
                "message": "Vault rebalanced successfully (mock mode)"
            }
        
        target_allocations = rebalance_data.get("targetAllocations")
        rebalance_strategy = rebalance_data.get("strategy", "proportional")
        
        result = await vault_service.rebalance_vault(vault_id, target_allocations, rebalance_strategy)
        return {
            "rebalanceId": result["rebalance_id"],
            "vaultId": vault_id,
            "targetAllocations": target_allocations,
            "status": result["status"],
            "executedAt": result["executed_at"],
            "changes": result["changes"],
            "message": "Vault rebalanced successfully"
        }
    except Exception as e:
        logger.error(f"Failed to rebalance vault: {e}")
        raise HTTPException(status_code=500, detail=f"Vault rebalance error: {str(e)}")

@app.get("/api/v1/vaults/{vault_id}/transactions")
async def get_vault_transactions(vault_id: str, limit: int = 50, offset: int = 0):
    """Get vault transaction history"""
    try:
        vault_service = registry.get_service("vault_management_service")
        if not vault_service:
            # Mock transaction history
            return {
                "transactions": [
                    {
                        "id": f"tx_001_{vault_id}",
                        "type": "allocation",
                        "amount": 25000.0,
                        "from": vault_id,
                        "to": "marcus_momentum",
                        "status": "completed",
                        "timestamp": "2024-01-15T14:30:00Z",
                        "description": "Allocated funds to Marcus Momentum agent"
                    },
                    {
                        "id": f"tx_002_{vault_id}",
                        "type": "withdrawal",
                        "amount": 5000.0,
                        "from": vault_id,
                        "to": "external_wallet",
                        "status": "completed", 
                        "timestamp": "2024-01-15T12:15:00Z",
                        "description": "Withdrawal to external wallet"
                    },
                    {
                        "id": f"tx_003_{vault_id}",
                        "type": "rebalance",
                        "amount": 10000.0,
                        "from": "alex_arbitrage",
                        "to": "marcus_momentum",
                        "status": "completed",
                        "timestamp": "2024-01-15T10:45:00Z",
                        "description": "Rebalancing between agents"
                    }
                ],
                "pagination": {
                    "total": 3,
                    "limit": limit,
                    "offset": offset,
                    "hasMore": False
                }
            }
        
        transactions = await vault_service.get_transaction_history(vault_id, limit, offset)
        return {
            "transactions": transactions["transactions"],
            "pagination": transactions["pagination"]
        }
    except Exception as e:
        logger.error(f"Failed to get vault transactions: {e}")
        raise HTTPException(status_code=500, detail=f"Transaction history error: {str(e)}")

@app.get("/api/v1/vaults/{vault_id}/performance")
async def get_vault_performance(vault_id: str, timeframe: str = "1M"):
    """Get vault performance metrics"""
    try:
        vault_service = registry.get_service("vault_management_service")
        if not vault_service:
            return {
                "vaultId": vault_id,
                "timeframe": timeframe,
                "totalReturn": 15677.85,
                "returnPercent": 5.71,
                "dailyPnL": 2847.29,
                "maxDrawdown": 0.045,
                "sharpeRatio": 1.84,
                "volatility": 0.125,
                "winRate": 0.78,
                "bestDay": 4567.89,
                "worstDay": -1234.56,
                "tradingDays": 30,
                "profitableDays": 23,
                "lastUpdated": datetime.now(timezone.utc).isoformat()
            }
        
        performance = await vault_service.get_performance_metrics(vault_id, timeframe)
        return performance
    except Exception as e:
        logger.error(f"Failed to get vault performance: {e}")
        raise HTTPException(status_code=500, detail=f"Vault performance error: {str(e)}")

@app.get("/api/v1/vaults/summary")
async def get_vaults_summary():
    """Get summary of all vaults"""
    try:
        vault_service = registry.get_service("vault_management_service")
        if not vault_service:
            return {
                "totalVaults": 4,
                "totalBalance": 1247893.45,
                "totalAllocated": 791104.33,
                "totalAvailable": 456789.12,
                "totalReturn": 24612.07,
                "totalReturnPercent": 2.01,
                "dailyPnL": 4081.85,
                "activeAgents": 3,
                "activeFarms": 2,
                "riskExposure": 0.63,
                "systemHealth": "optimal",
                "lastUpdated": datetime.now(timezone.utc).isoformat()
            }
        
        summary = await vault_service.get_vaults_summary()
        return summary
    except Exception as e:
        logger.error(f"Failed to get vaults summary: {e}")
        raise HTTPException(status_code=500, detail=f"Vaults summary error: {str(e)}")

# ==========================================
# MULTI-CHAIN WALLET INTEGRATION ENDPOINTS - PHASE 9
# ==========================================

@app.get("/api/v1/wallets/multi-chain")
async def get_multi_chain_overview():
    """Get multi-chain wallet overview"""
    try:
        vault_service = registry.get_service("vault_management_service")
        if not vault_service:
            # Return mock multi-chain overview
            return {
                "total_balance_usd": 982456.78,
                "active_chains": 5,
                "total_chains": 5,
                "total_wallets": 9,
                "chains": {
                    "ethereum": {
                        "chain_id": 1,
                        "name": "Ethereum",
                        "native_token": "ETH",
                        "total_balance_usd": 456789.12,
                        "wallet_count": 3,
                        "last_block": 18945673,
                        "gas_price_gwei": 25.4,
                        "status": "active"
                    },
                    "bsc": {
                        "chain_id": 56,
                        "name": "Binance Smart Chain",
                        "native_token": "BNB",
                        "total_balance_usd": 234567.89,
                        "wallet_count": 2,
                        "last_block": 34856729,
                        "gas_price_gwei": 5.2,
                        "status": "active"
                    },
                    "polygon": {
                        "chain_id": 137,
                        "name": "Polygon",
                        "native_token": "MATIC",
                        "total_balance_usd": 123456.78,
                        "wallet_count": 2,
                        "last_block": 50123987,
                        "gas_price_gwei": 32.1,
                        "status": "active"
                    },
                    "arbitrum": {
                        "chain_id": 42161,
                        "name": "Arbitrum One",
                        "native_token": "ETH",
                        "total_balance_usd": 78945.67,
                        "wallet_count": 1,
                        "last_block": 145678912,
                        "gas_price_gwei": 0.3,
                        "status": "active"
                    },
                    "solana": {
                        "chain_id": 101,
                        "name": "Solana",
                        "native_token": "SOL",
                        "total_balance_usd": 89012.34,
                        "wallet_count": 1,
                        "last_block": 234567890,
                        "gas_price_gwei": 0.0001,
                        "status": "active"
                    }
                },
                "last_updated": datetime.now(timezone.utc).isoformat()
            }
        
        overview = await vault_service.get_multi_chain_overview()
        return overview
    except Exception as e:
        logger.error(f"Failed to get multi-chain overview: {e}")
        raise HTTPException(status_code=500, detail=f"Multi-chain overview error: {str(e)}")

@app.get("/api/v1/wallets/{wallet_id}/balances")
async def get_chain_balances(wallet_id: str):
    """Get balances for all chains for a specific wallet"""
    try:
        vault_service = registry.get_service("vault_management_service")
        if not vault_service:
            # Return mock chain balances
            return {
                "wallet_id": wallet_id,
                "total_usd_value": 163754.89,
                "balances": {
                    "ethereum": {
                        "native": {
                            "symbol": "ETH",
                            "balance": 15.47623,
                            "usd_value": 31254.89,
                            "price_usd": 2021.45
                        },
                        "tokens": [
                            {
                                "symbol": "USDC",
                                "balance": 25000.0,
                                "usd_value": 25000.0,
                                "price_usd": 1.0,
                                "contract": "0xa0b86a33e6d86a4b11e8f7e3b9a1a8a7f8b9c0d1e2"
                            },
                            {
                                "symbol": "WBTC",
                                "balance": 2.5,
                                "usd_value": 107500.0,
                                "price_usd": 43000.0,
                                "contract": "0x2260fac5e5542a773aa44fbcfedf7c193bc2c599"
                            }
                        ]
                    },
                    "bsc": {
                        "native": {
                            "symbol": "BNB",
                            "balance": 45.287,
                            "usd_value": 13586.1,
                            "price_usd": 300.0
                        },
                        "tokens": [
                            {
                                "symbol": "CAKE",
                                "balance": 1250.0,
                                "usd_value": 5000.0,
                                "price_usd": 4.0,
                                "contract": "0x0e09fabb73bd3ade0a17ecc321fd13a19e81ce82"
                            }
                        ]
                    }
                },
                "last_updated": datetime.now(timezone.utc).isoformat()
            }
        
        balances = await vault_service.get_chain_balances(wallet_id)
        return balances
    except Exception as e:
        logger.error(f"Failed to get chain balances for {wallet_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Chain balances error: {str(e)}")

@app.get("/api/v1/wallets/cross-chain-positions")
async def get_cross_chain_positions():
    """Get cross-chain position summary"""
    try:
        vault_service = registry.get_service("vault_management_service")
        if not vault_service:
            # Return mock cross-chain positions
            return [
                {
                    "position_id": "pos_1",
                    "asset": "ETH",
                    "total_amount": 25.67,
                    "total_usd_value": 51854.32,
                    "chains": {
                        "ethereum": {"amount": 15.47, "percentage": 60.3},
                        "arbitrum": {"amount": 5.2, "percentage": 20.3},
                        "polygon": {"amount": 5.0, "percentage": 19.4}
                    },
                    "avg_cost_basis": 1890.45,
                    "unrealized_pnl": 3367.82,
                    "unrealized_pnl_percent": 6.95
                },
                {
                    "position_id": "pos_2",
                    "asset": "USDC",
                    "total_amount": 75000.0,
                    "total_usd_value": 75000.0,
                    "chains": {
                        "ethereum": {"amount": 40000.0, "percentage": 53.3},
                        "polygon": {"amount": 20000.0, "percentage": 26.7},
                        "bsc": {"amount": 15000.0, "percentage": 20.0}
                    },
                    "avg_cost_basis": 1.0,
                    "unrealized_pnl": 0.0,
                    "unrealized_pnl_percent": 0.0
                }
            ]
        
        positions = await vault_service.get_cross_chain_positions()
        return positions
    except Exception as e:
        logger.error(f"Failed to get cross-chain positions: {e}")
        raise HTTPException(status_code=500, detail=f"Cross-chain positions error: {str(e)}")

@app.post("/api/v1/wallets/cross-chain-transfer")
async def initiate_cross_chain_transfer(transfer_request: dict):
    """Initiate a cross-chain transfer"""
    try:
        vault_service = registry.get_service("vault_management_service")
        if not vault_service:
            # Return mock transfer initiation
            import uuid
            transfer_id = str(uuid.uuid4())
            from_chain = transfer_request.get("from_chain", "ethereum")
            to_chain = transfer_request.get("to_chain", "polygon")
            asset = transfer_request.get("asset", "ETH")
            amount = transfer_request.get("amount", 1.0)
            
            # Mock bridge selection
            bridge_options = {
                ("ethereum", "polygon"): {"bridge": "Polygon Bridge", "fee_usd": 15.0, "time_minutes": 8},
                ("ethereum", "arbitrum"): {"bridge": "Arbitrum Bridge", "fee_usd": 8.0, "time_minutes": 12},
                ("ethereum", "bsc"): {"bridge": "Binance Bridge", "fee_usd": 5.0, "time_minutes": 15}
            }
            
            bridge_info = bridge_options.get((from_chain, to_chain), {
                "bridge": "Generic Bridge", "fee_usd": 10.0, "time_minutes": 20
            })
            
            return {
                "transfer_id": transfer_id,
                "from_chain": from_chain,
                "to_chain": to_chain,
                "asset": asset,
                "amount": amount,
                "bridge": bridge_info["bridge"],
                "estimated_fee_usd": bridge_info["fee_usd"],
                "estimated_time_minutes": bridge_info["time_minutes"],
                "status": "pending",
                "created_at": datetime.now(timezone.utc).isoformat(),
                "tx_hash": f"0x{uuid.uuid4().hex}"
            }
        
        result = await vault_service.initiate_cross_chain_transfer(transfer_request)
        return result
    except Exception as e:
        logger.error(f"Failed to initiate cross-chain transfer: {e}")
        raise HTTPException(status_code=500, detail=f"Cross-chain transfer error: {str(e)}")

@app.get("/api/v1/wallets/transaction-history")
async def get_transaction_history_multi_chain(chain: str = None, limit: int = 50):
    """Get multi-chain transaction history"""
    try:
        vault_service = registry.get_service("vault_management_service")
        if not vault_service:
            # Return mock transaction history
            import uuid
            transactions = []
            chains = ["ethereum", "bsc", "polygon", "arbitrum", "solana"]
            
            if chain:
                chains = [chain]
            
            for i in range(limit):
                selected_chain = chains[i % len(chains)]
                tx_types = ["transfer", "swap", "bridge", "deposit", "withdrawal"]
                
                tx = {
                    "tx_id": f"tx_{uuid.uuid4().hex[:8]}",
                    "chain": selected_chain,
                    "type": tx_types[i % len(tx_types)],
                    "asset": ["ETH", "BTC", "USDC", "BNB", "MATIC"][i % 5],
                    "amount": round(10 + (i * 13.7) % 1000, 4),
                    "usd_value": round(100 + (i * 456.78) % 10000, 2),
                    "from_address": f"0x{uuid.uuid4().hex[:40]}",
                    "to_address": f"0x{uuid.uuid4().hex[:40]}",
                    "tx_hash": f"0x{uuid.uuid4().hex}",
                    "status": "confirmed" if i % 10 != 0 else "pending",
                    "gas_fee_usd": round(5 + (i * 2.3) % 50, 2),
                    "timestamp": (datetime.now(timezone.utc) - timedelta(hours=i)).isoformat()
                }
                transactions.append(tx)
            
            return transactions
        
        params = {"limit": limit}
        if chain:
            params["chain"] = chain
            
        history = await vault_service.get_transaction_history_multi_chain(params)
        return history
    except Exception as e:
        logger.error(f"Failed to get multi-chain transaction history: {e}")
        raise HTTPException(status_code=500, detail=f"Transaction history error: {str(e)}")

@app.get("/api/v1/wallets/portfolio-overview")
async def get_portfolio_allocation_multi_chain():
    """Get portfolio allocation across chains"""
    try:
        vault_service = registry.get_service("vault_management_service")
        if not vault_service:
            # Return mock portfolio allocation
            return {
                "total_portfolio_usd": 982456.78,
                "chain_allocation": {
                    "ethereum": {"usd_value": 456789.12, "percentage": 46.5},
                    "bsc": {"usd_value": 234567.89, "percentage": 23.9},
                    "polygon": {"usd_value": 123456.78, "percentage": 12.6},
                    "arbitrum": {"usd_value": 78945.67, "percentage": 8.0},
                    "solana": {"usd_value": 89012.34, "percentage": 9.0}
                },
                "asset_allocation": {
                    "ETH": {"usd_value": 298456.78, "percentage": 30.4},
                    "BTC": {"usd_value": 245678.90, "percentage": 25.0},
                    "USDC": {"usd_value": 196789.12, "percentage": 20.0},
                    "BNB": {"usd_value": 147890.12, "percentage": 15.1},
                    "Others": {"usd_value": 93642.86, "percentage": 9.5}
                },
                "defi_exposure": {
                    "lending": {"usd_value": 147890.12, "percentage": 15.1},
                    "liquidity_pools": {"usd_value": 98567.89, "percentage": 10.0},
                    "staking": {"usd_value": 73456.78, "percentage": 7.5},
                    "yield_farming": {"usd_value": 49234.56, "percentage": 5.0}
                },
                "risk_metrics": {
                    "concentration_risk": 0.35,
                    "chain_diversification": 0.78,
                    "asset_diversification": 0.82,
                    "liquidity_score": 0.89
                },
                "last_updated": datetime.now(timezone.utc).isoformat()
            }
        
        allocation = await vault_service.get_portfolio_allocation_multi_chain()
        return allocation
    except Exception as e:
        logger.error(f"Failed to get portfolio allocation: {e}")
        raise HTTPException(status_code=500, detail=f"Portfolio allocation error: {str(e)}")

@app.get("/api/v1/wallets/supported-chains")
async def get_supported_chains():
    """Get list of supported blockchain networks"""
    try:
        vault_service = registry.get_service("vault_management_service")
        if not vault_service:
            # Return mock supported chains
            return [
                {
                    "chain_id": 1,
                    "name": "Ethereum",
                    "symbol": "ETH",
                    "rpc_url": "https://eth-mainnet.alchemyapi.io/v2/...",
                    "explorer_url": "https://etherscan.io",
                    "bridge_support": True,
                    "defi_protocols": ["Uniswap", "Aave", "Compound", "MakerDAO"],
                    "avg_gas_price_gwei": 25.4,
                    "status": "active"
                },
                {
                    "chain_id": 56,
                    "name": "Binance Smart Chain",
                    "symbol": "BNB",
                    "rpc_url": "https://bsc-dataseed.binance.org/",
                    "explorer_url": "https://bscscan.com",
                    "bridge_support": True,
                    "defi_protocols": ["PancakeSwap", "Venus", "Alpaca Finance"],
                    "avg_gas_price_gwei": 5.2,
                    "status": "active"
                },
                {
                    "chain_id": 137,
                    "name": "Polygon",
                    "symbol": "MATIC",
                    "rpc_url": "https://polygon-mainnet.alchemyapi.io/v2/...",
                    "explorer_url": "https://polygonscan.com",
                    "bridge_support": True,
                    "defi_protocols": ["QuickSwap", "Aave", "Curve"],
                    "avg_gas_price_gwei": 32.1,
                    "status": "active"
                },
                {
                    "chain_id": 42161,
                    "name": "Arbitrum One",
                    "symbol": "ETH",
                    "rpc_url": "https://arb1.arbitrum.io/rpc",
                    "explorer_url": "https://arbiscan.io",
                    "bridge_support": True,
                    "defi_protocols": ["GMX", "Balancer", "Uniswap V3"],
                    "avg_gas_price_gwei": 0.3,
                    "status": "active"
                },
                {
                    "chain_id": 101,
                    "name": "Solana",
                    "symbol": "SOL",
                    "rpc_url": "https://api.mainnet-beta.solana.com",
                    "explorer_url": "https://solscan.io",
                    "bridge_support": True,
                    "defi_protocols": ["Raydium", "Serum", "Orca"],
                    "avg_gas_price_gwei": 0.0001,
                    "status": "active"
                }
            ]
        
        chains = await vault_service.get_supported_chains()
        return chains
    except Exception as e:
        logger.error(f"Failed to get supported chains: {e}")
        raise HTTPException(status_code=500, detail=f"Supported chains error: {str(e)}")

@app.get("/api/v1/wallets/connections")
async def get_wallet_connections():
    """Get connected wallet information"""
    try:
        vault_service = registry.get_service("vault_management_service")
        if not vault_service:
            # Return mock wallet connections
            return [
                {
                    "wallet_id": "metamask_1",
                    "wallet_type": "MetaMask",
                    "address": "0x742d35cc6634c0532925a3b8d8a742e684e",
                    "chain": "ethereum",
                    "status": "connected",
                    "last_activity": datetime.now(timezone.utc).isoformat(),
                    "balance_usd": 456789.12
                },
                {
                    "wallet_id": "trust_1",
                    "wallet_type": "Trust Wallet",
                    "address": "0x9876543210abcdef1234567890abcdef12345678",
                    "chain": "bsc",
                    "status": "connected",
                    "last_activity": (datetime.now(timezone.utc) - timedelta(hours=2)).isoformat(),
                    "balance_usd": 234567.89
                },
                {
                    "wallet_id": "phantom_1",
                    "wallet_type": "Phantom",
                    "address": "Hx7vL8bK9pQr3mN4cF6aE2dW1zS8tU5vY7rT9qP",
                    "chain": "solana",
                    "status": "connected",
                    "last_activity": (datetime.now(timezone.utc) - timedelta(minutes=30)).isoformat(),
                    "balance_usd": 89012.34
                }
            ]
        
        connections = await vault_service.get_wallet_connections()
        return connections
    except Exception as e:
        logger.error(f"Failed to get wallet connections: {e}")
        raise HTTPException(status_code=500, detail=f"Wallet connections error: {str(e)}")

@app.post("/api/v1/wallets/estimate-gas")
async def estimate_gas_fees(transaction_params: dict):
    """Estimate gas fees for a transaction"""
    try:
        vault_service = registry.get_service("vault_management_service")
        if not vault_service:
            # Return mock gas estimation
            chain = transaction_params.get("chain", "ethereum")
            tx_type = transaction_params.get("type", "transfer")
            
            gas_estimates = {
                "ethereum": {
                    "transfer": {"gas_limit": 21000, "gas_price_gwei": 25.4},
                    "swap": {"gas_limit": 150000, "gas_price_gwei": 25.4},
                    "bridge": {"gas_limit": 200000, "gas_price_gwei": 25.4}
                },
                "bsc": {
                    "transfer": {"gas_limit": 21000, "gas_price_gwei": 5.2},
                    "swap": {"gas_limit": 120000, "gas_price_gwei": 5.2},
                    "bridge": {"gas_limit": 180000, "gas_price_gwei": 5.2}
                }
            }
            
            estimate = gas_estimates.get(chain, {}).get(tx_type, {
                "gas_limit": 21000, "gas_price_gwei": 20.0
            })
            
            gas_fee_eth = (estimate["gas_limit"] * estimate["gas_price_gwei"]) / 1e9
            gas_fee_usd = gas_fee_eth * 2021.45  # Mock ETH price
            
            return {
                "chain": chain,
                "transaction_type": tx_type,
                "gas_limit": estimate["gas_limit"],
                "gas_price_gwei": estimate["gas_price_gwei"],
                "gas_fee_eth": round(gas_fee_eth, 6),
                "gas_fee_usd": round(gas_fee_usd, 2),
                "estimated_time_minutes": 2 if chain != "ethereum" else 5
            }
        
        estimate = await vault_service.estimate_gas_fees(transaction_params)
        return estimate
    except Exception as e:
        logger.error(f"Failed to estimate gas fees: {e}")
        raise HTTPException(status_code=500, detail=f"Gas estimation error: {str(e)}")

@app.get("/api/v1/wallets/yield-positions")
async def get_yield_positions():
    """Get DeFi yield positions across chains"""
    try:
        vault_service = registry.get_service("vault_management_service")
        if not vault_service:
            # Return mock yield positions
            return [
                {
                    "position_id": "yield_1",
                    "protocol": "Aave",
                    "chain": "ethereum",
                    "position_type": "lending",
                    "asset": "USDC",
                    "amount": 50000.0,
                    "apy": 4.25,
                    "earned_usd": 2125.0,
                    "status": "active",
                    "auto_compound": True
                },
                {
                    "position_id": "yield_2",
                    "protocol": "PancakeSwap",
                    "chain": "bsc",
                    "position_type": "liquidity_pool",
                    "asset": "CAKE-BNB LP",
                    "amount": 15000.0,
                    "apy": 18.5,
                    "earned_usd": 925.0,
                    "status": "active",
                    "auto_compound": False
                },
                {
                    "position_id": "yield_3",
                    "protocol": "Curve",
                    "chain": "polygon",
                    "position_type": "liquidity_pool",
                    "asset": "3pool",
                    "amount": 25000.0,
                    "apy": 6.75,
                    "earned_usd": 687.5,
                    "status": "active",
                    "auto_compound": True
                }
            ]
        
        positions = await vault_service.get_yield_positions()
        return positions
    except Exception as e:
        logger.error(f"Failed to get yield positions: {e}")
        raise HTTPException(status_code=500, detail=f"Yield positions error: {str(e)}")

# ==========================================
# DEFI PROTOCOL INTEGRATION ENDPOINTS - PHASE 11
# ==========================================

@app.get("/api/v1/defi/protocols")
async def get_supported_protocols(chain: str = None):
    """Get list of supported DeFi protocols"""
    try:
        defi_service = registry.get_service("defi_protocol_integration_service")
        if not defi_service:
            # Return mock DeFi protocols
            protocols = [
                {
                    "protocol_id": "ethereum_uniswap_v3",
                    "name": "Uniswap V3",
                    "protocol_type": "dex",
                    "chain": "ethereum",
                    "tvl_usd": 4500000000.0,
                    "base_apy": 5.2,
                    "reward_apy": 1.56,
                    "total_apy": 6.76,
                    "contract_address": "0xE592427A0AEce92De3Edee1F18E0157C05861564",
                    "risk_score": 0.15,
                    "audit_status": "audited",
                    "last_updated": datetime.now(timezone.utc).isoformat()
                },
                {
                    "protocol_id": "ethereum_aave",
                    "name": "Aave",
                    "protocol_type": "lending",
                    "chain": "ethereum",
                    "tvl_usd": 12000000000.0,
                    "base_apy": 3.8,
                    "reward_apy": 1.14,
                    "total_apy": 4.94,
                    "contract_address": "0x7d2768dE32b0b80b7a3454c06BdAc94A69DDc7A9",
                    "risk_score": 0.12,
                    "audit_status": "audited",
                    "last_updated": datetime.now(timezone.utc).isoformat()
                },
                {
                    "protocol_id": "polygon_quickswap",
                    "name": "QuickSwap",
                    "protocol_type": "dex",
                    "chain": "polygon",
                    "tvl_usd": 250000000.0,
                    "base_apy": 8.5,
                    "reward_apy": 2.55,
                    "total_apy": 11.05,
                    "contract_address": "0xa5E0829CaCEd8fFDD4De3c43696c57F7D7A678ff",
                    "risk_score": 0.25,
                    "audit_status": "reviewed",
                    "last_updated": datetime.now(timezone.utc).isoformat()
                },
                {
                    "protocol_id": "bsc_pancakeswap",
                    "name": "PancakeSwap",
                    "protocol_type": "dex",
                    "chain": "bsc",
                    "tvl_usd": 1800000000.0,
                    "base_apy": 12.3,
                    "reward_apy": 3.69,
                    "total_apy": 15.99,
                    "contract_address": "0x10ED43C718714eb63d5aA57B78B54704E256024E",
                    "risk_score": 0.35,
                    "audit_status": "reviewed",
                    "last_updated": datetime.now(timezone.utc).isoformat()
                },
                {
                    "protocol_id": "ethereum_lido",
                    "name": "Lido",
                    "protocol_type": "liquid_staking",
                    "chain": "ethereum",
                    "tvl_usd": 25000000000.0,
                    "base_apy": 4.1,
                    "reward_apy": 0.0,
                    "total_apy": 4.1,
                    "contract_address": "0xae7ab96520DE3A18E5e111B5EaAb095312D7fE84",
                    "risk_score": 0.08,
                    "audit_status": "audited",
                    "last_updated": datetime.now(timezone.utc).isoformat()
                }
            ]
            
            if chain:
                protocols = [p for p in protocols if p["chain"].lower() == chain.lower()]
            
            return protocols
        
        protocols = await defi_service.get_supported_protocols(chain)
        return protocols
    except Exception as e:
        logger.error(f"Failed to get DeFi protocols: {e}")
        raise HTTPException(status_code=500, detail=f"DeFi protocols error: {str(e)}")

@app.get("/api/v1/defi/protocols/{protocol_id}")
async def get_protocol_details(protocol_id: str):
    """Get detailed information about a specific DeFi protocol"""
    try:
        defi_service = registry.get_service("defi_protocol_integration_service")
        if not defi_service:
            # Return mock protocol details
            return {
                "protocol_id": protocol_id,
                "name": "Uniswap V3",
                "protocol_type": "dex",
                "chain": "ethereum",
                "tvl_usd": 4500000000.0,
                "base_apy": 5.2,
                "reward_apy": 1.56,
                "total_apy": 6.76,
                "contract_address": "0xE592427A0AEce92De3Edee1F18E0157C05861564",
                "risk_score": 0.15,
                "audit_status": "audited",
                "available_pools": [
                    {"pair": "ETH/USDC", "apy": 6.8, "tvl": 450000000.0},
                    {"pair": "BTC/ETH", "apy": 5.9, "tvl": 280000000.0},
                    {"pair": "USDC/USDT", "apy": 4.2, "tvl": 180000000.0}
                ],
                "fees": {"deposit": 0.0, "withdrawal": 0.0, "performance": 0.05},
                "lock_period_days": 0,
                "auto_compound": True,
                "last_updated": datetime.now(timezone.utc).isoformat()
            }
        
        protocol = await defi_service.get_protocol_details(protocol_id)
        if not protocol:
            raise HTTPException(status_code=404, detail="Protocol not found")
        
        return protocol
    except Exception as e:
        logger.error(f"Failed to get protocol details: {e}")
        raise HTTPException(status_code=500, detail=f"Protocol details error: {str(e)}")

@app.get("/api/v1/defi/opportunities")
async def discover_yield_opportunities(
    min_apy: float = 5.0,
    max_risk_score: float = 0.5,
    chains: str = None
):
    """Discover yield farming opportunities based on criteria"""
    try:
        defi_service = registry.get_service("defi_protocol_integration_service")
        if not defi_service:
            # Return mock yield opportunities
            opportunities = [
                {
                    "opportunity_id": "bsc_pancakeswap_cake_bnb",
                    "protocol_name": "PancakeSwap",
                    "pool_name": "CAKE-BNB Pool",
                    "asset_pair": "CAKE/BNB",
                    "chain": "bsc",
                    "apy": 18.5,
                    "tvl_usd": 45000000.0,
                    "minimum_deposit": 100.0,
                    "risk_score": 0.35,
                    "impermanent_loss_risk": 0.25,
                    "lock_period_days": 0,
                    "auto_compound": True,
                    "rewards_tokens": ["CAKE"]
                },
                {
                    "opportunity_id": "ethereum_aave_usdc",
                    "protocol_name": "Aave",
                    "pool_name": "USDC Lending",
                    "asset_pair": "USDC",
                    "chain": "ethereum",
                    "apy": 4.25,
                    "tvl_usd": 2400000000.0,
                    "minimum_deposit": 50.0,
                    "risk_score": 0.12,
                    "impermanent_loss_risk": 0.0,
                    "lock_period_days": 0,
                    "auto_compound": True,
                    "rewards_tokens": ["AAVE"]
                },
                {
                    "opportunity_id": "polygon_quickswap_matic_usdt",
                    "protocol_name": "QuickSwap",
                    "pool_name": "MATIC-USDT Pool",
                    "asset_pair": "MATIC/USDT",
                    "chain": "polygon",
                    "apy": 12.8,
                    "tvl_usd": 15000000.0,
                    "minimum_deposit": 25.0,
                    "risk_score": 0.28,
                    "impermanent_loss_risk": 0.18,
                    "lock_period_days": 0,
                    "auto_compound": True,
                    "rewards_tokens": ["QUICK", "MATIC"]
                }
            ]
            
            # Apply filters
            if chains:
                chain_list = [c.strip() for c in chains.split(',')]
                opportunities = [o for o in opportunities if o["chain"] in chain_list]
            
            opportunities = [o for o in opportunities if o["apy"] >= min_apy and o["risk_score"] <= max_risk_score]
            
            return opportunities
        
        chain_list = chains.split(',') if chains else None
        opportunities = await defi_service.discover_yield_opportunities(min_apy, max_risk_score, chain_list)
        return opportunities
    except Exception as e:
        logger.error(f"Failed to discover yield opportunities: {e}")
        raise HTTPException(status_code=500, detail=f"Yield opportunities error: {str(e)}")

@app.post("/api/v1/defi/positions")
async def enter_defi_position(position_request: dict):
    """Enter a new DeFi position"""
    try:
        defi_service = registry.get_service("defi_protocol_integration_service")
        if not defi_service:
            # Return mock position creation
            import uuid
            position_id = str(uuid.uuid4())
            return {
                "position_id": position_id,
                "protocol_id": position_request.get("protocol_id"),
                "position_type": position_request.get("position_type", "liquidity_pool"),
                "asset_symbol": position_request.get("asset_symbol"),
                "amount_deposited": position_request.get("amount", 1000.0),
                "status": "active",
                "entry_timestamp": datetime.now(timezone.utc).isoformat(),
                "expected_apy": 8.5,
                "tx_hash": f"0x{uuid.uuid4().hex}",
                "message": "Position entered successfully (mock mode)"
            }
        
        from decimal import Decimal
        position = await defi_service.enter_position(
            protocol_id=position_request["protocol_id"],
            position_type=position_request["position_type"],
            asset_symbol=position_request["asset_symbol"],
            amount=Decimal(str(position_request["amount"])),
            wallet_address=position_request.get("wallet_address", "0x742d35cc6634c0532925a3b8d8a742e684e"),
            auto_compound=position_request.get("auto_compound", True)
        )
        
        return position
    except Exception as e:
        logger.error(f"Failed to enter DeFi position: {e}")
        raise HTTPException(status_code=500, detail=f"DeFi position entry error: {str(e)}")

@app.delete("/api/v1/defi/positions/{position_id}")
async def exit_defi_position(position_id: str):
    """Exit a DeFi position"""
    try:
        defi_service = registry.get_service("defi_protocol_integration_service")
        if not defi_service:
            # Return mock exit summary
            return {
                "position_id": position_id,
                "exit_timestamp": datetime.now(timezone.utc).isoformat(),
                "initial_deposit": 1000.0,
                "final_value": 1085.50,
                "total_return": 85.50,
                "return_percentage": 8.55,
                "rewards_earned": 35.20,
                "time_in_position_days": 45,
                "annualized_return": 69.2,
                "tx_hash": f"0x{uuid.uuid4().hex}",
                "message": "Position exited successfully"
            }
        
        exit_summary = await defi_service.exit_position(position_id)
        return exit_summary
    except Exception as e:
        logger.error(f"Failed to exit DeFi position: {e}")
        raise HTTPException(status_code=500, detail=f"DeFi position exit error: {str(e)}")

@app.post("/api/v1/defi/positions/{position_id}/harvest")
async def harvest_position_rewards(position_id: str):
    """Harvest rewards from a DeFi position"""
    try:
        defi_service = registry.get_service("defi_protocol_integration_service")
        if not defi_service:
            # Return mock harvest result
            return {
                "position_id": position_id,
                "harvest_timestamp": datetime.now(timezone.utc).isoformat(),
                "rewards_harvested": 25.80,
                "total_rewards_earned": 156.40,
                "auto_compounded": True,
                "new_position_value": 1156.40,
                "tx_hash": f"0x{uuid.uuid4().hex}",
                "message": "Rewards harvested and compounded successfully"
            }
        
        harvest_result = await defi_service.harvest_rewards(position_id)
        return harvest_result
    except Exception as e:
        logger.error(f"Failed to harvest position rewards: {e}")
        raise HTTPException(status_code=500, detail=f"Harvest rewards error: {str(e)}")

@app.get("/api/v1/defi/portfolio")
async def get_defi_portfolio_overview(wallet_address: str = None):
    """Get comprehensive DeFi portfolio overview"""
    try:
        defi_service = registry.get_service("defi_protocol_integration_service")
        if not defi_service:
            # Return mock portfolio overview
            return {
                "portfolio_summary": {
                    "total_deposited": 90000.0,
                    "total_current_value": 96750.0,
                    "total_rewards_earned": 4250.0,
                    "total_unrealized_pnl": 6750.0,
                    "portfolio_return_percentage": 7.5,
                    "active_positions": 5,
                    "protocols_used": 4,
                    "chains_used": 3
                },
                "protocol_breakdown": {
                    "Uniswap V3": {
                        "total_value": 35000.0,
                        "positions": 2,
                        "rewards_earned": 1750.0
                    },
                    "Aave": {
                        "total_value": 25000.0,
                        "positions": 1,
                        "rewards_earned": 1125.0
                    },
                    "PancakeSwap": {
                        "total_value": 20000.0,
                        "positions": 1,
                        "rewards_earned": 900.0
                    },
                    "QuickSwap": {
                        "total_value": 16750.0,
                        "positions": 1,
                        "rewards_earned": 475.0
                    }
                },
                "chain_breakdown": {
                    "ethereum": {"total_value": 60000.0, "positions": 3, "percentage": 62.0},
                    "polygon": {"total_value": 16750.0, "positions": 1, "percentage": 17.3},
                    "bsc": {"total_value": 20000.0, "positions": 1, "percentage": 20.7}
                },
                "risk_metrics": {
                    "average_risk_score": 0.18,
                    "diversification_score": 0.8,
                    "chain_diversification": 3
                },
                "last_updated": datetime.now(timezone.utc).isoformat()
            }
        
        portfolio = await defi_service.get_portfolio_overview(wallet_address)
        return portfolio
    except Exception as e:
        logger.error(f"Failed to get DeFi portfolio overview: {e}")
        raise HTTPException(status_code=500, detail=f"DeFi portfolio error: {str(e)}")

@app.get("/api/v1/defi/positions/{position_id}")
async def get_position_details(position_id: str):
    """Get detailed information about a specific DeFi position"""
    try:
        defi_service = registry.get_service("defi_protocol_integration_service")
        if not defi_service:
            # Return mock position details
            return {
                "position_id": position_id,
                "user_wallet": "0x742d35cc6634c0532925a3b8d8a742e684e",
                "protocol_id": "ethereum_uniswap_v3",
                "position_type": "liquidity_pool",
                "status": "active",
                "asset_symbol": "ETH/USDC",
                "amount_deposited": 15000.0,
                "current_value_usd": 15750.0,
                "rewards_earned_usd": 450.0,
                "unrealized_pnl_usd": 750.0,
                "entry_timestamp": (datetime.now(timezone.utc) - timedelta(days=30)).isoformat(),
                "last_harvest": (datetime.now(timezone.utc) - timedelta(days=7)).isoformat(),
                "auto_compound": True,
                "protocol_info": {
                    "name": "Uniswap V3",
                    "type": "dex",
                    "chain": "ethereum",
                    "current_apy": 6.8,
                    "risk_score": 0.15,
                    "contract_address": "0xE592427A0AEce92De3Edee1F18E0157C05861564"
                },
                "performance": {
                    "days_in_position": 30,
                    "daily_return_usd": 25.0,
                    "annualized_return_percentage": 8.0,
                    "total_return_percentage": 8.0
                }
            }
        
        position_details = await defi_service.get_position_details(position_id)
        if not position_details:
            raise HTTPException(status_code=404, detail="Position not found")
        
        return position_details
    except Exception as e:
        logger.error(f"Failed to get position details: {e}")
        raise HTTPException(status_code=500, detail=f"Position details error: {str(e)}")

@app.get("/api/v1/defi/analytics")
async def get_defi_analytics_dashboard():
    """Get comprehensive DeFi analytics for dashboard"""
    try:
        defi_service = registry.get_service("defi_protocol_integration_service")
        if not defi_service:
            # Return mock analytics
            return {
                "protocol_analytics": {
                    "total_protocols_supported": 12,
                    "active_protocols": 8,
                    "total_tvl_usd": 45200000000.0,
                    "average_apy": 8.7,
                    "average_risk_score": 0.21
                },
                "position_analytics": {
                    "total_positions": 5,
                    "position_types": {
                        "liquidity_pool": {"count": 3, "total_value": 71750.0},
                        "lending_deposit": {"count": 1, "total_value": 25000.0},
                        "yield_farm": {"count": 1, "total_value": 20000.0}
                    },
                    "total_value_locked": 116750.0,
                    "total_rewards_earned": 4250.0
                },
                "chain_distribution": {
                    "ethereum": 5,
                    "polygon": 3,
                    "bsc": 2,
                    "arbitrum": 2
                },
                "opportunity_metrics": {
                    "high_yield_opportunities": 6,
                    "low_risk_opportunities": 4,
                    "audited_protocols": 8
                },
                "last_updated": datetime.now(timezone.utc).isoformat()
            }
        
        analytics = await defi_service.get_analytics_dashboard()
        return analytics
    except Exception as e:
        logger.error(f"Failed to get DeFi analytics: {e}")
        raise HTTPException(status_code=500, detail=f"DeFi analytics error: {str(e)}")

# ==========================================
# ADVANCED ANALYTICS SYSTEM ENDPOINTS - PHASE 12
# ==========================================

@app.get("/api/v1/analytics/performance")
async def get_performance_metrics(entity_id: str = "portfolio", timeframe: str = "1m"):
    """Get comprehensive performance metrics"""
    try:
        analytics_service = registry.get_service("advanced_analytics_service")
        if not analytics_service:
            # Return mock performance metrics
            return {
                "entity_id": entity_id,
                "timeframe": timeframe,
                "total_return": 0.085,
                "annual_return": 0.124,
                "sharpe_ratio": 1.42,
                "sortino_ratio": 1.68,
                "max_drawdown": 0.085,
                "volatility": 0.18,
                "win_rate": 0.675,
                "profit_factor": 2.15,
                "calmar_ratio": 1.46,
                "var_95": 0.025,
                "var_99": 0.045,
                "beta": 0.85,
                "alpha": 0.045,
                "information_ratio": 0.68,
                "last_updated": datetime.now(timezone.utc).isoformat()
            }
        
        from services.advanced_analytics_service import TimeFrame
        timeframe_enum = TimeFrame(timeframe)
        metrics = await analytics_service.calculate_performance_metrics(entity_id, timeframe_enum)
        
        result = {
            "entity_id": entity_id,
            "timeframe": timeframe,
            **{k: v for k, v in metrics.__dict__.items()},
            "last_updated": datetime.now(timezone.utc).isoformat()
        }
        return result
    except Exception as e:
        logger.error(f"Failed to get performance metrics: {e}")
        raise HTTPException(status_code=500, detail=f"Performance metrics error: {str(e)}")

@app.get("/api/v1/analytics/risk")
async def get_risk_metrics(entity_id: str = "portfolio", confidence_level: float = 0.95):
    """Get comprehensive risk metrics"""
    try:
        analytics_service = registry.get_service("advanced_analytics_service")
        if not analytics_service:
            # Return mock risk metrics
            return {
                "entity_id": entity_id,
                "confidence_level": confidence_level,
                "portfolio_var": 0.035,
                "expected_shortfall": 0.052,
                "concentration_risk": 0.28,
                "correlation_risk": 0.42,
                "liquidity_risk": 0.15,
                "leverage_ratio": 1.85,
                "risk_budget_utilization": 0.78,
                "stress_test_results": {
                    "market_crash_2008": -0.35,
                    "covid_crash_2020": -0.28,
                    "crypto_winter_2022": -0.45,
                    "interest_rate_shock": -0.15,
                    "liquidity_crisis": -0.25
                },
                "last_updated": datetime.now(timezone.utc).isoformat()
            }
        
        metrics = await analytics_service.calculate_risk_metrics(entity_id, confidence_level)
        
        result = {
            "entity_id": entity_id,
            "confidence_level": confidence_level,
            **{k: v for k, v in metrics.__dict__.items()},
            "last_updated": datetime.now(timezone.utc).isoformat()
        }
        return result
    except Exception as e:
        logger.error(f"Failed to get risk metrics: {e}")
        raise HTTPException(status_code=500, detail=f"Risk metrics error: {str(e)}")

@app.get("/api/v1/analytics/market")
async def get_market_analytics():
    """Get market analytics and regime detection"""
    try:
        analytics_service = registry.get_service("advanced_analytics_service")
        if not analytics_service:
            # Return mock market analytics
            return {
                "market_regime": "bull_market",
                "volatility_regime": "normal",
                "correlation_regime": "low_correlation",
                "sentiment_score": 0.72,
                "trend_strength": 0.85,
                "momentum_score": 0.68,
                "mean_reversion_score": 0.32,
                "market_breadth": 0.75,
                "regime_confidence": 0.82,
                "regime_duration_days": 45,
                "volatility_percentile": 0.45,
                "fear_greed_index": 68,
                "last_updated": datetime.now(timezone.utc).isoformat()
            }
        
        analytics = await analytics_service.calculate_market_analytics()
        
        result = {
            **{k: v for k, v in analytics.__dict__.items()},
            "regime_confidence": 0.82,
            "regime_duration_days": 45,
            "volatility_percentile": 0.45,
            "fear_greed_index": 68,
            "last_updated": datetime.now(timezone.utc).isoformat()
        }
        return result
    except Exception as e:
        logger.error(f"Failed to get market analytics: {e}")
        raise HTTPException(status_code=500, detail=f"Market analytics error: {str(e)}")

@app.get("/api/v1/analytics/attribution")
async def get_performance_attribution(entity_id: str = "portfolio", timeframe: str = "1m"):
    """Get performance attribution analysis"""
    try:
        analytics_service = registry.get_service("advanced_analytics_service")
        if not analytics_service:
            # Return mock attribution analysis
            return {
                "entity_id": entity_id,
                "timeframe": timeframe,
                "total_return": 0.085,
                "attribution_breakdown": {
                    "agent_selection": {"return": 0.035, "percentage": 41.2},
                    "strategy_allocation": {"return": 0.025, "percentage": 29.4},
                    "timing": {"return": 0.015, "percentage": 17.6},
                    "interaction": {"return": 0.010, "percentage": 11.8}
                },
                "risk_attribution": {
                    "systematic_risk": {"contribution": 0.040, "percentage": 65.0},
                    "idiosyncratic_risk": {"contribution": 0.022, "percentage": 35.0}
                },
                "factor_attribution": {
                    "momentum": {"exposure": 0.35, "return": 0.028},
                    "mean_reversion": {"exposure": 0.25, "return": 0.018},
                    "volatility": {"exposure": 0.20, "return": 0.012},
                    "carry": {"exposure": 0.20, "return": 0.027}
                },
                "alpha_sources": {
                    "security_selection": 0.025,
                    "market_timing": 0.015,
                    "cross_asset": 0.020,
                    "volatility_trading": 0.025
                },
                "last_updated": datetime.now(timezone.utc).isoformat()
            }
        
        from services.advanced_analytics_service import TimeFrame
        timeframe_enum = TimeFrame(timeframe)
        attribution = await analytics_service.generate_performance_attribution(entity_id, timeframe_enum)
        return attribution
    except Exception as e:
        logger.error(f"Failed to get performance attribution: {e}")
        raise HTTPException(status_code=500, detail=f"Performance attribution error: {str(e)}")

@app.get("/api/v1/analytics/correlation")
async def get_correlation_analysis(timeframe: str = "1m"):
    """Get correlation analysis between assets and strategies"""
    try:
        analytics_service = registry.get_service("advanced_analytics_service")
        if not analytics_service:
            # Return mock correlation analysis
            return {
                "timeframe": timeframe,
                "asset_correlations": {
                    "BTC": {"ETH": 0.75, "SPY": 0.25, "BONDS": -0.15, "GOLD": 0.10, "DXY": -0.45},
                    "ETH": {"BTC": 0.75, "SPY": 0.30, "BONDS": -0.10, "GOLD": 0.05, "DXY": -0.40},
                    "SPY": {"BTC": 0.25, "ETH": 0.30, "BONDS": -0.20, "GOLD": -0.05, "DXY": -0.30},
                    "BONDS": {"BTC": -0.15, "ETH": -0.10, "SPY": -0.20, "GOLD": 0.40, "DXY": 0.20},
                    "GOLD": {"BTC": 0.10, "ETH": 0.05, "SPY": -0.05, "BONDS": 0.40, "DXY": -0.60},
                    "DXY": {"BTC": -0.45, "ETH": -0.40, "SPY": -0.30, "BONDS": 0.20, "GOLD": -0.60}
                },
                "strategy_correlations": {
                    "momentum": {"BTC": 0.45, "ETH": 0.40, "SPY": 0.35, "BONDS": -0.15, "GOLD": 0.05, "DXY": -0.25},
                    "mean_reversion": {"BTC": -0.25, "ETH": -0.20, "SPY": 0.15, "BONDS": 0.30, "GOLD": 0.20, "DXY": 0.10},
                    "arbitrage": {"BTC": 0.05, "ETH": 0.08, "SPY": 0.02, "BONDS": 0.01, "GOLD": 0.00, "DXY": -0.02},
                    "volatility": {"BTC": 0.60, "ETH": 0.55, "SPY": 0.40, "BONDS": -0.10, "GOLD": 0.15, "DXY": -0.30}
                },
                "concentration_metrics": {
                    "max_correlation": 0.75,
                    "average_correlation": 0.18,
                    "correlation_clusters": ["crypto_cluster", "traditional_cluster", "safe_haven_cluster"]
                },
                "regime_analysis": {
                    "current_regime": "normal_correlation",
                    "regime_probability": 0.75,
                    "regime_stability": 0.68
                },
                "last_updated": datetime.now(timezone.utc).isoformat()
            }
        
        from services.advanced_analytics_service import TimeFrame
        timeframe_enum = TimeFrame(timeframe)
        correlation = await analytics_service.generate_correlation_analysis(timeframe_enum)
        return correlation
    except Exception as e:
        logger.error(f"Failed to get correlation analysis: {e}")
        raise HTTPException(status_code=500, detail=f"Correlation analysis error: {str(e)}")

@app.get("/api/v1/analytics/dashboard")
async def get_analytics_dashboard():
    """Get comprehensive analytics dashboard"""
    try:
        analytics_service = registry.get_service("advanced_analytics_service")
        if not analytics_service:
            # Return mock analytics dashboard
            return {
                "portfolio_summary": {
                    "total_return_ytd": 0.085,
                    "sharpe_ratio": 1.42,
                    "max_drawdown": 0.085,
                    "win_rate": 0.675,
                    "volatility": 0.18,
                    "var_95": 0.035,
                    "current_positions": 15,
                    "active_strategies": 8,
                    "last_updated": datetime.now(timezone.utc).isoformat()
                },
                "performance_metrics": {
                    "total_return": 0.085,
                    "annual_return": 0.124,
                    "sharpe_ratio": 1.42,
                    "max_drawdown": 0.085,
                    "win_rate": 0.675,
                    "profit_factor": 2.15
                },
                "risk_metrics": {
                    "portfolio_var": 0.035,
                    "expected_shortfall": 0.052,
                    "concentration_risk": 0.28,
                    "correlation_risk": 0.42,
                    "leverage_ratio": 1.85
                },
                "market_analytics": {
                    "market_regime": "bull_market",
                    "volatility_regime": "normal",
                    "sentiment_score": 0.72,
                    "trend_strength": 0.85
                },
                "performance_trends": {
                    "daily_returns": [0.002, 0.001, -0.003, 0.005, 0.002, -0.001, 0.004],
                    "cumulative_returns": [0.075, 0.076, 0.073, 0.078, 0.080, 0.079, 0.083],
                    "rolling_sharpe": [1.35, 1.38, 1.32, 1.45, 1.42, 1.40, 1.44]
                },
                "agent_performance": {
                    "agent_marcus": {"total_return": 0.12, "sharpe_ratio": 1.55, "max_drawdown": 0.06, "win_rate": 0.70},
                    "agent_alex": {"total_return": 0.08, "sharpe_ratio": 1.25, "max_drawdown": 0.04, "win_rate": 0.65},
                    "agent_sophia": {"total_return": 0.15, "sharpe_ratio": 1.75, "max_drawdown": 0.08, "win_rate": 0.75}
                },
                "alerts": [
                    {
                        "id": "risk_001",
                        "type": "risk",
                        "severity": "medium",
                        "message": "Portfolio VaR has increased by 15% over the last week",
                        "timestamp": datetime.now(timezone.utc).isoformat()
                    }
                ],
                "recommendations": [
                    {
                        "id": "rec_001",
                        "category": "risk_management",
                        "priority": "high",
                        "recommendation": "Consider reducing position sizes in highly correlated assets",
                        "rationale": "Correlation risk has increased to 0.75, above the 0.70 threshold"
                    }
                ],
                "last_updated": datetime.now(timezone.utc).isoformat()
            }
        
        dashboard = await analytics_service.generate_analytics_dashboard()
        return dashboard
    except Exception as e:
        logger.error(f"Failed to get analytics dashboard: {e}")
        raise HTTPException(status_code=500, detail=f"Analytics dashboard error: {str(e)}")

@app.get("/api/v1/analytics/reports/{report_type}")
async def generate_analytics_report(report_type: str, entity_id: str = "portfolio", timeframe: str = "1m"):
    """Generate specific analytics reports"""
    try:
        analytics_service = registry.get_service("advanced_analytics_service")
        
        if report_type == "performance":
            if not analytics_service:
                return {
                    "report_type": "performance",
                    "entity_id": entity_id,
                    "summary": {
                        "total_return": 0.085,
                        "sharpe_ratio": 1.42,
                        "max_drawdown": 0.085,
                        "win_rate": 0.675
                    },
                    "detailed_metrics": {
                        "monthly_returns": [0.015, 0.025, -0.010, 0.032, 0.018, 0.005],
                        "rolling_volatility": [0.15, 0.16, 0.19, 0.17, 0.18, 0.16],
                        "drawdown_periods": [
                            {"start": "2024-01-15", "end": "2024-01-25", "max_drawdown": 0.035},
                            {"start": "2024-03-05", "end": "2024-03-12", "max_drawdown": 0.022}
                        ]
                    },
                    "benchmark_comparison": {
                        "benchmark": "SPY",
                        "excess_return": 0.035,
                        "tracking_error": 0.08,
                        "information_ratio": 0.68
                    },
                    "generated_at": datetime.now(timezone.utc).isoformat()
                }
            
            from services.advanced_analytics_service import TimeFrame
            timeframe_enum = TimeFrame(timeframe)
            metrics = await analytics_service.calculate_performance_metrics(entity_id, timeframe_enum)
            attribution = await analytics_service.generate_performance_attribution(entity_id, timeframe_enum)
            
            return {
                "report_type": "performance",
                "entity_id": entity_id,
                "timeframe": timeframe,
                "performance_metrics": {k: v for k, v in metrics.__dict__.items()},
                "attribution_analysis": attribution,
                "generated_at": datetime.now(timezone.utc).isoformat()
            }
        
        elif report_type == "risk":
            if not analytics_service:
                return {
                    "report_type": "risk",
                    "entity_id": entity_id,
                    "risk_summary": {
                        "portfolio_var": 0.035,
                        "expected_shortfall": 0.052,
                        "max_drawdown": 0.085,
                        "concentration_risk": 0.28
                    },
                    "stress_tests": {
                        "market_crash": -0.35,
                        "liquidity_crisis": -0.25,
                        "interest_rate_shock": -0.15
                    },
                    "risk_limits": {
                        "var_limit": 0.05,
                        "concentration_limit": 0.40,
                        "leverage_limit": 3.0,
                        "current_utilization": 0.78
                    },
                    "generated_at": datetime.now(timezone.utc).isoformat()
                }
            
            risk_metrics = await analytics_service.calculate_risk_metrics(entity_id)
            
            return {
                "report_type": "risk",
                "entity_id": entity_id,
                "risk_metrics": {k: v for k, v in risk_metrics.__dict__.items()},
                "risk_limits": {
                    "var_limit": 0.05,
                    "concentration_limit": 0.40,
                    "leverage_limit": 3.0,
                    "current_utilization": risk_metrics.risk_budget_utilization
                },
                "generated_at": datetime.now(timezone.utc).isoformat()
            }
        
        elif report_type == "correlation":
            if not analytics_service:
                return {
                    "report_type": "correlation",
                    "correlation_matrix": {
                        "BTC": {"ETH": 0.75, "SPY": 0.25},
                        "ETH": {"BTC": 0.75, "SPY": 0.30},
                        "SPY": {"BTC": 0.25, "ETH": 0.30}
                    },
                    "risk_analysis": {
                        "max_correlation": 0.75,
                        "diversification_ratio": 0.68,
                        "concentration_risk": 0.28
                    },
                    "generated_at": datetime.now(timezone.utc).isoformat()
                }
            
            from services.advanced_analytics_service import TimeFrame
            timeframe_enum = TimeFrame(timeframe)
            correlation = await analytics_service.generate_correlation_analysis(timeframe_enum)
            
            return {
                "report_type": "correlation",
                "timeframe": timeframe,
                **correlation,
                "generated_at": datetime.now(timezone.utc).isoformat()
            }
        
        else:
            raise HTTPException(status_code=400, detail=f"Unknown report type: {report_type}")
            
    except Exception as e:
        logger.error(f"Failed to generate analytics report: {e}")
        raise HTTPException(status_code=500, detail=f"Analytics report error: {str(e)}")

# ==========================================
# ENHANCED MARKET DATA API ENDPOINTS
# ==========================================

@app.get("/api/v1/market/live-data/{symbol}")
async def get_live_market_data(symbol: str):
    """Get real-time market data for a specific symbol"""
    try:
        market_data_service = registry.get_service("market_data_service")
        if not market_data_service:
            # Return comprehensive mock live data
            import random
            base_prices = {
                "BTC": 67234.85, "ETH": 3847.92, "SOL": 142.73, "ADA": 0.4567,
                "MATIC": 0.8934, "DOT": 6.234, "LINK": 14.567, "UNI": 7.891
            }
            base_price = base_prices.get(symbol.upper(), random.uniform(1, 100))
            
            return {
                "symbol": symbol.upper(),
                "price": round(base_price * random.uniform(0.98, 1.02), 4),
                "change24h": round(random.uniform(-10, 10), 2),
                "changePercent24h": round(random.uniform(-15, 15), 2),
                "volume24h": random.randint(1000000, 100000000),
                "marketCap": base_price * random.randint(1000000, 100000000),
                "high24h": round(base_price * random.uniform(1.01, 1.08), 4),
                "low24h": round(base_price * random.uniform(0.92, 0.99), 4),
                "open24h": round(base_price * random.uniform(0.95, 1.05), 4),
                "volatility": round(random.uniform(0.15, 0.45), 3),
                "bid": round(base_price * 0.999, 4),
                "ask": round(base_price * 1.001, 4),
                "spread": round(base_price * 0.002, 4),
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "source": "aggregated_feed",
                "exchanges": [
                    {"name": "Binance", "price": round(base_price * random.uniform(0.999, 1.001), 4)},
                    {"name": "Coinbase", "price": round(base_price * random.uniform(0.999, 1.001), 4)},
                    {"name": "Kraken", "price": round(base_price * random.uniform(0.999, 1.001), 4)}
                ]
            }
        
        live_data = await market_data_service.get_live_data(symbol)
        return live_data
    except Exception as e:
        logger.error(f"Failed to get live market data for {symbol}: {e}")
        raise HTTPException(status_code=500, detail=f"Live market data error: {str(e)}")

@app.get("/api/v1/market/watchlist")
async def get_market_watchlist():
    """Get watchlist with real-time data for all tracked symbols"""
    try:
        market_data_service = registry.get_service("market_data_service")
        if not market_data_service:
            # Return comprehensive watchlist
            symbols = ["BTC", "ETH", "SOL", "ADA", "MATIC", "DOT", "LINK", "UNI", "AVAX", "ATOM"]
            watchlist = []
            
            for symbol in symbols:
                import random
                base_prices = {
                    "BTC": 67234.85, "ETH": 3847.92, "SOL": 142.73, "ADA": 0.4567,
                    "MATIC": 0.8934, "DOT": 6.234, "LINK": 14.567, "UNI": 7.891,
                    "AVAX": 23.456, "ATOM": 8.912
                }
                base_price = base_prices.get(symbol, random.uniform(1, 100))
                change_pct = random.uniform(-8, 8)
                
                watchlist.append({
                    "symbol": symbol,
                    "name": f"{symbol} Token",
                    "price": round(base_price * random.uniform(0.99, 1.01), 4),
                    "change24h": round(base_price * change_pct / 100, 4),
                    "changePercent24h": round(change_pct, 2),
                    "volume24h": random.randint(5000000, 200000000),
                    "marketCap": base_price * random.randint(5000000, 500000000),
                    "rank": symbols.index(symbol) + 1,
                    "isWatched": True,
                    "alerts": {
                        "priceAlert": base_price * 1.05,
                        "volumeAlert": None,
                        "hasActiveAlerts": random.choice([True, False])
                    },
                    "technicalIndicators": {
                        "rsi": round(random.uniform(30, 70), 1),
                        "macd": "bullish" if change_pct > 0 else "bearish",
                        "movingAverage": round(base_price * random.uniform(0.98, 1.02), 4),
                        "support": round(base_price * 0.95, 4),
                        "resistance": round(base_price * 1.05, 4)
                    },
                    "sentiment": {
                        "score": round(random.uniform(0.3, 0.8), 2),
                        "trend": "bullish" if change_pct > 2 else "bearish" if change_pct < -2 else "neutral"
                    },
                    "lastUpdated": datetime.now(timezone.utc).isoformat()
                })
            
            return {
                "watchlist": watchlist,
                "totalSymbols": len(watchlist),
                "lastUpdated": datetime.now(timezone.utc).isoformat()
            }
        
        watchlist = await market_data_service.get_watchlist()
        return watchlist
    except Exception as e:
        logger.error(f"Failed to get market watchlist: {e}")
        raise HTTPException(status_code=500, detail=f"Market watchlist error: {str(e)}")

@app.post("/api/v1/market/watchlist/{symbol}")
async def add_to_watchlist(symbol: str, alert_data: dict = None):
    """Add symbol to watchlist with optional alerts"""
    try:
        market_data_service = registry.get_service("market_data_service")
        if not market_data_service:
            return {
                "symbol": symbol.upper(),
                "status": "added",
                "alerts": alert_data or {},
                "addedAt": datetime.now(timezone.utc).isoformat(),
                "message": "Symbol added to watchlist successfully (mock mode)"
            }
        
        result = await market_data_service.add_to_watchlist(symbol, alert_data)
        return result
    except Exception as e:
        logger.error(f"Failed to add {symbol} to watchlist: {e}")
        raise HTTPException(status_code=500, detail=f"Watchlist addition error: {str(e)}")

@app.delete("/api/v1/market/watchlist/{symbol}")
async def remove_from_watchlist(symbol: str):
    """Remove symbol from watchlist"""
    try:
        market_data_service = registry.get_service("market_data_service")
        if not market_data_service:
            return {
                "symbol": symbol.upper(),
                "status": "removed",
                "removedAt": datetime.now(timezone.utc).isoformat(),
                "message": "Symbol removed from watchlist successfully (mock mode)"
            }
        
        result = await market_data_service.remove_from_watchlist(symbol)
        return result
    except Exception as e:
        logger.error(f"Failed to remove {symbol} from watchlist: {e}")
        raise HTTPException(status_code=500, detail=f"Watchlist removal error: {str(e)}")

@app.get("/api/v1/market/historical/{symbol}")
async def get_historical_market_data(
    symbol: str, 
    timeframe: str = "1h", 
    period: str = "30d",
    limit: int = 100
):
    """Get historical market data with flexible timeframes"""
    try:
        market_data_service = registry.get_service("market_data_service")
        if not market_data_service:
            # Generate mock historical data
            import random
            from datetime import timedelta
            
            base_price = 67234.85 if symbol.upper() == "BTC" else 3847.92 if symbol.upper() == "ETH" else 142.73
            data_points = []
            current_time = datetime.now(timezone.utc)
            
            # Generate data points based on timeframe
            time_delta = timedelta(hours=1) if timeframe == "1h" else timedelta(days=1) if timeframe == "1d" else timedelta(minutes=15)
            
            for i in range(limit):
                timestamp = current_time - (time_delta * i)
                price_variation = random.uniform(0.95, 1.05)
                
                open_price = base_price * price_variation
                close_price = open_price * random.uniform(0.98, 1.02)
                high_price = max(open_price, close_price) * random.uniform(1.0, 1.02)
                low_price = min(open_price, close_price) * random.uniform(0.98, 1.0)
                volume = random.randint(1000000, 50000000)
                
                data_points.append({
                    "timestamp": timestamp.isoformat(),
                    "open": round(open_price, 4),
                    "high": round(high_price, 4),
                    "low": round(low_price, 4),
                    "close": round(close_price, 4),
                    "volume": volume,
                    "trades": random.randint(1000, 10000)
                })
            
            data_points.reverse()  # Chronological order
            
            return {
                "symbol": symbol.upper(),
                "timeframe": timeframe,
                "period": period,
                "data": data_points,
                "count": len(data_points),
                "lastUpdated": datetime.now(timezone.utc).isoformat()
            }
        
        historical_data = await market_data_service.get_historical_data(symbol, timeframe, period, limit)
        return historical_data
    except Exception as e:
        logger.error(f"Failed to get historical data for {symbol}: {e}")
        raise HTTPException(status_code=500, detail=f"Historical data error: {str(e)}")

@app.get("/api/v1/market/technical-analysis/{symbol}")
async def get_technical_analysis(symbol: str, timeframe: str = "1h"):
    """Get comprehensive technical analysis for a symbol"""
    try:
        market_data_service = registry.get_service("market_data_service")
        if not market_data_service:
            import random
            return {
                "symbol": symbol.upper(),
                "timeframe": timeframe,
                "indicators": {
                    "rsi": {
                        "value": round(random.uniform(25, 75), 1),
                        "signal": "neutral",
                        "interpretation": "Neither overbought nor oversold"
                    },
                    "macd": {
                        "macd": round(random.uniform(-100, 100), 2),
                        "signal": round(random.uniform(-100, 100), 2),
                        "histogram": round(random.uniform(-50, 50), 2),
                        "crossover": "bullish" if random.choice([True, False]) else "bearish"
                    },
                    "movingAverages": {
                        "sma20": round(random.uniform(60000, 70000), 2),
                        "sma50": round(random.uniform(58000, 72000), 2),
                        "ema12": round(random.uniform(62000, 68000), 2),
                        "ema26": round(random.uniform(61000, 69000), 2)
                    },
                    "bollingerBands": {
                        "upper": round(random.uniform(68000, 72000), 2),
                        "middle": round(random.uniform(65000, 68000), 2),
                        "lower": round(random.uniform(62000, 65000), 2),
                        "bandwidth": round(random.uniform(0.05, 0.15), 3)
                    },
                    "stochastic": {
                        "k": round(random.uniform(20, 80), 1),
                        "d": round(random.uniform(20, 80), 1),
                        "signal": "neutral"
                    }
                },
                "patterns": [
                    {
                        "name": "Bull Flag",
                        "confidence": round(random.uniform(0.6, 0.9), 2),
                        "status": "forming"
                    },
                    {
                        "name": "Support Level",
                        "level": round(random.uniform(65000, 67000), 2),
                        "confidence": round(random.uniform(0.7, 0.95), 2)
                    }
                ],
                "sentiment": {
                    "overall": random.choice(["bullish", "bearish", "neutral"]),
                    "score": round(random.uniform(0.3, 0.8), 2),
                    "confidence": round(random.uniform(0.6, 0.9), 2)
                },
                "recommendation": {
                    "action": random.choice(["buy", "sell", "hold"]),
                    "strength": random.choice(["weak", "moderate", "strong"]),
                    "reasoning": "Based on current technical indicators and market conditions"
                },
                "lastUpdated": datetime.now(timezone.utc).isoformat()
            }
        
        technical_analysis = await market_data_service.get_technical_analysis(symbol, timeframe)
        return technical_analysis
    except Exception as e:
        logger.error(f"Failed to get technical analysis for {symbol}: {e}")
        raise HTTPException(status_code=500, detail=f"Technical analysis error: {str(e)}")

@app.get("/api/v1/market/sentiment")
async def get_market_sentiment():
    """Get overall market sentiment and fear/greed index"""
    try:
        market_data_service = registry.get_service("market_data_service")
        if not market_data_service:
            import random
            return {
                "overall": {
                    "sentiment": random.choice(["bullish", "bearish", "neutral"]),
                    "score": round(random.uniform(0.3, 0.8), 2),
                    "fearGreedIndex": random.randint(20, 80),
                    "marketCondition": random.choice(["bull_market", "bear_market", "sideways"])
                },
                "sectors": [
                    {
                        "name": "DeFi",
                        "sentiment": "bullish",
                        "score": round(random.uniform(0.6, 0.8), 2),
                        "topCoins": ["UNI", "AAVE", "COMP"]
                    },
                    {
                        "name": "Layer 1",
                        "sentiment": "neutral",
                        "score": round(random.uniform(0.4, 0.6), 2),
                        "topCoins": ["ETH", "SOL", "ADA"]
                    },
                    {
                        "name": "Gaming",
                        "sentiment": "bearish",
                        "score": round(random.uniform(0.2, 0.4), 2),
                        "topCoins": ["AXS", "SAND", "MANA"]
                    }
                ],
                "socialMetrics": {
                    "twitterMentions": random.randint(10000, 100000),
                    "redditPosts": random.randint(1000, 10000),
                    "newsArticles": random.randint(100, 1000),
                    "influencerSentiment": round(random.uniform(0.3, 0.8), 2)
                },
                "volatilityIndex": round(random.uniform(0.15, 0.45), 2),
                "marketDominance": {
                    "btc": round(random.uniform(40, 50), 1),
                    "eth": round(random.uniform(15, 25), 1),
                    "altcoins": round(random.uniform(30, 40), 1)
                },
                "lastUpdated": datetime.now(timezone.utc).isoformat()
            }
        
        sentiment = await market_data_service.get_market_sentiment()
        return sentiment
    except Exception as e:
        logger.error(f"Failed to get market sentiment: {e}")
        raise HTTPException(status_code=500, detail=f"Market sentiment error: {str(e)}")

@app.get("/api/v1/market/alerts")
async def get_market_alerts():
    """Get active market alerts and notifications"""
    try:
        market_data_service = registry.get_service("market_data_service")
        if not market_data_service:
            return {
                "alerts": [
                    {
                        "id": "alert_001",
                        "type": "price_alert",
                        "symbol": "BTC",
                        "condition": "price_above",
                        "threshold": 68000.0,
                        "currentValue": 67234.85,
                        "status": "active",
                        "triggered": False,
                        "createdAt": "2024-01-15T10:00:00Z"
                    },
                    {
                        "id": "alert_002",
                        "type": "volume_alert",
                        "symbol": "ETH",
                        "condition": "volume_spike",
                        "threshold": 50000000,
                        "currentValue": 45678912,
                        "status": "active",
                        "triggered": False,
                        "createdAt": "2024-01-15T11:30:00Z"
                    },
                    {
                        "id": "alert_003",
                        "type": "technical_alert",
                        "symbol": "SOL",
                        "condition": "rsi_oversold",
                        "threshold": 30,
                        "currentValue": 28.5,
                        "status": "triggered",
                        "triggered": True,
                        "triggeredAt": "2024-01-15T14:45:00Z",
                        "createdAt": "2024-01-15T09:15:00Z"
                    }
                ],
                "totalAlerts": 3,
                "activeAlerts": 2,
                "triggeredAlerts": 1,
                "lastUpdated": datetime.now(timezone.utc).isoformat()
            }
        
        alerts = await market_data_service.get_market_alerts()
        return alerts
    except Exception as e:
        logger.error(f"Failed to get market alerts: {e}")
        raise HTTPException(status_code=500, detail=f"Market alerts error: {str(e)}")

@app.post("/api/v1/market/alerts")
async def create_market_alert(alert_data: dict):
    """Create a new market alert"""
    try:
        market_data_service = registry.get_service("market_data_service")
        if not market_data_service:
            import uuid
            return {
                "alertId": str(uuid.uuid4()),
                "symbol": alert_data.get("symbol"),
                "type": alert_data.get("type"),
                "condition": alert_data.get("condition"),
                "threshold": alert_data.get("threshold"),
                "status": "active",
                "createdAt": datetime.now(timezone.utc).isoformat(),
                "message": "Market alert created successfully (mock mode)"
            }
        
        alert = await market_data_service.create_alert(alert_data)
        return alert
    except Exception as e:
        logger.error(f"Failed to create market alert: {e}")
        raise HTTPException(status_code=500, detail=f"Alert creation error: {str(e)}")

# ==========================================
# TRADING OVERVIEW API ENDPOINTS
# ==========================================

@app.get("/api/v1/trading/overview")
async def get_trading_overview():
    """Get comprehensive trading overview dashboard data"""
    try:
        trading_service = registry.get_service("trading_overview_service")
        if not trading_service:
            # Return comprehensive mock trading overview
            return {
                "summary": {
                    "totalEquity": 1247893.45,
                    "dailyPnL": 4081.85,
                    "totalPnL": 24612.07,
                    "totalReturn": 2.01,
                    "winRate": 0.742,
                    "totalTrades": 1847,
                    "activeTrades": 23,
                    "openPositions": 17,
                    "availableCash": 456789.12,
                    "marginUsed": 234567.89,
                    "buyingPower": 678901.23,
                    "riskExposure": 0.68,
                    "maxDrawdown": 0.087,
                    "sharpeRatio": 1.84,
                    "lastUpdated": datetime.now(timezone.utc).isoformat()
                },
                "recentTrades": [
                    {
                        "id": "trade_001",
                        "symbol": "BTC",
                        "type": "buy",
                        "quantity": 0.15,
                        "price": 67100.00,
                        "value": 10065.00,
                        "timestamp": "2024-01-15T15:28:00Z",
                        "status": "filled",
                        "agent": "marcus_momentum",
                        "strategy": "momentum_breakout",
                        "pnl": 234.56,
                        "pnlPercent": 2.33
                    },
                    {
                        "id": "trade_002", 
                        "symbol": "ETH",
                        "type": "sell",
                        "quantity": 2.5,
                        "price": 3850.00,
                        "value": 9625.00,
                        "timestamp": "2024-01-15T15:25:00Z",
                        "status": "filled",
                        "agent": "sophia_reversion",
                        "strategy": "mean_reversion",
                        "pnl": -89.34,
                        "pnlPercent": -0.92
                    },
                    {
                        "id": "trade_003",
                        "symbol": "SOL",
                        "type": "buy",
                        "quantity": 35.0,
                        "price": 142.50,
                        "value": 4987.50,
                        "timestamp": "2024-01-15T15:20:00Z",
                        "status": "filled",
                        "agent": "alex_arbitrage",
                        "strategy": "arbitrage",
                        "pnl": 156.78,
                        "pnlPercent": 3.14
                    }
                ],
                "openPositions": [
                    {
                        "symbol": "BTC",
                        "side": "long",
                        "quantity": 1.25,
                        "averagePrice": 66789.45,
                        "currentPrice": 67234.85,
                        "marketValue": 84043.56,
                        "unrealizedPnL": 556.75,
                        "unrealizedPnLPercent": 0.67,
                        "entryTime": "2024-01-15T10:30:00Z",
                        "stopLoss": 65234.56,
                        "takeProfit": 69876.54,
                        "agent": "marcus_momentum",
                        "riskAmount": 1554.89
                    },
                    {
                        "symbol": "ETH",
                        "side": "long", 
                        "quantity": 8.75,
                        "averagePrice": 3789.23,
                        "currentPrice": 3847.92,
                        "marketValue": 33669.30,
                        "unrealizedPnL": 514.04,
                        "unrealizedPnLPercent": 1.55,
                        "entryTime": "2024-01-15T09:45:00Z",
                        "stopLoss": 3650.00,
                        "takeProfit": 4000.00,
                        "agent": "alex_arbitrage",
                        "riskAmount": 1218.57
                    },
                    {
                        "symbol": "SOL",
                        "side": "short",
                        "quantity": 120.0,
                        "averagePrice": 145.67,
                        "currentPrice": 142.73,
                        "marketValue": 17127.60,
                        "unrealizedPnL": 352.80,
                        "unrealizedPnLPercent": 2.04,
                        "entryTime": "2024-01-15T08:15:00Z",
                        "stopLoss": 148.90,
                        "takeProfit": 138.50,
                        "agent": "sophia_reversion",
                        "riskAmount": 387.60
                    }
                ],
                "strategyPerformance": [
                    {
                        "strategy": "momentum_trading",
                        "totalPnL": 8945.67,
                        "totalPnLPercent": 3.89,
                        "dailyPnL": 1247.85,
                        "winRate": 0.74,
                        "trades": 89,
                        "avgTrade": 100.51,
                        "maxDrawdown": 0.045,
                        "sharpeRatio": 1.84,
                        "allocation": 45.2,
                        "status": "active"
                    },
                    {
                        "strategy": "arbitrage",
                        "totalPnL": 6789.34,
                        "totalPnLPercent": 2.97,
                        "dailyPnL": 892.34,
                        "winRate": 0.89,
                        "trades": 156,
                        "avgTrade": 43.52,
                        "maxDrawdown": 0.012,
                        "sharpeRatio": 2.47,
                        "allocation": 32.1,
                        "status": "active"
                    },
                    {
                        "strategy": "mean_reversion",
                        "totalPnL": -1234.67,
                        "totalPnLPercent": -0.56,
                        "dailyPnL": -234.67,
                        "winRate": 0.52,
                        "trades": 67,
                        "avgTrade": -18.43,
                        "maxDrawdown": 0.087,
                        "sharpeRatio": 0.89,
                        "allocation": 22.7,
                        "status": "paused"
                    }
                ],
                "riskMetrics": {
                    "portfolioVaR": 15678.90,
                    "dailyVaR": 5234.56,
                    "maxExposure": 0.75,
                    "currentExposure": 0.68,
                    "leverageRatio": 1.35,
                    "diversificationScore": 0.82,
                    "correlationRisk": 0.24,
                    "marginUtilization": 0.56,
                    "liquidityRisk": "low",
                    "lastStressTest": "2024-01-15T12:00:00Z"
                }
            }
        
        overview = await trading_service.get_trading_overview()
        return overview
    except Exception as e:
        logger.error(f"Failed to get trading overview: {e}")
        raise HTTPException(status_code=500, detail=f"Trading overview error: {str(e)}")

@app.get("/api/v1/trading/positions")
async def get_trading_positions(status: str = "all"):
    """Get detailed trading positions"""
    try:
        trading_service = registry.get_service("trading_overview_service")
        if not trading_service:
            # Filter positions based on status
            all_positions = [
                {
                    "id": "pos_001",
                    "symbol": "BTC",
                    "side": "long",
                    "quantity": 1.25,
                    "averagePrice": 66789.45,
                    "currentPrice": 67234.85,
                    "marketValue": 84043.56,
                    "unrealizedPnL": 556.75,
                    "unrealizedPnLPercent": 0.67,
                    "entryTime": "2024-01-15T10:30:00Z",
                    "stopLoss": 65234.56,
                    "takeProfit": 69876.54,
                    "agent": "marcus_momentum",
                    "strategy": "momentum_trading",
                    "riskAmount": 1554.89,
                    "status": "open"
                },
                {
                    "id": "pos_002",
                    "symbol": "ETH",
                    "side": "long",
                    "quantity": 8.75,
                    "averagePrice": 3789.23,
                    "currentPrice": 3847.92,
                    "marketValue": 33669.30,
                    "unrealizedPnL": 514.04,
                    "unrealizedPnLPercent": 1.55,
                    "entryTime": "2024-01-15T09:45:00Z",
                    "stopLoss": 3650.00,
                    "takeProfit": 4000.00,
                    "agent": "alex_arbitrage",
                    "strategy": "arbitrage",
                    "riskAmount": 1218.57,
                    "status": "open"
                },
                {
                    "id": "pos_003",
                    "symbol": "MATIC",
                    "side": "long",
                    "quantity": 5000.0,
                    "averagePrice": 0.8567,
                    "currentPrice": 0.8934,
                    "marketValue": 4467.00,
                    "unrealizedPnL": 183.50,
                    "unrealizedPnLPercent": 4.28,
                    "entryTime": "2024-01-14T16:20:00Z",
                    "stopLoss": 0.8100,
                    "takeProfit": 0.9500,
                    "agent": "sophia_reversion",
                    "strategy": "mean_reversion",
                    "riskAmount": 233.50,
                    "status": "closed"
                }
            ]
            
            if status != "all":
                filtered_positions = [pos for pos in all_positions if pos["status"] == status]
                return {"positions": filtered_positions, "count": len(filtered_positions)}
            
            return {"positions": all_positions, "count": len(all_positions)}
        
        positions = await trading_service.get_positions(status)
        return positions
    except Exception as e:
        logger.error(f"Failed to get trading positions: {e}")
        raise HTTPException(status_code=500, detail=f"Trading positions error: {str(e)}")

@app.get("/api/v1/trading/orders")
async def get_trading_orders(status: str = "all", limit: int = 50):
    """Get trading orders with optional status filter"""
    try:
        trading_service = registry.get_service("trading_overview_service")
        if not trading_service:
            # Mock orders data
            all_orders = [
                {
                    "id": "order_001",
                    "symbol": "BTC",
                    "type": "market",
                    "side": "buy",
                    "quantity": 0.15,
                    "price": None,
                    "filledPrice": 67100.00,
                    "filledQuantity": 0.15,
                    "status": "filled",
                    "timestamp": "2024-01-15T15:28:00Z",
                    "agent": "marcus_momentum",
                    "strategy": "momentum_trading",
                    "value": 10065.00
                },
                {
                    "id": "order_002",
                    "symbol": "ETH",
                    "type": "limit",
                    "side": "sell",
                    "quantity": 2.5,
                    "price": 3850.00,
                    "filledPrice": 3850.00,
                    "filledQuantity": 2.5,
                    "status": "filled",
                    "timestamp": "2024-01-15T15:25:00Z",
                    "agent": "sophia_reversion",
                    "strategy": "mean_reversion",
                    "value": 9625.00
                },
                {
                    "id": "order_003",
                    "symbol": "SOL",
                    "type": "limit",
                    "side": "buy",
                    "quantity": 50.0,
                    "price": 140.00,
                    "filledPrice": None,
                    "filledQuantity": 0,
                    "status": "pending",
                    "timestamp": "2024-01-15T15:30:00Z",
                    "agent": "alex_arbitrage",
                    "strategy": "arbitrage",
                    "value": 7000.00
                }
            ]
            
            if status != "all":
                filtered_orders = [order for order in all_orders if order["status"] == status]
                return {"orders": filtered_orders, "count": len(filtered_orders)}
            
            return {"orders": all_orders[:limit], "count": len(all_orders)}
        
        orders = await trading_service.get_orders(status, limit)
        return orders
    except Exception as e:
        logger.error(f"Failed to get trading orders: {e}")
        raise HTTPException(status_code=500, detail=f"Trading orders error: {str(e)}")

@app.post("/api/v1/trading/orders")
async def create_trading_order(order_data: dict):
    """Create a new trading order with enhanced exchange integration"""
    try:
        trading_service = registry.get_service("trading_overview_service")
        
        # Enhanced order creation with live trading support
        order_result = {
            "orderId": str(uuid.uuid4()),
            "symbol": order_data.get("symbol"),
            "type": order_data.get("type"),
            "side": order_data.get("side"),
            "quantity": order_data.get("quantity"),
            "price": order_data.get("price"),
            "exchange": order_data.get("exchange", "auto"),
            "status": "pending",
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "isLiveTrading": order_data.get("isLiveTrading", False),
            "forcePaper": order_data.get("forcePaper", True),
            "safetyChecks": {
                "positionSize": True,
                "priceDeviation": True,
                "balanceCheck": True
            },
            "message": "Order created successfully"
        }
        
        # Add execution details for paper vs live
        if order_data.get("isLiveTrading", False):
            order_result["executionMode"] = "live"
            order_result["riskWarning"] = "Live trading with real funds"
            order_result["message"] += " (LIVE TRADING)"
        else:
            order_result["executionMode"] = "paper"
            order_result["message"] += " (paper trading mode)"
        
        # Add order validation results
        order_result["validation"] = {
            "orderSize": "valid",
            "priceRange": "valid", 
            "balanceSufficient": True,
            "marketOpen": True,
            "riskLimits": "within_limits"
        }
        
        if trading_service:
            order = await trading_service.create_order(order_data)
            return order
        
        return {"success": True, "order": order_result}
    except Exception as e:
        logger.error(f"Failed to create trading order: {e}")
        raise HTTPException(status_code=500, detail=f"Order creation error: {str(e)}")

@app.put("/api/v1/trading/orders/{order_id}")
async def update_trading_order(order_id: str, update_data: dict):
    """Update a trading order"""
    try:
        trading_service = registry.get_service("trading_overview_service")
        if not trading_service:
            return {
                "orderId": order_id,
                "status": update_data.get("status", "updated"),
                "updatedAt": datetime.now(timezone.utc).isoformat(),
                "message": "Order updated successfully (mock mode)"
            }
        
        result = await trading_service.update_order(order_id, update_data)
        return result
    except Exception as e:
        logger.error(f"Failed to update trading order: {e}")
        raise HTTPException(status_code=500, detail=f"Order update error: {str(e)}")

@app.delete("/api/v1/trading/orders/{order_id}")
async def cancel_trading_order(order_id: str):
    """Cancel a trading order"""
    try:
        trading_service = registry.get_service("trading_overview_service")
        if not trading_service:
            return {
                "orderId": order_id,
                "status": "cancelled",
                "cancelledAt": datetime.now(timezone.utc).isoformat(),
                "message": "Order cancelled successfully (mock mode)"
            }
        
        result = await trading_service.cancel_order(order_id)
        return result
    except Exception as e:
        logger.error(f"Failed to cancel trading order: {e}")
        raise HTTPException(status_code=500, detail=f"Order cancellation error: {str(e)}")

@app.get("/api/v1/trading/performance")
async def get_trading_performance(timeframe: str = "30d"):
    """Get detailed trading performance metrics"""
    try:
        trading_service = registry.get_service("trading_overview_service")
        if not trading_service:
            return {
                "timeframe": timeframe,
                "summary": {
                    "totalReturn": 24612.07,
                    "totalReturnPercent": 2.01,
                    "sharpeRatio": 1.84,
                    "maxDrawdown": 0.087,
                    "winRate": 0.742,
                    "profitFactor": 1.65,
                    "averageTrade": 13.33,
                    "bestTrade": 1247.85,
                    "worstTrade": -456.78,
                    "totalTrades": 1847,
                    "winningTrades": 1371,
                    "losingTrades": 476
                },
                "dailyReturns": [
                    {"date": "2024-01-10", "return": 234.56, "cumulative": 23456.78},
                    {"date": "2024-01-11", "return": 456.78, "cumulative": 23913.56},
                    {"date": "2024-01-12", "return": -123.45, "cumulative": 23790.11},
                    {"date": "2024-01-13", "return": 789.01, "cumulative": 24579.12},
                    {"date": "2024-01-14", "return": 324.67, "cumulative": 24903.79},
                    {"date": "2024-01-15", "return": 289.73, "cumulative": 25193.52}
                ],
                "monthlyBreakdown": [
                    {"month": "2023-12", "profit": 5234.56, "trades": 156, "winRate": 0.78},
                    {"month": "2024-01", "profit": 4081.85, "trades": 89, "winRate": 0.74}
                ],
                "strategyBreakdown": [
                    {
                        "strategy": "momentum_trading",
                        "profit": 8945.67,
                        "profitPercent": 3.89,
                        "trades": 89,
                        "winRate": 0.74,
                        "contribution": 0.36
                    },
                    {
                        "strategy": "arbitrage",
                        "profit": 6789.34,
                        "profitPercent": 2.97,
                        "trades": 156,
                        "winRate": 0.89,
                        "contribution": 0.28
                    },
                    {
                        "strategy": "mean_reversion",
                        "profit": -1234.67,
                        "profitPercent": -0.56,
                        "trades": 67,
                        "winRate": 0.52,
                        "contribution": -0.05
                    }
                ],
                "lastUpdated": datetime.now(timezone.utc).isoformat()
            }
        
        performance = await trading_service.get_performance_metrics(timeframe)
        return performance
    except Exception as e:
        logger.error(f"Failed to get trading performance: {e}")
        raise HTTPException(status_code=500, detail=f"Trading performance error: {str(e)}")

@app.get("/api/v1/trading/risk-metrics")
async def get_trading_risk_metrics():
    """Get comprehensive risk metrics for trading"""
    try:
        trading_service = registry.get_service("trading_overview_service")
        if not trading_service:
            return {
                "overall": {
                    "portfolioVaR": 15678.90,
                    "dailyVaR": 5234.56,
                    "maxExposure": 0.75,
                    "currentExposure": 0.68,
                    "leverageRatio": 1.35,
                    "marginUtilization": 0.56
                },
                "diversification": {
                    "diversificationScore": 0.82,
                    "correlationRisk": 0.24,
                    "sectorConcentration": {
                        "crypto": 0.85,
                        "defi": 0.15,
                        "nft": 0.0
                    },
                    "assetConcentration": {
                        "BTC": 0.45,
                        "ETH": 0.32,
                        "SOL": 0.15,
                        "others": 0.08
                    }
                },
                "liquidityMetrics": {
                    "liquidityRisk": "low",
                    "averageBidAskSpread": 0.025,
                    "marketDepth": "high",
                    "liquidationRisk": 0.12
                },
                "stressTests": [
                    {
                        "scenario": "market_crash_20",
                        "expectedLoss": 24567.89,
                        "probability": 0.05,
                        "description": "20% market crash scenario"
                    },
                    {
                        "scenario": "volatility_spike",
                        "expectedLoss": 12345.67,
                        "probability": 0.15,
                        "description": "Volatility spike to 50%+"
                    },
                    {
                        "scenario": "liquidity_crunch",
                        "expectedLoss": 8901.23,
                        "probability": 0.10,
                        "description": "Market liquidity shortage"
                    }
                ],
                "alerts": [
                    {
                        "type": "exposure_warning",
                        "level": "medium",
                        "message": "Portfolio exposure approaching 70% limit",
                        "currentValue": 0.68,
                        "threshold": 0.70
                    }
                ],
                "lastUpdated": datetime.now(timezone.utc).isoformat()
            }
        
        risk_metrics = await trading_service.get_risk_metrics()
        return risk_metrics
    except Exception as e:
        logger.error(f"Failed to get trading risk metrics: {e}")
        raise HTTPException(status_code=500, detail=f"Trading risk metrics error: {str(e)}")

# ==========================================
# ENHANCED LIVE TRADING ENDPOINTS
# ==========================================

@app.post("/api/v1/trading/live/order")
async def create_live_trading_order(order_data: dict):
    """Create a live trading order with enhanced safety checks"""
    try:
        # Enhanced order data with safety checks
        enhanced_order = {
            "id": str(uuid.uuid4()),
            "symbol": order_data.get("symbol"),
            "side": order_data.get("side"),
            "type": order_data.get("type", "limit"),
            "amount": order_data.get("amount", 0),
            "price": order_data.get("price"),
            "exchange": order_data.get("exchange", "binance"),
            "isLiveTrading": True,
            "safetyChecks": {
                "maxOrderSize": 0.1,  # 10% of balance max
                "priceDeviationLimit": 0.02,  # 2% price deviation max
                "dailyLossLimit": 1000,  # $1000 daily loss limit
                "balanceRequired": True
            },
            "status": "pending_validation",
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
        # Simulate safety check validations
        safety_passed = True
        safety_messages = []
        
        if enhanced_order["amount"] > enhanced_order["safetyChecks"]["maxOrderSize"]:
            safety_passed = False
            safety_messages.append("Order size exceeds maximum allowed")
        
        if safety_passed:
            enhanced_order["status"] = "submitted"
            enhanced_order["message"] = "Live order submitted successfully"
        else:
            enhanced_order["status"] = "rejected"
            enhanced_order["message"] = "Order rejected by safety checks"
            enhanced_order["rejectionReasons"] = safety_messages
        
        return {"success": safety_passed, "order": enhanced_order}
        
    except Exception as e:
        logger.error(f"Failed to create live trading order: {e}")
        raise HTTPException(status_code=500, detail=f"Live trading order error: {str(e)}")

@app.get("/api/v1/trading/live/positions")
async def get_live_positions(exchange: str = "all"):
    """Get live trading positions from exchanges"""
    try:
        positions = [
            {
                "id": f"pos_{uuid.uuid4()}",
                "symbol": "BTC/USDT",
                "exchange": "binance",
                "side": "long",
                "size": 0.0234,
                "entryPrice": 67234.85,
                "currentPrice": 67891.23,
                "unrealizedPnl": 15.37,
                "realizedPnl": 0,
                "marginUsed": 1576.89,
                "leverage": 1.0,
                "timestamp": datetime.now(timezone.utc).isoformat()
            },
            {
                "id": f"pos_{uuid.uuid4()}",
                "symbol": "ETH/USDT", 
                "exchange": "coinbase",
                "side": "long",
                "size": 1.247,
                "entryPrice": 3847.92,
                "currentPrice": 3889.45,
                "unrealizedPnl": 51.73,
                "realizedPnl": 0,
                "marginUsed": 4798.32,
                "leverage": 1.0,
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
        ]
        
        if exchange != "all":
            positions = [p for p in positions if p["exchange"] == exchange]
        
        return {"positions": positions, "totalPositions": len(positions)}
        
    except Exception as e:
        logger.error(f"Failed to get live positions: {e}")
        raise HTTPException(status_code=500, detail=f"Live positions error: {str(e)}")

@app.get("/api/v1/trading/live/balances")
async def get_live_balances(exchange: str = "all"):
    """Get live trading balances from exchanges"""
    try:
        balances = [
            {
                "exchange": "binance",
                "asset": "USDT",
                "free": 5247.83,
                "locked": 1576.89,
                "total": 6824.72,
                "usdValue": 6824.72
            },
            {
                "exchange": "binance",
                "asset": "BTC",
                "free": 0.0234,
                "locked": 0,
                "total": 0.0234,
                "usdValue": 1588.65
            },
            {
                "exchange": "coinbase",
                "asset": "USD",
                "free": 3247.19,
                "locked": 0,
                "total": 3247.19,
                "usdValue": 3247.19
            },
            {
                "exchange": "coinbase",
                "asset": "ETH",
                "free": 1.247,
                "locked": 0,
                "total": 1.247,
                "usdValue": 4850.32
            }
        ]
        
        if exchange != "all":
            balances = [b for b in balances if b["exchange"] == exchange]
        
        total_usd_value = sum(b["usdValue"] for b in balances)
        
        return {
            "balances": balances,
            "totalUsdValue": total_usd_value,
            "exchangeCount": len(set(b["exchange"] for b in balances))
        }
        
    except Exception as e:
        logger.error(f"Failed to get live balances: {e}")
        raise HTTPException(status_code=500, detail=f"Live balances error: {str(e)}")

@app.get("/api/v1/trading/live/status")
async def get_live_trading_status():
    """Get live trading system status"""
    try:
        return {
            "systemStatus": "operational",
            "exchanges": {
                "binance": {
                    "connected": True,
                    "lastPing": datetime.now(timezone.utc).isoformat(),
                    "orderBookHealth": "healthy",
                    "websocketConnected": True,
                    "apiLimitsRemaining": 5000,
                    "responseTime": 45
                },
                "coinbase": {
                    "connected": True,
                    "lastPing": datetime.now(timezone.utc).isoformat(),
                    "orderBookHealth": "healthy",
                    "websocketConnected": True,
                    "apiLimitsRemaining": 10000,
                    "responseTime": 32
                },
                "hyperliquid": {
                    "connected": False,
                    "lastPing": None,
                    "orderBookHealth": "disconnected",
                    "websocketConnected": False,
                    "apiLimitsRemaining": 0,
                    "responseTime": None
                }
            },
            "safetyFeatures": {
                "circuitBreakers": True,
                "positionLimits": True,
                "dailyLossLimits": True,
                "priceDeviationChecks": True,
                "emergencyStopEnabled": True
            },
            "performanceMetrics": {
                "ordersPerSecond": 15.7,
                "averageExecutionTime": 127,
                "successRate": 99.8,
                "uptime": "99.95%"
            },
            "lastUpdated": datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"Failed to get live trading status: {e}")
        raise HTTPException(status_code=500, detail=f"Live trading status error: {str(e)}")

@app.post("/api/v1/trading/live/emergency-stop")
async def emergency_stop_trading():
    """Emergency stop all live trading activities"""
    try:
        # Simulate emergency stop
        return {
            "status": "emergency_stop_initiated",
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "actions": [
                "All pending orders cancelled",
                "New order submission disabled",
                "Risk management alerts triggered",
                "Positions marked for review"
            ],
            "message": "Emergency stop completed successfully",
            "nextSteps": "Manual review required to resume trading"
        }
        
    except Exception as e:
        logger.error(f"Failed to execute emergency stop: {e}")
        raise HTTPException(status_code=500, detail=f"Emergency stop error: {str(e)}")

# Development and debugging endpoints
if DEBUG:
    @app.get("/api/v1/debug/services")
    async def debug_services():
        """Debug endpoint to check all service statuses"""
        return {
            "services": registry.list_services(),
            "connections": registry.list_connections(),
            "registry_initialized": registry.is_initialized(),
            "database_initialized": db_manager.is_initialized()
        }
    
    @app.get("/api/v1/debug/health-detailed")
    async def debug_health():
        """Detailed health check for debugging"""
        return await registry.health_check()

# Include Phase 2 Agent Trading API endpoints
from api.phase2_endpoints import router as phase2_router
app.include_router(phase2_router)

# Include Phase 6-8 Autonomous Trading API endpoints
from api.autonomous_endpoints import router as autonomous_router
app.include_router(autonomous_router)

# Include Expert Agents API endpoints
from api.v1.expert_agents_routes import router as expert_agents_router
app.include_router(expert_agents_router)

# Chat Terminal API Endpoints
@app.post("/api/v1/chat/message")
async def handle_chat_message(request: Dict[str, Any]):
    """Handle chat terminal messages and commands"""
    try:
        content = request.get("content", "").strip()
        message_type = request.get("type", "message")
        
        if not content:
            return {"success": False, "error": "Message content is required"}
        
        # Handle commands
        if content.startswith("/"):
            return await process_chat_command(content)
        else:
            # Handle regular messages - send to LLM
            return await process_chat_message(content)
            
    except Exception as e:
        logger.error(f"Error handling chat message: {e}")
        return {"success": False, "error": str(e)}

async def process_chat_command(command: str) -> Dict[str, Any]:
    """Process chat terminal commands"""
    try:
        parts = command[1:].split()
        cmd = parts[0].lower() if parts else ""
        args = parts[1:] if len(parts) > 1 else []
        
        if cmd == "status":
            return {
                "success": True,
                "data": {
                    "system_status": "operational",
                    "active_services": len(registry.services),
                    "uptime": "5h 23m",
                    "memory_usage": "45%",
                    "cpu_usage": "23%"
                }
            }
        
        elif cmd == "agents":
            agent_service = registry.get_service("agent_coordinator")
            if agent_service:
                agents = await agent_service.get_all_agents()
                return {"success": True, "data": agents}
            else:
                return {
                    "success": True,
                    "data": [
                        {"name": "Marcus Momentum", "status": "active", "performance": "+12.5%"},
                        {"name": "Alex Arbitrage", "status": "active", "performance": "+8.7%"},
                        {"name": "Sophia Reversion", "status": "idle", "performance": "+15.2%"},
                        {"name": "Riley Risk", "status": "monitoring", "performance": "+5.3%"}
                    ]
                }
        
        elif cmd == "portfolio":
            portfolio_service = registry.get_service("portfolio_service")
            if portfolio_service:
                portfolio = await portfolio_service.get_portfolio_summary()
                return {"success": True, "data": portfolio}
            else:
                return {
                    "success": True,
                    "data": {
                        "total_value": 125678.90,
                        "total_pnl": 8765.43,
                        "positions": 12,
                        "cash_balance": 25432.10
                    }
                }
        
        elif cmd == "trade":
            if len(args) < 3:
                return {"success": False, "error": "Trade command requires: symbol side amount"}
            
            symbol, side, amount = args[0], args[1], args[2]
            
            # Simulate trade execution
            return {
                "success": True,
                "data": {
                    "order_id": f"order_{hash(symbol + side + amount) % 10000}",
                    "symbol": symbol,
                    "side": side,
                    "amount": amount,
                    "status": "executed",
                    "price": 45623.50 if "BTC" in symbol else 2456.78
                }
            }
        
        elif cmd == "goals":
            goal_service = registry.get_service("goal_management")
            if goal_service:
                goals = await goal_service.get_all_goals()
                return {"success": True, "data": goals}
            else:
                return {
                    "success": True,
                    "data": [
                        {"name": "Monthly Profit", "progress": 85.5, "status": "on_track"},
                        {"name": "Risk Management", "progress": 92.3, "status": "achieved"},
                        {"name": "Diversification", "progress": 76.8, "status": "in_progress"}
                    ]
                }
        
        elif cmd == "risk":
            return {
                "success": True,
                "data": {
                    "portfolio_var": 15678.90,
                    "max_drawdown": 8.5,
                    "sharpe_ratio": 2.34,
                    "risk_score": 6,
                    "alerts": 2
                }
            }
        
        elif cmd == "farms":
            farm_service = registry.get_service("farm_management")
            if farm_service:
                farms = await farm_service.get_all_farms_api()
                return {"success": True, "data": farms}
            else:
                return {
                    "success": True,
                    "data": [
                        {"name": "Momentum Farm", "agents": 3, "performance": "+15.2%", "status": "active"},
                        {"name": "Arbitrage Farm", "agents": 2, "performance": "+8.7%", "status": "active"},
                        {"name": "Reversion Farm", "agents": 2, "performance": "+12.1%", "status": "paused"}
                    ]
                }
        
        elif cmd == "vault":
            vault_service = registry.get_service("vault_management")
            if vault_service:
                vaults = await vault_service.get_all_vaults()
                return {"success": True, "data": vaults}
            else:
                return {
                    "success": True,
                    "data": {
                        "master_vault": {"balance": 95432.10, "allocation": "75%"},
                        "trading_vault": {"balance": 45678.90, "allocation": "20%"},
                        "reserve_vault": {"balance": 12345.67, "allocation": "5%"}
                    }
                }
        
        else:
            return {"success": False, "error": f"Unknown command: /{cmd}"}
            
    except Exception as e:
        return {"success": False, "error": f"Command processing error: {str(e)}"}

async def process_chat_message(content: str) -> Dict[str, Any]:
    """Process regular chat messages with LLM"""
    try:
        # Try to get LLM service
        llm_service = registry.get_service("llm_integration")
        
        if llm_service:
            response = await llm_service.process_user_message(content)
            return {
                "success": True,
                "data": {
                    "response": response.get("content", "No response generated"),
                    "agent_name": response.get("agent_name", "Assistant"),
                    "confidence": response.get("confidence", 0.8)
                }
            }
        else:
            # Mock LLM response
            mock_responses = [
                "I understand you're asking about the trading system. Let me analyze the current market conditions.",
                "Based on recent performance data, I can provide insights into our trading strategies.",
                "The current portfolio allocation looks well-balanced. Would you like me to elaborate?",
                "Market conditions are favorable for our momentum strategies right now.",
                "I'm monitoring the risk metrics closely. Everything appears to be within acceptable parameters."
            ]
            
            import random
            response = random.choice(mock_responses)
            
            return {
                "success": True,
                "data": {
                    "response": response,
                    "agent_name": "Trading Assistant",
                    "confidence": 0.85
                }
            }
            
    except Exception as e:
        return {"success": False, "error": f"Message processing error: {str(e)}"}

# WebSocket endpoint for real-time updates
@app.websocket("/ws/dashboard")
async def websocket_dashboard_endpoint(websocket: WebSocket):
    """WebSocket endpoint for real-time dashboard updates"""
    try:
        websocket_service = registry.get_service('websocket')
        await websocket_service.handle_websocket(websocket)
    except Exception as e:
        print(f"WebSocket error: {e}")

# Farm Management API Endpoints - Phase 8
@app.get("/api/v1/farms")
async def get_all_farms():
    """Get all farms"""
    try:
        farm_service = registry.get_service("farm_management")
        if farm_service:
            return await farm_service.get_all_farms_api()
        else:
            # Mock data fallback
            return [
                {
                    "farm_id": "farm_1",
                    "farm_name": "Momentum Farm",
                    "farm_type": "trend_following",
                    "status": "active",
                    "current_agents": 3,
                    "max_agents": 5,
                    "performance": {
                        "total_pnl": 15420.50,
                        "win_rate": 68.5,
                        "active_agents": 3
                    }
                },
                {
                    "farm_id": "farm_2", 
                    "farm_name": "Arbitrage Farm",
                    "farm_type": "arbitrage",
                    "status": "active",
                    "current_agents": 2,
                    "max_agents": 4,
                    "performance": {
                        "total_pnl": 8950.75,
                        "win_rate": 72.1,
                        "active_agents": 2
                    }
                }
            ]
    except Exception as e:
        logger.error(f"Error getting farms: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/farms")
async def create_farm(farm_data: Dict[str, Any]):
    """Create a new farm"""
    try:
        farm_service = registry.get_service("farm_management")
        if farm_service:
            return await farm_service.create_farm_api(farm_data)
        else:
            # Mock creation
            import uuid
            farm_id = str(uuid.uuid4())
            return {
                "farm_id": farm_id,
                "farm_name": farm_data.get("name", "New Farm"),
                "farm_type": farm_data.get("type", "multi_strategy"),
                "status": "inactive",
                "current_agents": 0,
                "max_agents": farm_data.get("max_agents", 5),
                "created_at": datetime.now().isoformat()
            }
    except Exception as e:
        logger.error(f"Error creating farm: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/farms/{farm_id}")
async def get_farm_by_id(farm_id: str):
    """Get farm details by ID"""
    try:
        farm_service = registry.get_service("farm_management")
        if farm_service:
            farm = await farm_service.get_farm_by_id_api(farm_id)
            if not farm:
                raise HTTPException(status_code=404, detail="Farm not found")
            return farm
        else:
            # Mock data
            return {
                "farm_id": farm_id,
                "farm_name": "Sample Farm",
                "farm_type": "multi_strategy",
                "status": "active",
                "current_agents": 2,
                "max_agents": 5,
                "performance": {
                    "total_pnl": 12500.0,
                    "win_rate": 65.0,
                    "active_agents": 2
                }
            }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting farm: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.put("/api/v1/farms/{farm_id}")
async def update_farm(farm_id: str, farm_data: Dict[str, Any]):
    """Update farm configuration"""
    try:
        farm_service = registry.get_service("farm_management")
        if farm_service:
            return await farm_service.update_farm_api(farm_id, farm_data)
        else:
            # Mock update
            return {
                "farm_id": farm_id,
                "farm_name": farm_data.get("name", "Updated Farm"),
                "updated_at": datetime.now().isoformat()
            }
    except Exception as e:
        logger.error(f"Error updating farm: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/v1/farms/{farm_id}")
async def delete_farm(farm_id: str):
    """Delete a farm"""
    try:
        farm_service = registry.get_service("farm_management")
        if farm_service:
            success = await farm_service.delete_farm_api(farm_id)
            return {"success": success}
        else:
            return {"success": True}
    except Exception as e:
        logger.error(f"Error deleting farm: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/farms/{farm_id}/agents")
async def get_farm_agents(farm_id: str):
    """Get agents assigned to a farm"""
    try:
        farm_service = registry.get_service("farm_management")
        if farm_service:
            return await farm_service.get_farm_agents_detailed(farm_id)
        else:
            # Mock data
            return [
                {
                    "agent_id": "agent_1",
                    "name": "Marcus Momentum",
                    "role": "primary",
                    "status": "active",
                    "performance": {
                        "profit": 5420.50,
                        "trades": 45,
                        "win_rate": 68.5
                    }
                }
            ]
    except Exception as e:
        logger.error(f"Error getting farm agents: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/farms/{farm_id}/agents")
async def add_agent_to_farm(farm_id: str, request: Dict[str, Any]):
    """Add agent to farm"""
    try:
        farm_service = registry.get_service("farm_management")
        agent_id = request.get("agent_id")
        role = request.get("role", "support")
        
        if farm_service:
            success = await farm_service.add_agent_to_farm(farm_id, agent_id, role)
            return {"success": success}
        else:
            return {"success": True}
    except Exception as e:
        logger.error(f"Error adding agent to farm: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/v1/farms/{farm_id}/agents/{agent_id}")
async def remove_agent_from_farm(farm_id: str, agent_id: str):
    """Remove agent from farm"""
    try:
        farm_service = registry.get_service("farm_management")
        if farm_service:
            success = await farm_service.remove_agent_from_farm(agent_id, farm_id)
            return {"success": success}
        else:
            return {"success": True}
    except Exception as e:
        logger.error(f"Error removing agent from farm: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/farms/{farm_id}/performance")
async def get_farm_performance(farm_id: str):
    """Get farm performance metrics"""
    try:
        farm_service = registry.get_service("farm_management")
        if farm_service:
            performance = await farm_service.get_farm_performance_detailed(farm_id)
            if not performance:
                raise HTTPException(status_code=404, detail="Farm performance not found")
            return performance
        else:
            # Mock performance data
            return {
                "total_pnl": 15420.50,
                "average_pnl": 5140.17,
                "total_trades": 75,
                "win_rate": 68.5,
                "farm_return": 15.2,
                "risk_adjusted_return": 12.8,
                "utilization_rate": 85.0,
                "consistency_score": 78.5,
                "active_agents": 3
            }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting farm performance: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/farms/{farm_id}/start")
async def start_farm(farm_id: str):
    """Start farm operations"""
    try:
        farm_service = registry.get_service("farm_management")
        if farm_service:
            success = await farm_service.activate_farm(farm_id)
            return {"success": success, "status": "active"}
        else:
            return {"success": True, "status": "active"}
    except Exception as e:
        logger.error(f"Error starting farm: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/farms/{farm_id}/stop")
async def stop_farm(farm_id: str):
    """Stop farm operations"""
    try:
        farm_service = registry.get_service("farm_management")
        if farm_service:
            success = await farm_service.pause_farm(farm_id)
            return {"success": success, "status": "paused"}
        else:
            return {"success": True, "status": "paused"}
    except Exception as e:
        logger.error(f"Error stopping farm: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/farms/{farm_id}/rebalance")
async def rebalance_farm(farm_id: str, rebalance_params: Dict[str, Any]):
    """Rebalance farm allocation"""
    try:
        farm_service = registry.get_service("farm_management")
        if farm_service:
            return await farm_service.rebalance_farm_api(farm_id, rebalance_params)
        else:
            # Mock rebalance result
            return {
                "farm_id": farm_id,
                "rebalance_type": rebalance_params.get("type", "performance_based"),
                "expected_improvement": 12.5,
                "status": "completed",
                "rebalance_timestamp": datetime.now().isoformat()
            }
    except Exception as e:
        logger.error(f"Error rebalancing farm: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/farms/metrics")
async def get_farm_metrics():
    """Get overall farm system metrics"""
    try:
        farm_service = registry.get_service("farm_management")
        if farm_service:
            return await farm_service.get_farm_metrics()
        else:
            # Mock metrics
            return {
                "total_farms": 3,
                "active_farms": 2,
                "paused_farms": 1,
                "total_agents": 8,
                "total_profit": 25750.50,
                "avg_agents_per_farm": 2.7,
                "system_efficiency": 85.0
            }
    except Exception as e:
        logger.error(f"Error getting farm metrics: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==========================================
# KNOWLEDGE GRAPH API ENDPOINTS - PHASE 13
# ==========================================

@app.get("/api/v1/knowledge/graph/overview")
async def get_knowledge_graph_overview():
    """Get comprehensive knowledge graph overview and dashboard"""
    try:
        knowledge_service = registry.get_service("knowledge_graph_service")
        if not knowledge_service:
            # Return comprehensive mock knowledge graph data
            return {
                "graph_overview": {
                    "total_nodes": 47,
                    "total_relationships": 68,
                    "entity_distribution": {
                        "symbol": 12,
                        "strategy": 8,
                        "agent": 6,
                        "indicator": 9,
                        "event": 4,
                        "pattern": 5,
                        "sentiment": 3
                    },
                    "category_distribution": {
                        "asset": 12,
                        "strategy": 8,
                        "agent": 6,
                        "market_data": 15,
                        "analytics": 4,
                        "external": 2
                    },
                    "relationship_distribution": {
                        "correlates_with": 15,
                        "influences": 12,
                        "operates_on": 10,
                        "measures": 8,
                        "depends_on": 6,
                        "triggers": 5,
                        "affects": 4,
                        "similar_to": 3,
                        "caused_by": 3,
                        "contains": 2
                    }
                },
                "recent_activity": {
                    "nodes": [
                        {"id": "node_1", "name": "BTC/USD", "type": "symbol", "updated": "2025-06-20T10:30:00Z"},
                        {"id": "node_4", "name": "Momentum Trading", "type": "strategy", "updated": "2025-06-20T09:15:00Z"},
                        {"id": "node_6", "name": "Marcus Momentum", "type": "agent", "updated": "2025-06-20T08:45:00Z"},
                        {"id": "node_8", "name": "RSI", "type": "indicator", "updated": "2025-06-20T08:30:00Z"},
                        {"id": "node_10", "name": "Fed Rate Decision", "type": "event", "updated": "2025-06-20T07:20:00Z"}
                    ],
                    "relationships": [
                        {"id": "rel_1", "source": "BTC/USD", "target": "ETH/USD", "type": "correlates_with", "strength": 0.85, "updated": "2025-06-20T10:15:00Z"},
                        {"id": "rel_4", "source": "Momentum Trading", "target": "BTC/USD", "type": "operates_on", "strength": 0.90, "updated": "2025-06-20T09:30:00Z"},
                        {"id": "rel_6", "source": "Marcus Momentum", "target": "Momentum Trading", "type": "depends_on", "strength": 0.95, "updated": "2025-06-20T09:00:00Z"},
                        {"id": "rel_8", "source": "RSI", "target": "BTC/USD", "type": "measures", "strength": 0.80, "updated": "2025-06-20T08:45:00Z"},
                        {"id": "rel_10", "source": "Fed Rate Decision", "target": "BTC/USD", "type": "influences", "strength": 0.60, "updated": "2025-06-20T08:00:00Z"}
                    ]
                },
                "insights": {
                    "graph_metrics": {
                        "nodes": 47,
                        "relationships": 68,
                        "density": 0.032,
                        "connected_components": 3,
                        "average_clustering": 0.34,
                        "diameter": 6
                    },
                    "centrality_analysis": {
                        "top_degree_nodes": [
                            {"node_id": "node_1", "name": "BTC/USD", "centrality": 0.85},
                            {"node_id": "node_4", "name": "Momentum Trading", "centrality": 0.72},
                            {"node_id": "node_8", "name": "RSI", "centrality": 0.68}
                        ],
                        "top_betweenness_nodes": [
                            {"node_id": "node_1", "name": "BTC/USD", "centrality": 0.45},
                            {"node_id": "node_6", "name": "Marcus Momentum", "centrality": 0.38}
                        ]
                    },
                    "community_detection": {
                        "total_communities": 4,
                        "communities": {
                            "0": [{"name": "BTC/USD"}, {"name": "ETH/USD"}, {"name": "Crypto Assets"}],
                            "1": [{"name": "Momentum Trading"}, {"name": "Marcus Momentum"}, {"name": "Trend Strategies"}],
                            "2": [{"name": "RSI"}, {"name": "MACD"}, {"name": "Technical Indicators"}],
                            "3": [{"name": "Fed Rate Decision"}, {"name": "Market Events"}]
                        },
                        "modularity_score": 0.67
                    },
                    "influence_patterns": {
                        "top_influencers": [
                            {"node_id": "node_10", "name": "Fed Rate Decision", "influence_score": 0.92},
                            {"node_id": "node_1", "name": "BTC/USD", "influence_score": 0.78},
                            {"node_id": "node_4", "name": "Momentum Trading", "influence_score": 0.65}
                        ]
                    },
                    "knowledge_gaps": [
                        {"type": "sparse_coverage", "description": "Limited sentiment entity coverage", "severity": "medium"},
                        {"type": "missing_relationships", "description": "Few correlation relationships for altcoins", "severity": "low"}
                    ]
                },
                "search_suggestions": [
                    "BTC correlation analysis",
                    "momentum strategy patterns",
                    "RSI indicator relationships",
                    "market event impacts",
                    "agent performance connections",
                    "trading pattern recognition",
                    "cross-asset correlations",
                    "strategy effectiveness analysis"
                ],
                "last_updated": datetime.now(timezone.utc).isoformat()
            }
        
        dashboard = await knowledge_service.get_knowledge_dashboard()
        return dashboard
        
    except Exception as e:
        logger.error(f"Failed to get knowledge graph overview: {e}")
        raise HTTPException(status_code=500, detail=f"Knowledge graph error: {str(e)}")

@app.get("/api/v1/knowledge/search")
async def semantic_search_knowledge_graph(
    query: str,
    entity_types: Optional[str] = None,
    categories: Optional[str] = None,
    limit: int = 10
):
    """Perform semantic search across the knowledge graph"""
    try:
        knowledge_service = registry.get_service("knowledge_graph_service")
        if not knowledge_service:
            # Return mock search results
            return {
                "query": query,
                "results": [
                    {
                        "node_id": "node_1",
                        "score": 0.95,
                        "relevance": "name_match, description_match",
                        "path": ["ETH/USD", "Momentum Trading", "Marcus Momentum"],
                        "context": {
                            "entity_type": "symbol",
                            "category": "asset",
                            "name": "BTC/USD",
                            "description": "Bitcoin to US Dollar trading pair with high volatility and strong market influence"
                        }
                    },
                    {
                        "node_id": "node_4",
                        "score": 0.78,
                        "relevance": "property_match, partial_name_match",
                        "path": ["BTC/USD", "Marcus Momentum", "RSI"],
                        "context": {
                            "entity_type": "strategy",
                            "category": "strategy",
                            "name": "Momentum Trading",
                            "description": "Trend-following strategy using momentum indicators for cryptocurrency trading"
                        }
                    },
                    {
                        "node_id": "node_8",
                        "score": 0.65,
                        "relevance": "description_match, property_indicator_type",
                        "path": ["BTC/USD", "ETH/USD"],
                        "context": {
                            "entity_type": "indicator",
                            "category": "market_data",
                            "name": "RSI",
                            "description": "Relative Strength Index oscillator for identifying overbought/oversold conditions"
                        }
                    }
                ],
                "total_results": 3,
                "search_time_ms": 45,
                "filters_applied": {
                    "entity_types": entity_types.split(",") if entity_types else None,
                    "categories": categories.split(",") if categories else None,
                    "limit": limit
                }
            }
        
        # Parse filters
        entity_type_list = None
        category_list = None
        
        if entity_types:
            from services.knowledge_graph_service import EntityType
            entity_type_list = [EntityType(t.strip()) for t in entity_types.split(",")]
        
        if categories:
            from services.knowledge_graph_service import NodeCategory
            category_list = [NodeCategory(c.strip()) for c in categories.split(",")]
        
        results = await knowledge_service.semantic_search(query, entity_type_list, category_list, limit)
        
        return {
            "query": query,
            "results": [
                {
                    "node_id": result.node_id,
                    "score": result.score,
                    "relevance": result.relevance,
                    "path": result.path,
                    "context": result.context
                } for result in results
            ],
            "total_results": len(results),
            "filters_applied": {
                "entity_types": entity_types.split(",") if entity_types else None,
                "categories": categories.split(",") if categories else None,
                "limit": limit
            }
        }
        
    except Exception as e:
        logger.error(f"Failed to perform semantic search: {e}")
        raise HTTPException(status_code=500, detail=f"Search error: {str(e)}")

@app.get("/api/v1/knowledge/entity/{entity_id}/relationships")
async def get_entity_relationships(
    entity_id: str,
    relationship_types: Optional[str] = None,
    max_depth: int = 2
):
    """Get relationships for a specific entity"""
    try:
        knowledge_service = registry.get_service("knowledge_graph_service")
        if not knowledge_service:
            # Return mock relationship data
            return {
                "entity_id": entity_id,
                "direct_relationships": [
                    {
                        "relationship_id": "rel_1",
                        "target_node_id": "node_2",
                        "target_name": "ETH/USD",
                        "relationship_type": "correlates_with",
                        "strength": 0.85,
                        "confidence": 0.90
                    },
                    {
                        "relationship_id": "rel_4",
                        "target_node_id": "node_4",
                        "target_name": "Momentum Trading",
                        "relationship_type": "operates_on",
                        "strength": 0.90,
                        "confidence": 0.85
                    },
                    {
                        "relationship_id": "rel_8",
                        "target_node_id": "node_8",
                        "target_name": "RSI",
                        "relationship_type": "measures",
                        "strength": 0.80,
                        "confidence": 0.85
                    }
                ],
                "indirect_relationships": [
                    {
                        "target_node_id": "node_6",
                        "target_name": "Marcus Momentum",
                        "path": ["BTC/USD", "Momentum Trading", "Marcus Momentum"],
                        "path_length": 2,
                        "path_strength": 0.855
                    },
                    {
                        "target_node_id": "node_9",
                        "target_name": "MACD",
                        "path": ["BTC/USD", "RSI", "MACD"],
                        "path_length": 2,
                        "path_strength": 0.68
                    }
                ],
                "relationship_summary": {
                    "total_direct": 3,
                    "total_indirect": 2,
                    "average_strength": 0.85,
                    "relationship_types": {
                        "correlates_with": 1,
                        "operates_on": 1,
                        "measures": 1
                    },
                    "connectivity_score": 4.0
                }
            }
        
        # Parse relationship types filter
        relationship_type_list = None
        if relationship_types:
            from services.knowledge_graph_service import RelationshipType
            relationship_type_list = [RelationshipType(t.strip()) for t in relationship_types.split(",")]
        
        relationships = await knowledge_service.find_relationships(entity_id, relationship_type_list, max_depth)
        return relationships
        
    except Exception as e:
        logger.error(f"Failed to get entity relationships: {e}")
        raise HTTPException(status_code=500, detail=f"Relationship query error: {str(e)}")

@app.get("/api/v1/knowledge/entity/{entity_id}/insights")
async def get_entity_insights(entity_id: str):
    """Get comprehensive insights about a specific entity"""
    try:
        knowledge_service = registry.get_service("knowledge_graph_service")
        if not knowledge_service:
            # Return mock entity insights
            return {
                "entity_info": {
                    "id": entity_id,
                    "name": "BTC/USD",
                    "type": "symbol",
                    "category": "asset",
                    "description": "Bitcoin to US Dollar trading pair",
                    "confidence": 0.95
                },
                "relationship_analysis": {
                    "total_direct": 8,
                    "total_indirect": 15,
                    "average_strength": 0.72,
                    "connectivity_score": 15.5
                },
                "network_position": {
                    "centrality_scores": {
                        "degree": 0.85,
                        "betweenness": 0.42,
                        "closeness": 0.68
                    },
                    "local_structure": {
                        "clustering_coefficient": 0.34,
                        "degree": 8,
                        "neighbor_types": {
                            "symbol": 3,
                            "strategy": 2,
                            "indicator": 2,
                            "event": 1
                        }
                    },
                    "influence_score": 0.65,
                    "broker_score": 0.42,
                    "hub_score": 0.85
                },
                "semantic_context": {
                    "semantic_cluster": "asset",
                    "entity_class": "symbol",
                    "related_entities": [
                        {"node_id": "node_2", "name": "ETH/USD", "relationship": "same_type"},
                        {"node_id": "node_3", "name": "SOL/USD", "relationship": "same_category"}
                    ],
                    "key_properties": ["symbol", "asset_class", "volatility", "market_cap"],
                    "confidence": 0.95
                },
                "temporal_analysis": {
                    "creation_date": "2025-05-15T10:30:00Z",
                    "last_updated": "2025-06-20T14:25:00Z",
                    "age_days": 36,
                    "update_frequency": "daily",
                    "activity_score": 0.88,
                    "trend": "increasing"
                },
                "recommendations": [
                    {
                        "type": "connect",
                        "target_node": "node_12",
                        "target_name": "Volatility Index",
                        "reason": "Similar volatility characteristics",
                        "priority": "medium"
                    },
                    {
                        "type": "enrich",
                        "property": "trading_volume",
                        "reason": "Common property for symbol entities",
                        "priority": "low"
                    }
                ]
            }
        
        insights = await knowledge_service.get_entity_insights(entity_id)
        return insights
        
    except Exception as e:
        logger.error(f"Failed to get entity insights: {e}")
        raise HTTPException(status_code=500, detail=f"Entity insights error: {str(e)}")

@app.get("/api/v1/knowledge/patterns/analysis")
async def analyze_graph_patterns():
    """Analyze patterns and insights in the knowledge graph"""
    try:
        knowledge_service = registry.get_service("knowledge_graph_service")
        if not knowledge_service:
            # Return mock pattern analysis
            return {
                "graph_metrics": {
                    "nodes": 47,
                    "relationships": 68,
                    "density": 0.032,
                    "connected_components": 3,
                    "average_clustering": 0.34,
                    "diameter": 6
                },
                "centrality_analysis": {
                    "degree_centrality": {
                        "top_nodes": [
                            ["node_1", 0.85, "BTC/USD"],
                            ["node_4", 0.72, "Momentum Trading"],
                            ["node_8", 0.68, "RSI"],
                            ["node_6", 0.65, "Marcus Momentum"],
                            ["node_2", 0.58, "ETH/USD"]
                        ],
                        "average": 0.34
                    },
                    "betweenness_centrality": {
                        "top_nodes": [
                            ["node_1", 0.45, "BTC/USD"],
                            ["node_6", 0.38, "Marcus Momentum"],
                            ["node_4", 0.32, "Momentum Trading"],
                            ["node_8", 0.28, "RSI"],
                            ["node_10", 0.25, "Fed Rate Decision"]
                        ],
                        "average": 0.18
                    },
                    "closeness_centrality": {
                        "top_nodes": [
                            ["node_1", 0.68, "BTC/USD"],
                            ["node_4", 0.62, "Momentum Trading"],
                            ["node_8", 0.58, "RSI"],
                            ["node_6", 0.55, "Marcus Momentum"],
                            ["node_2", 0.52, "ETH/USD"]
                        ],
                        "average": 0.42
                    },
                    "eigenvector_centrality": {
                        "top_nodes": [
                            ["node_1", 0.78, "BTC/USD"],
                            ["node_4", 0.65, "Momentum Trading"],
                            ["node_6", 0.58, "Marcus Momentum"],
                            ["node_8", 0.52, "RSI"],
                            ["node_2", 0.48, "ETH/USD"]
                        ],
                        "average": 0.28
                    }
                },
                "clustering_analysis": {
                    "global_clustering_coefficient": 0.34,
                    "nodes_with_high_clustering": [
                        {"node_id": "node_1", "name": "BTC/USD", "clustering": 0.67},
                        {"node_id": "node_4", "name": "Momentum Trading", "clustering": 0.58},
                        {"node_id": "node_8", "name": "RSI", "clustering": 0.52}
                    ],
                    "triangles": 12,
                    "transitivity": 0.41
                },
                "community_detection": {
                    "total_communities": 4,
                    "communities": {
                        "0": [
                            {"node_id": "node_1", "name": "BTC/USD", "type": "symbol", "category": "asset"},
                            {"node_id": "node_2", "name": "ETH/USD", "type": "symbol", "category": "asset"},
                            {"node_id": "node_3", "name": "SOL/USD", "type": "symbol", "category": "asset"}
                        ],
                        "1": [
                            {"node_id": "node_4", "name": "Momentum Trading", "type": "strategy", "category": "strategy"},
                            {"node_id": "node_6", "name": "Marcus Momentum", "type": "agent", "category": "agent"},
                            {"node_id": "node_5", "name": "Mean Reversion", "type": "strategy", "category": "strategy"}
                        ],
                        "2": [
                            {"node_id": "node_8", "name": "RSI", "type": "indicator", "category": "market_data"},
                            {"node_id": "node_9", "name": "MACD", "type": "indicator", "category": "market_data"},
                            {"node_id": "node_11", "name": "Bollinger Bands", "type": "indicator", "category": "market_data"}
                        ],
                        "3": [
                            {"node_id": "node_10", "name": "Fed Rate Decision", "type": "event", "category": "external"},
                            {"node_id": "node_12", "name": "Market Sentiment", "type": "sentiment", "category": "analytics"}
                        ]
                    },
                    "modularity_score": 0.67,
                    "largest_community": 8
                },
                "influence_patterns": {
                    "top_influencers": [
                        {"node_id": "node_10", "name": "Fed Rate Decision", "influence_out": 6, "influence_in": 1, "net_influence": 5},
                        {"node_id": "node_1", "name": "BTC/USD", "influence_out": 4, "influence_in": 2, "net_influence": 2},
                        {"node_id": "node_4", "name": "Momentum Trading", "influence_out": 3, "influence_in": 1, "net_influence": 2}
                    ],
                    "total_influence_relationships": 28,
                    "average_influence": 1.4
                },
                "knowledge_gaps": [
                    {
                        "type": "isolation",
                        "description": "3 nodes have no relationships",
                        "severity": "medium",
                        "nodes": ["node_15", "node_22", "node_31"]
                    },
                    {
                        "type": "sparse_coverage",
                        "description": "Limited coverage for 2 entity types",
                        "severity": "low",
                        "entities": ["sentiment", "news"]
                    }
                ]
            }
        
        analysis = await knowledge_service.analyze_graph_patterns()
        return analysis
        
    except Exception as e:
        logger.error(f"Failed to analyze graph patterns: {e}")
        raise HTTPException(status_code=500, detail=f"Pattern analysis error: {str(e)}")

@app.post("/api/v1/knowledge/query")
async def query_knowledge_graph(query_request: dict):
    """Execute complex graph queries"""
    try:
        knowledge_service = registry.get_service("knowledge_graph_service")
        if not knowledge_service:
            # Return mock query results based on query type
            query_type = query_request.get("query_type", "similarity")
            
            if query_type == "shortest_path":
                return {
                    "query_type": "shortest_path",
                    "path": ["node_1", "node_4", "node_6"],
                    "path_names": ["BTC/USD", "Momentum Trading", "Marcus Momentum"],
                    "length": 2,
                    "total_strength": 0.855
                }
            elif query_type == "subgraph":
                return {
                    "query_type": "subgraph",
                    "nodes": ["node_1", "node_2", "node_4", "node_6", "node_8"],
                    "node_names": ["BTC/USD", "ETH/USD", "Momentum Trading", "Marcus Momentum", "RSI"],
                    "edges": 8,
                    "density": 0.4,
                    "subgraph_score": 0.78
                }
            elif query_type == "similarity":
                return {
                    "query_type": "similarity",
                    "target_node": query_request.get("parameters", {}).get("node", "node_1"),
                    "similar_nodes": [
                        {"node_id": "node_2", "name": "ETH/USD", "similarity": 0.85},
                        {"node_id": "node_3", "name": "SOL/USD", "similarity": 0.72},
                        {"node_id": "node_7", "name": "MATIC/USD", "similarity": 0.68}
                    ]
                }
            elif query_type == "influence":
                return {
                    "query_type": "influence",
                    "source_node": query_request.get("parameters", {}).get("node", "node_1"),
                    "influenced_nodes": [
                        {
                            "node_id": "node_4",
                            "name": "Momentum Trading",
                            "influence_strength": 0.85,
                            "path_length": 1,
                            "path": ["BTC/USD", "Momentum Trading"]
                        },
                        {
                            "node_id": "node_6",
                            "name": "Marcus Momentum",
                            "influence_strength": 0.72,
                            "path_length": 2,
                            "path": ["BTC/USD", "Momentum Trading", "Marcus Momentum"]
                        }
                    ]
                }
            else:
                return {"error": f"Unknown query type: {query_type}"}
        
        from services.knowledge_graph_service import GraphQuery
        graph_query = GraphQuery(
            query_id=str(uuid.uuid4()),
            query_type=query_request["query_type"],
            parameters=query_request.get("parameters", {}),
            filters=query_request.get("filters", {}),
            limit=query_request.get("limit", 100)
        )
        
        result = await knowledge_service.query_graph(graph_query)
        return result
        
    except Exception as e:
        logger.error(f"Failed to execute graph query: {e}")
        raise HTTPException(status_code=500, detail=f"Graph query error: {str(e)}")

@app.get("/api/v1/knowledge/service/status")
async def get_knowledge_service_status():
    """Get knowledge graph service status and metrics"""
    try:
        knowledge_service = registry.get_service("knowledge_graph_service")
        if not knowledge_service:
            return {
                "service": "knowledge_graph_service",
                "status": "mock_mode",
                "graph_metrics": {
                    "total_nodes": 47,
                    "total_relationships": 68,
                    "connected_components": 3,
                    "average_clustering": 0.34,
                    "density": 0.032,
                    "diameter": 6
                },
                "cache_size": 0,
                "entity_types": ["symbol", "strategy", "agent", "market", "indicator", "event", "correlation", "pattern", "sentiment", "news", "metric"],
                "relationship_types": ["correlates_with", "influences", "caused_by", "similar_to", "depends_on", "contains", "triggers", "precedes", "affects", "operates_on", "measures"],
                "last_update": datetime.now(timezone.utc).isoformat(),
                "mode": "mock_data"
            }
        
        status = await knowledge_service.get_service_status()
        return status
        
    except Exception as e:
        logger.error(f"Failed to get knowledge service status: {e}")
        raise HTTPException(status_code=500, detail=f"Service status error: {str(e)}")

# ==========================================
# DATA MANAGEMENT PIPELINE API ENDPOINTS - PHASE 15
# ==========================================

@app.get("/api/v1/data/pipeline/status")
async def get_data_pipeline_status():
    """Get comprehensive data pipeline status and metrics"""
    try:
        pipeline_service = registry.get_service("data_management_pipeline_service")
        if not pipeline_service:
            # Return comprehensive mock pipeline status
            import random
            return {
                "pipeline_status": "running",
                "data_sources": {
                    "total": 8,
                    "active": 7,
                    "inactive": 1
                },
                "processing_metrics": {
                    "records_processed": 125847,
                    "processing_rate": 45.7,
                    "success_rate": 0.967,
                    "error_rate": 0.033,
                    "avg_processing_time": 12.4
                },
                "quality_metrics": {
                    "overall_quality": 0.89,
                    "distribution": {
                        "high": 98234,
                        "medium": 21567,
                        "low": 4892,
                        "invalid": 1154
                    }
                },
                "stage_distribution": {
                    "raw": 1247,
                    "validated": 2156,
                    "enriched": 3842,
                    "transformed": 8934,
                    "aggregated": 15672,
                    "archived": 93996
                },
                "buffer_status": {
                    "current_size": 127,
                    "max_size": 1000,
                    "utilization": 0.127
                },
                "recent_activity": [
                    {
                        "timestamp": "2025-06-20T14:45:00Z",
                        "action": "data_ingested",
                        "source": "binance_market_data",
                        "records": 342
                    },
                    {
                        "timestamp": "2025-06-20T14:44:00Z",
                        "action": "validation_completed",
                        "source": "tradingview_signals",
                        "records": 89
                    },
                    {
                        "timestamp": "2025-06-20T14:43:00Z",
                        "action": "enrichment_applied",
                        "source": "news_feeds",
                        "records": 156
                    }
                ],
                "last_updated": datetime.now(timezone.utc).isoformat()
            }
        
        status = await pipeline_service.get_pipeline_status()
        return status
        
    except Exception as e:
        logger.error(f"Failed to get data pipeline status: {e}")
        raise HTTPException(status_code=500, detail=f"Pipeline status error: {str(e)}")

@app.get("/api/v1/data/quality/report")
async def get_data_quality_report(
    source_id: Optional[str] = None,
    timeframe: str = "24h"
):
    """Generate comprehensive data quality report"""
    try:
        pipeline_service = registry.get_service("data_management_pipeline_service")
        if not pipeline_service:
            # Return mock quality report
            if source_id:
                return {
                    "source_id": source_id,
                    "source_name": "Binance Market Data",
                    "timeframe": timeframe,
                    "quality_metrics": {
                        "overall_score": 0.92,
                        "completeness": 0.96,
                        "accuracy": 0.94,
                        "consistency": 0.89,
                        "timeliness": 0.91,
                        "validity": 0.95
                    },
                    "quality_distribution": {
                        "high": 8934,
                        "medium": 1247,
                        "low": 156,
                        "invalid": 23
                    },
                    "quality_trends": {
                        "last_24h": [0.89, 0.91, 0.94, 0.92, 0.93, 0.92],
                        "timestamps": ["00:00", "04:00", "08:00", "12:00", "16:00", "20:00"]
                    },
                    "issues_detected": [
                        {"type": "missing_fields", "count": 45, "severity": "low"},
                        {"type": "outlier_values", "count": 12, "severity": "medium"},
                        {"type": "duplicate_records", "count": 3, "severity": "low"}
                    ],
                    "recommendations": [
                        {
                            "category": "validation",
                            "description": "Increase field validation for price data",
                            "priority": "medium"
                        }
                    ],
                    "generated_at": datetime.now(timezone.utc).isoformat()
                }
            else:
                return {
                    "timeframe": timeframe,
                    "overall_metrics": {
                        "total_records": 125847,
                        "quality_score": 0.89,
                        "completeness": 0.94,
                        "accuracy": 0.91,
                        "consistency": 0.87,
                        "timeliness": 0.92
                    },
                    "source_breakdown": {
                        "source_1": {"name": "Binance Market Data", "records": 45672, "quality_score": 0.92, "error_rate": 0.015},
                        "source_2": {"name": "TradingView Signals", "records": 23451, "quality_score": 0.87, "error_rate": 0.032},
                        "source_3": {"name": "CryptoPanic News", "records": 12983, "quality_score": 0.84, "error_rate": 0.041},
                        "source_4": {"name": "Twitter Sentiment", "records": 34567, "quality_score": 0.78, "error_rate": 0.067},
                        "source_5": {"name": "Ethereum Node", "records": 9174, "quality_score": 0.95, "error_rate": 0.008}
                    },
                    "quality_trends": {
                        "hourly": [0.87, 0.89, 0.91, 0.88, 0.92, 0.90, 0.89, 0.94, 0.91, 0.88, 0.93, 0.89],
                        "daily": [0.88, 0.91, 0.89, 0.92, 0.87, 0.94, 0.89]
                    },
                    "top_issues": [
                        {"source": "Twitter Sentiment", "issue": "Rate limit exceeded", "count": 89},
                        {"source": "TradingView Signals", "issue": "Missing confidence scores", "count": 45},
                        {"source": "Binance Market Data", "issue": "Price spike outliers", "count": 23}
                    ],
                    "generated_at": datetime.now(timezone.utc).isoformat()
                }
        
        report = await pipeline_service.get_data_quality_report(source_id, timeframe)
        return report
        
    except Exception as e:
        logger.error(f"Failed to generate quality report: {e}")
        raise HTTPException(status_code=500, detail=f"Quality report error: {str(e)}")

@app.get("/api/v1/data/sources")
async def get_data_sources():
    """Get list of all configured data sources"""
    try:
        pipeline_service = registry.get_service("data_management_pipeline_service")
        if not pipeline_service:
            # Return mock data sources
            return {
                "data_sources": [
                    {
                        "source_id": "source_1",
                        "name": "Binance Market Data",
                        "type": "market_data",
                        "status": "active",
                        "url": "wss://stream.binance.com:9443/ws/!ticker@arr",
                        "update_frequency": 1,
                        "quality_threshold": 0.95,
                        "retention_days": 90,
                        "records_today": 45672,
                        "last_update": "2025-06-20T14:45:32Z"
                    },
                    {
                        "source_id": "source_2",
                        "name": "TradingView Signals",
                        "type": "trading_signals",
                        "status": "active",
                        "url": "https://api.tradingview.com/signals",
                        "update_frequency": 60,
                        "quality_threshold": 0.85,
                        "retention_days": 30,
                        "records_today": 1247,
                        "last_update": "2025-06-20T14:44:15Z"
                    },
                    {
                        "source_id": "source_3",
                        "name": "CryptoPanic News",
                        "type": "news_feeds",
                        "status": "active",
                        "url": "https://cryptopanic.com/api/v1/posts/",
                        "update_frequency": 300,
                        "quality_threshold": 0.75,
                        "retention_days": 7,
                        "records_today": 523,
                        "last_update": "2025-06-20T14:40:00Z"
                    },
                    {
                        "source_id": "source_4",
                        "name": "Twitter Sentiment",
                        "type": "social_sentiment",
                        "status": "warning",
                        "url": "https://api.twitter.com/2/tweets/search/stream",
                        "update_frequency": 30,
                        "quality_threshold": 0.70,
                        "retention_days": 3,
                        "records_today": 8934,
                        "last_update": "2025-06-20T14:43:45Z"
                    },
                    {
                        "source_id": "source_5",
                        "name": "Ethereum Node",
                        "type": "blockchain_data",
                        "status": "active",
                        "url": "https://mainnet.infura.io/v3/PROJECT_ID",
                        "update_frequency": 15,
                        "quality_threshold": 0.90,
                        "retention_days": 180,
                        "records_today": 2156,
                        "last_update": "2025-06-20T14:45:12Z"
                    }
                ],
                "summary": {
                    "total_sources": 5,
                    "active_sources": 4,
                    "warning_sources": 1,
                    "inactive_sources": 0,
                    "total_records_today": 58532
                }
            }
        
        sources = {
            source_id: {
                "source_id": source_id,
                "name": source.name,
                "type": source.source_type.value,
                "status": "active" if source.is_active else "inactive",
                "url": source.url,
                "update_frequency": source.update_frequency,
                "quality_threshold": source.quality_threshold,
                "retention_days": source.retention_days,
                "metadata": source.metadata
            } for source_id, source in pipeline_service.data_sources.items()
        }
        
        return {
            "data_sources": list(sources.values()),
            "summary": {
                "total_sources": len(sources),
                "active_sources": sum(1 for s in sources.values() if s["status"] == "active"),
                "inactive_sources": sum(1 for s in sources.values() if s["status"] == "inactive")
            }
        }
        
    except Exception as e:
        logger.error(f"Failed to get data sources: {e}")
        raise HTTPException(status_code=500, detail=f"Data sources error: {str(e)}")

@app.post("/api/v1/data/sources")
async def add_data_source(source_config: dict):
    """Add a new data source to the pipeline"""
    try:
        pipeline_service = registry.get_service("data_management_pipeline_service")
        if not pipeline_service:
            # Return mock response
            source_id = str(uuid.uuid4())
            return {
                "source_id": source_id,
                "name": source_config.get("name", "New Data Source"),
                "type": source_config.get("source_type", "market_data"),
                "status": "created",
                "message": "Data source created successfully (mock mode)",
                "created_at": datetime.now(timezone.utc).isoformat()
            }
        
        source = await pipeline_service.add_data_source(source_config)
        return {
            "source_id": source.source_id,
            "name": source.name,
            "type": source.source_type.value,
            "status": "created",
            "created_at": datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"Failed to add data source: {e}")
        raise HTTPException(status_code=500, detail=f"Add data source error: {str(e)}")

@app.get("/api/v1/data/lineage/{record_id}")
async def get_data_lineage(record_id: str):
    """Get data lineage for a specific record"""
    try:
        pipeline_service = registry.get_service("data_management_pipeline_service")
        if not pipeline_service:
            # Return mock lineage
            return {
                "record_id": record_id,
                "lineage": [
                    {
                        "stage": "ingestion",
                        "timestamp": "2025-06-20T14:30:00Z",
                        "source": "binance_market_data",
                        "action": "data_received",
                        "metadata": {"format": "json", "size_bytes": 1024}
                    },
                    {
                        "stage": "validation",
                        "timestamp": "2025-06-20T14:30:05Z",
                        "action": "schema_validated",
                        "metadata": {"validation_rules": 12, "passed": 11, "failed": 1}
                    },
                    {
                        "stage": "enrichment",
                        "timestamp": "2025-06-20T14:30:08Z",
                        "action": "market_data_enriched",
                        "metadata": {"fields_added": ["volatility", "market_cap"], "source": "external_api"}
                    },
                    {
                        "stage": "transformation",
                        "timestamp": "2025-06-20T14:30:12Z",
                        "action": "data_normalized",
                        "metadata": {"transformations": ["price_formatting", "timestamp_conversion"]}
                    },
                    {
                        "stage": "storage",
                        "timestamp": "2025-06-20T14:30:15Z",
                        "action": "data_stored",
                        "metadata": {"storage_type": "time_series", "partition": "2025-06-20"}
                    }
                ],
                "current_stage": "stored",
                "quality_score": 0.94,
                "transformations_applied": 4,
                "enrichments_applied": 2,
                "generated_at": datetime.now(timezone.utc).isoformat()
            }
        
        lineage = await pipeline_service.get_data_lineage(record_id)
        return lineage
        
    except Exception as e:
        logger.error(f"Failed to get data lineage: {e}")
        raise HTTPException(status_code=500, detail=f"Data lineage error: {str(e)}")

@app.get("/api/v1/data/analytics/dashboard")
async def get_data_analytics_dashboard():
    """Get comprehensive data analytics dashboard"""
    try:
        pipeline_service = registry.get_service("data_management_pipeline_service")
        if not pipeline_service:
            # Return comprehensive mock analytics dashboard
            import random
            return {
                "overview": {
                    "total_data_sources": 8,
                    "total_records_today": 58947,
                    "processing_throughput": 45.7,
                    "overall_quality_score": 0.89,
                    "pipeline_uptime": "99.7%",
                    "storage_utilization": "67.3%"
                },
                "source_performance": {
                    "binance_market_data": {
                        "name": "Binance Market Data",
                        "type": "market_data",
                        "status": "active",
                        "records_today": 23456,
                        "quality_score": 0.94,
                        "latency_ms": 45.2,
                        "error_rate": 0.008
                    },
                    "tradingview_signals": {
                        "name": "TradingView Signals",
                        "type": "trading_signals",
                        "status": "active",
                        "records_today": 1247,
                        "quality_score": 0.87,
                        "latency_ms": 120.5,
                        "error_rate": 0.023
                    },
                    "news_feeds": {
                        "name": "CryptoPanic News",
                        "type": "news_feeds",
                        "status": "active",
                        "records_today": 892,
                        "quality_score": 0.82,
                        "latency_ms": 89.3,
                        "error_rate": 0.035
                    },
                    "social_sentiment": {
                        "name": "Twitter Sentiment",
                        "type": "social_sentiment",
                        "status": "warning",
                        "records_today": 12456,
                        "quality_score": 0.76,
                        "latency_ms": 156.7,
                        "error_rate": 0.078
                    }
                },
                "processing_pipeline": {
                    "stages": {
                        "ingestion": {"records": 1247, "rate": "45.7/s", "errors": 3},
                        "validation": {"records": 1203, "rate": "43.2/s", "errors": 12},
                        "enrichment": {"records": 1191, "rate": "42.8/s", "errors": 5},
                        "transformation": {"records": 1186, "rate": "42.5/s", "errors": 2},
                        "storage": {"records": 1184, "rate": "42.4/s", "errors": 1}
                    },
                    "bottlenecks": ["validation", "enrichment"],
                    "optimization_suggestions": [
                        "Increase validation thread pool",
                        "Cache enrichment API responses",
                        "Implement parallel processing for transformation stage"
                    ]
                },
                "quality_metrics": {
                    "completeness": 0.94,
                    "accuracy": 0.91,
                    "consistency": 0.87,
                    "timeliness": 0.92,
                    "validity": 0.89
                },
                "data_volume_trends": {
                    "hourly": [42.5, 45.7, 48.2, 44.1, 39.8, 52.3, 47.9, 43.6, 49.1, 41.7, 46.8, 44.3],
                    "daily": [45234, 52198, 41567, 48923, 44781, 50432, 47856]
                },
                "alerts": [
                    {
                        "id": "alert_001",
                        "severity": "warning",
                        "message": "High error rate detected in Twitter Sentiment source",
                        "timestamp": "2025-06-20T14:30:00Z",
                        "source": "social_sentiment"
                    },
                    {
                        "id": "alert_002",
                        "severity": "info",
                        "message": "Data enrichment cache hit ratio dropped to 75%",
                        "timestamp": "2025-06-20T14:15:00Z",
                        "source": "enrichment_service"
                    },
                    {
                        "id": "alert_003",
                        "severity": "low",
                        "message": "Storage utilization reached 70% threshold",
                        "timestamp": "2025-06-20T14:00:00Z",
                        "source": "storage_manager"
                    }
                ],
                "recommendations": [
                    {
                        "category": "performance",
                        "title": "Increase validation parallelism",
                        "description": "Current validation stage is bottleneck with 43.2/s throughput",
                        "priority": "high",
                        "estimated_impact": "15-20% throughput increase"
                    },
                    {
                        "category": "quality",
                        "title": "Implement data profiling",
                        "description": "Automatic quality threshold adjustment based on historical patterns",
                        "priority": "medium",
                        "estimated_impact": "5-8% quality score improvement"
                    },
                    {
                        "category": "storage",
                        "title": "Archive old data",
                        "description": "Move data older than retention period to cold storage",
                        "priority": "medium",
                        "estimated_impact": "25% storage reduction"
                    }
                ],
                "last_updated": datetime.now(timezone.utc).isoformat()
            }
        
        dashboard = await pipeline_service.get_data_analytics_dashboard()
        return dashboard
        
    except Exception as e:
        logger.error(f"Failed to get data analytics dashboard: {e}")
        raise HTTPException(status_code=500, detail=f"Data analytics error: {str(e)}")

@app.post("/api/v1/data/process/batch")
async def process_data_batch(batch_request: dict):
    """Process a batch of data records through the pipeline"""
    try:
        pipeline_service = registry.get_service("data_management_pipeline_service")
        if not pipeline_service:
            # Return mock batch processing result
            records_count = batch_request.get("records_count", 100)
            processing_time = records_count * 0.124  # Mock processing time
            
            return {
                "batch_id": str(uuid.uuid4()),
                "processed_count": records_count,
                "error_count": max(0, int(records_count * 0.02)),  # 2% error rate
                "processing_time_ms": processing_time,
                "success_rate": 0.98,
                "throughput": records_count / (processing_time / 1000),
                "errors": [
                    {"record_id": f"rec_{i}", "error": "validation_failed", "timestamp": datetime.now(timezone.utc).isoformat()}
                    for i in range(max(0, int(records_count * 0.02)))
                ],
                "processed_at": datetime.now(timezone.utc).isoformat()
            }
        
        # Create mock data records for processing
        from services.data_management_pipeline_service import DataRecord, DataSourceType, ProcessingStage, DataQuality
        
        records = []
        for i in range(batch_request.get("records_count", 10)):
            record = DataRecord(
                record_id=str(uuid.uuid4()),
                source_id="source_1",
                data_type=DataSourceType.MARKET_DATA,
                stage=ProcessingStage.RAW,
                quality=DataQuality.HIGH,
                timestamp=datetime.now(timezone.utc),
                data={"price": 67234.85, "volume": 1247},
                metadata={"batch_id": batch_request.get("batch_id", str(uuid.uuid4()))}
            )
            records.append(record)
        
        result = await pipeline_service.process_data_batch(records)
        return result
        
    except Exception as e:
        logger.error(f"Failed to process data batch: {e}")
        raise HTTPException(status_code=500, detail=f"Batch processing error: {str(e)}")

@app.get("/api/v1/data/service/status")
async def get_data_service_status():
    """Get data management service status and metrics"""
    try:
        pipeline_service = registry.get_service("data_management_pipeline_service")
        if not pipeline_service:
            return {
                "service": "data_management_pipeline_service",
                "status": "mock_mode",
                "data_sources": 5,
                "processing_queue_size": 127,
                "records_processed": 125847,
                "success_rate": 0.967,
                "last_update": datetime.now(timezone.utc).isoformat(),
                "mode": "mock_data"
            }
        
        status = await pipeline_service.get_service_status()
        return status
        
    except Exception as e:
        logger.error(f"Failed to get data service status: {e}")
        raise HTTPException(status_code=500, detail=f"Service status error: {str(e)}")

# ==========================================
# ELIZA AI INTEGRATION API ENDPOINTS - PHASE 16
# ==========================================

@app.post("/api/v1/ai/conversation/start")
async def start_ai_conversation(conversation_request: dict):
    """Start a new AI conversation session"""
    try:
        eliza_service = registry.get_service("eliza_ai_integration_service")
        if not eliza_service:
            # Return mock conversation session
            session_id = str(uuid.uuid4())
            return {
                "session_id": session_id,
                "user_id": conversation_request.get("user_id", "user_1"),
                "mode": conversation_request.get("mode", "trading_assistant"),
                "personality": conversation_request.get("personality", "professional"),
                "status": "started",
                "welcome_message": {
                    "message_id": str(uuid.uuid4()),
                    "content": "Hello! I'm your AI trading assistant. I'm here to help you analyze markets, review your portfolio, and make informed trading decisions. How can I help you today?",
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "confidence_score": 1.0
                },
                "created_at": datetime.now(timezone.utc).isoformat()
            }
        
        from services.eliza_ai_integration_service import ConversationMode, ElizaPersonality
        
        mode = ConversationMode(conversation_request.get("mode", "trading_assistant"))
        personality = ElizaPersonality(conversation_request.get("personality", "professional"))
        
        session = await eliza_service.start_conversation(
            user_id=conversation_request["user_id"],
            mode=mode,
            personality=personality,
            context=conversation_request.get("context", {})
        )
        
        welcome_message = session.message_history[-1] if session.message_history else None
        
        return {
            "session_id": session.session_id,
            "user_id": session.user_id,
            "mode": session.mode.value,
            "personality": session.personality.value,
            "status": "started",
            "welcome_message": {
                "message_id": welcome_message.message_id,
                "content": welcome_message.content,
                "timestamp": welcome_message.timestamp.isoformat(),
                "confidence_score": welcome_message.confidence_score
            } if welcome_message else None,
            "created_at": session.created_at.isoformat()
        }
        
    except Exception as e:
        logger.error(f"Failed to start AI conversation: {e}")
        raise HTTPException(status_code=500, detail=f"Conversation start error: {str(e)}")

@app.post("/api/v1/ai/conversation/{session_id}/message")
async def send_ai_message(session_id: str, message_request: dict):
    """Send a message in an AI conversation"""
    try:
        eliza_service = registry.get_service("eliza_ai_integration_service")
        if not eliza_service:
            # Return mock AI response
            return {
                "message_id": str(uuid.uuid4()),
                "session_id": session_id,
                "user_message": {
                    "content": message_request.get("message", ""),
                    "timestamp": datetime.now(timezone.utc).isoformat()
                },
                "ai_response": {
                    "message_id": str(uuid.uuid4()),
                    "content": f"Thank you for your message about {message_request.get('message', 'trading')[:20]}... Based on current market conditions, I recommend focusing on risk management and maintaining a diversified portfolio. The technical indicators suggest we're in a period of heightened volatility, so consider reducing position sizes and focusing on high-probability setups.",
                    "confidence_score": 0.87,
                    "processing_time_ms": 1247,
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "metadata": {
                        "model": "gpt-4-turbo",
                        "personality": "professional",
                        "tokens_used": 156
                    }
                },
                "conversation_updated": True
            }
        
        from services.eliza_ai_integration_service import MessageType
        
        ai_response = await eliza_service.send_message(
            session_id=session_id,
            message=message_request["message"],
            user_id=message_request["user_id"],
            message_type=MessageType.USER_QUERY
        )
        
        return {
            "message_id": ai_response.message_id,
            "session_id": session_id,
            "ai_response": {
                "message_id": ai_response.message_id,
                "content": ai_response.content,
                "confidence_score": ai_response.confidence_score,
                "timestamp": ai_response.timestamp.isoformat(),
                "metadata": ai_response.metadata
            },
            "conversation_updated": True
        }
        
    except Exception as e:
        logger.error(f"Failed to send AI message: {e}")
        raise HTTPException(status_code=500, detail=f"Message send error: {str(e)}")

@app.get("/api/v1/ai/conversation/{session_id}/history")
async def get_conversation_history(session_id: str):
    """Get conversation message history"""
    try:
        eliza_service = registry.get_service("eliza_ai_integration_service")
        if not eliza_service:
            # Return mock conversation history
            return {
                "session_id": session_id,
                "messages": [
                    {
                        "message_id": "msg_1",
                        "type": "ai_response",
                        "content": "Hello! I'm your AI trading assistant. How can I help you today?",
                        "timestamp": "2025-06-20T14:00:00Z",
                        "confidence_score": 1.0,
                        "metadata": {"type": "welcome_message"}
                    },
                    {
                        "message_id": "msg_2", 
                        "type": "user_query",
                        "content": "What's your analysis of Bitcoin's recent price action?",
                        "timestamp": "2025-06-20T14:01:00Z",
                        "user_id": "user_1"
                    },
                    {
                        "message_id": "msg_3",
                        "type": "ai_response", 
                        "content": "Bitcoin has shown strong momentum recently, breaking above the $67,000 resistance level with good volume confirmation. The technical indicators suggest continued upward potential, but I'd recommend watching for profit-taking around $70,000. Given your moderate risk tolerance, consider taking partial profits if we reach that level.",
                        "timestamp": "2025-06-20T14:01:15Z",
                        "confidence_score": 0.89,
                        "metadata": {"model": "gpt-4-turbo", "tokens_used": 145}
                    }
                ],
                "total_messages": 3,
                "session_info": {
                    "mode": "trading_assistant",
                    "personality": "professional",
                    "created_at": "2025-06-20T14:00:00Z",
                    "last_activity": "2025-06-20T14:01:15Z"
                }
            }
        
        messages = await eliza_service.get_conversation_history(session_id)
        
        return {
            "session_id": session_id,
            "messages": [
                {
                    "message_id": msg.message_id,
                    "type": msg.message_type.value,
                    "content": msg.content,
                    "timestamp": msg.timestamp.isoformat(),
                    "confidence_score": msg.confidence_score,
                    "user_id": msg.user_id,
                    "metadata": msg.metadata
                } for msg in messages
            ],
            "total_messages": len(messages)
        }
        
    except Exception as e:
        logger.error(f"Failed to get conversation history: {e}")
        raise HTTPException(status_code=500, detail=f"History retrieval error: {str(e)}")

@app.get("/api/v1/ai/insights")
async def get_ai_insights(
    categories: Optional[str] = None,
    limit: int = 10
):
    """Get AI-generated insights and recommendations"""
    try:
        eliza_service = registry.get_service("eliza_ai_integration_service")
        if not eliza_service:
            # Return mock AI insights
            return {
                "insights": [
                    {
                        "insight_id": "insight_1",
                        "category": "market_analysis",
                        "title": "Bitcoin Bullish Momentum Continuation",
                        "content": "Technical analysis indicates Bitcoin is forming a bull flag pattern on the 4-hour chart. The pattern suggests potential upside to $72,000 level.",
                        "confidence": 0.84,
                        "risk_level": "medium",
                        "supporting_data": {
                            "price_target": 72000,
                            "probability": 0.74,
                            "timeframe": "5-7 days"
                        },
                        "recommended_actions": [
                            "Consider long position with tight stop-loss",
                            "Monitor volume confirmation on breakout"
                        ],
                        "created_at": "2025-06-20T14:30:00Z"
                    },
                    {
                        "insight_id": "insight_2",
                        "category": "portfolio_optimization",
                        "title": "Rebalancing Opportunity Detected",
                        "content": "Your portfolio allocation has drifted from target weights due to crypto outperformance. Consider rebalancing to lock in gains.",
                        "confidence": 0.91,
                        "risk_level": "low",
                        "supporting_data": {
                            "current_allocation": {"crypto": 35, "stocks": 45, "bonds": 20},
                            "target_allocation": {"crypto": 30, "stocks": 50, "bonds": 20}
                        },
                        "recommended_actions": [
                            "Sell 5% of crypto positions",
                            "Increase stock allocation by 5%"
                        ],
                        "created_at": "2025-06-20T13:15:00Z"
                    },
                    {
                        "insight_id": "insight_3",
                        "category": "risk_management",
                        "title": "Correlation Risk Alert",
                        "content": "Detected increased correlation between your tech stock and crypto holdings, reducing diversification benefits.",
                        "confidence": 0.89,
                        "risk_level": "medium",
                        "supporting_data": {
                            "current_correlation": 0.78,
                            "historical_correlation": 0.45,
                            "risk_increase": "23%"
                        },
                        "recommended_actions": [
                            "Consider reducing exposure to growth tech",
                            "Add defensive positions"
                        ],
                        "created_at": "2025-06-20T12:45:00Z"
                    }
                ],
                "total_insights": 3,
                "categories_available": ["market_analysis", "portfolio_optimization", "risk_management", "trading_opportunity", "education"],
                "generated_at": datetime.now(timezone.utc).isoformat()
            }
        
        category_list = categories.split(",") if categories else None
        insights = await eliza_service.get_ai_insights(category_list, limit)
        
        return {
            "insights": [
                {
                    "insight_id": insight.insight_id,
                    "category": insight.category,
                    "title": insight.title,
                    "content": insight.content,
                    "confidence": insight.confidence,
                    "risk_level": insight.risk_level,
                    "supporting_data": insight.supporting_data,
                    "recommended_actions": insight.recommended_actions,
                    "created_at": insight.created_at.isoformat()
                } for insight in insights
            ],
            "total_insights": len(insights),
            "filters_applied": {"categories": category_list, "limit": limit}
        }
        
    except Exception as e:
        logger.error(f"Failed to get AI insights: {e}")
        raise HTTPException(status_code=500, detail=f"AI insights error: {str(e)}")

@app.get("/api/v1/ai/analytics")
async def get_ai_analytics():
    """Get analytics about AI conversations and performance"""
    try:
        eliza_service = registry.get_service("eliza_ai_integration_service")
        if not eliza_service:
            # Return mock AI analytics
            return {
                "conversation_metrics": {
                    "total_sessions": 156,
                    "active_sessions": 23,
                    "total_messages": 2847,
                    "user_messages": 1456,
                    "ai_messages": 1391,
                    "average_confidence": 0.867
                },
                "mode_distribution": {
                    "trading_assistant": 89,
                    "market_analysis": 34,
                    "strategy_advisor": 18,
                    "risk_counselor": 12,
                    "education_tutor": 3
                },
                "personality_distribution": {
                    "professional": 78,
                    "friendly": 45,
                    "analytical": 23,
                    "cautious": 7,
                    "educational": 3
                },
                "engagement_metrics": {
                    "avg_messages_per_session": 18.2,
                    "avg_session_duration_minutes": 45.7,
                    "user_satisfaction_score": 4.2,
                    "response_time_ms": 1247
                },
                "ai_performance": {
                    "response_accuracy": 0.89,
                    "user_feedback_positive": 0.86,
                    "knowledge_coverage": 0.92,
                    "conversation_completion_rate": 0.78
                },
                "popular_topics": [
                    {"topic": "Bitcoin Analysis", "frequency": 45},
                    {"topic": "Portfolio Review", "frequency": 38},
                    {"topic": "Risk Assessment", "frequency": 29},
                    {"topic": "Strategy Optimization", "frequency": 22},
                    {"topic": "Market Outlook", "frequency": 18}
                ],
                "model_usage": {
                    "gpt-4-turbo": {"requests": 1247, "avg_response_time": 1.2},
                    "claude-3-opus": {"requests": 892, "avg_response_time": 1.8},
                    "gpt-4": {"requests": 567, "avg_response_time": 1.1}
                },
                "last_updated": datetime.now(timezone.utc).isoformat()
            }
        
        analytics = await eliza_service.get_conversation_analytics()
        return analytics
        
    except Exception as e:
        logger.error(f"Failed to get AI analytics: {e}")
        raise HTTPException(status_code=500, detail=f"AI analytics error: {str(e)}")

@app.get("/api/v1/ai/service/status")
async def get_ai_service_status():
    """Get Eliza AI service status and metrics"""
    try:
        eliza_service = registry.get_service("eliza_ai_integration_service")
        if not eliza_service:
            return {
                "service": "eliza_ai_integration_service",
                "status": "mock_mode",
                "active_sessions": 23,
                "total_sessions": 156,
                "ai_models": {
                    "conversation": "gpt-4-turbo",
                    "analysis": "claude-3-opus",
                    "strategy": "gpt-4",
                    "risk": "claude-3-sonnet"
                },
                "personality_types": 6,
                "conversation_modes": 6,
                "last_update": datetime.now(timezone.utc).isoformat(),
                "mode": "mock_data"
            }
        
        status = await eliza_service.get_service_status()
        return status
        
    except Exception as e:
        logger.error(f"Failed to get AI service status: {e}")
        raise HTTPException(status_code=500, detail=f"AI service status error: {str(e)}")

# ============================================================================
# MCP SERVER INTEGRATION API ENDPOINTS - Phase 17
# ============================================================================

@app.get("/api/v1/mcp/servers")
async def get_mcp_servers():
    """Get all MCP servers status and information"""
    try:
        mcp_service = registry.get_service("mcp_server_integration_service")
        if not mcp_service:
            return {"servers": [], "error": "MCP service not available"}
        
        servers = list(mcp_service.servers.values())
        return {
            "servers": [
                {
                    "server_id": server.server_id,
                    "name": server.name,
                    "type": server.server_type.value,
                    "status": server.status.value,
                    "capabilities": [cap.value for cap in server.capabilities],
                    "pid": server.pid,
                    "port": server.port,
                    "last_health_check": server.last_health_check.isoformat() if server.last_health_check else None,
                    "metadata": server.metadata
                } for server in servers
            ],
            "total_count": len(servers),
            "connected_count": len([s for s in servers if s.status.value == "connected"]),
            "last_updated": datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"Failed to get MCP servers: {e}")
        raise HTTPException(status_code=500, detail=f"MCP servers error: {str(e)}")

@app.post("/api/v1/mcp/servers/{server_id}/start")
async def start_mcp_server(server_id: str):
    """Start an MCP server"""
    try:
        mcp_service = registry.get_service("mcp_server_integration_service")
        if not mcp_service:
            raise HTTPException(status_code=503, detail="MCP service not available")
        
        result = await mcp_service.start_mcp_server(server_id)
        return result
        
    except Exception as e:
        logger.error(f"Failed to start MCP server {server_id}: {e}")
        raise HTTPException(status_code=500, detail=f"MCP server start error: {str(e)}")

@app.post("/api/v1/mcp/servers/{server_id}/stop")
async def stop_mcp_server(server_id: str):
    """Stop an MCP server"""
    try:
        mcp_service = registry.get_service("mcp_server_integration_service")
        if not mcp_service:
            raise HTTPException(status_code=503, detail="MCP service not available")
        
        result = await mcp_service.stop_mcp_server(server_id)
        return result
        
    except Exception as e:
        logger.error(f"Failed to stop MCP server {server_id}: {e}")
        raise HTTPException(status_code=500, detail=f"MCP server stop error: {str(e)}")

@app.get("/api/v1/mcp/servers/{server_id}/status")
async def get_mcp_server_status(server_id: str):
    """Get detailed status for a specific MCP server"""
    try:
        mcp_service = registry.get_service("mcp_server_integration_service")
        if not mcp_service:
            raise HTTPException(status_code=503, detail="MCP service not available")
        
        status = await mcp_service.get_server_status(server_id)
        return status
        
    except Exception as e:
        logger.error(f"Failed to get MCP server status {server_id}: {e}")
        raise HTTPException(status_code=500, detail=f"MCP server status error: {str(e)}")

@app.get("/api/v1/mcp/tools")
async def get_mcp_tools(server_id: Optional[str] = None):
    """Get available MCP tools"""
    try:
        mcp_service = registry.get_service("mcp_server_integration_service")
        if not mcp_service:
            return {"tools": [], "error": "MCP service not available"}
        
        tools = await mcp_service.get_available_tools(server_id)
        return {
            "tools": [
                {
                    "tool_id": tool.tool_id,
                    "server_id": tool.server_id,
                    "name": tool.name,
                    "description": tool.description,
                    "category": tool.category,
                    "input_schema": tool.input_schema,
                    "usage_count": tool.metadata.get("usage_count", 0) if tool.metadata else 0
                } for tool in tools
            ],
            "total_count": len(tools),
            "server_filter": server_id,
            "last_updated": datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"Failed to get MCP tools: {e}")
        raise HTTPException(status_code=500, detail=f"MCP tools error: {str(e)}")

@app.post("/api/v1/mcp/tools/{tool_id}/call")
async def call_mcp_tool(tool_id: str, parameters: Dict[str, Any]):
    """Call an MCP tool with parameters"""
    try:
        mcp_service = registry.get_service("mcp_server_integration_service")
        if not mcp_service:
            raise HTTPException(status_code=503, detail="MCP service not available")
        
        response = await mcp_service.call_mcp_tool(tool_id, parameters)
        return {
            "request_id": response.request_id,
            "server_id": response.server_id,
            "success": response.success,
            "result": response.result,
            "error": response.error,
            "timestamp": response.timestamp.isoformat() if response.timestamp else None,
            "duration_ms": response.duration_ms
        }
        
    except Exception as e:
        logger.error(f"Failed to call MCP tool {tool_id}: {e}")
        raise HTTPException(status_code=500, detail=f"MCP tool call error: {str(e)}")

@app.get("/api/v1/mcp/analytics")
async def get_mcp_analytics():
    """Get comprehensive MCP analytics"""
    try:
        mcp_service = registry.get_service("mcp_server_integration_service")
        if not mcp_service:
            return {"error": "MCP service not available"}
        
        analytics = await mcp_service.get_mcp_analytics()
        return analytics
        
    except Exception as e:
        logger.error(f"Failed to get MCP analytics: {e}")
        raise HTTPException(status_code=500, detail=f"MCP analytics error: {str(e)}")

@app.get("/api/v1/mcp/service/status")
async def get_mcp_service_status():
    """Get MCP service status"""
    try:
        mcp_service = registry.get_service("mcp_server_integration_service")
        if not mcp_service:
            return {"service": "mcp_server_integration_service", "status": "not_available"}
        
        status = await mcp_service.get_service_status()
        return status
        
    except Exception as e:
        logger.error(f"Failed to get MCP service status: {e}")
        raise HTTPException(status_code=500, detail=f"MCP service status error: {str(e)}")

# ============================================================================
# PYTHON ANALYSIS PIPELINE API ENDPOINTS - Phase 18
# ============================================================================

@app.post("/api/v1/python/scripts")
async def submit_python_script(script_data: Dict[str, Any]):
    """Submit a Python script for analysis"""
    try:
        pipeline_service = registry.get_service("python_analysis_pipeline_service")
        if not pipeline_service:
            raise HTTPException(status_code=503, detail="Python analysis service not available")
        
        script = await pipeline_service.submit_script(script_data)
        return {
            "script_id": script.script_id,
            "name": script.name,
            "language": script.language,
            "version": script.version,
            "dependencies": script.dependencies,
            "status": "submitted",
            "submitted_at": datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"Failed to submit Python script: {e}")
        raise HTTPException(status_code=500, detail=f"Script submission error: {str(e)}")

@app.get("/api/v1/python/scripts")
async def get_python_scripts():
    """Get all Python scripts"""
    try:
        pipeline_service = registry.get_service("python_analysis_pipeline_service")
        if not pipeline_service:
            return {"scripts": [], "error": "Python analysis service not available"}
        
        scripts = list(pipeline_service.scripts.values())
        return {
            "scripts": [
                {
                    "script_id": script.script_id,
                    "name": script.name,
                    "language": script.language,
                    "version": script.version,
                    "dependencies": script.dependencies,
                    "lines_of_code": len(script.code.split('\n')),
                    "character_count": len(script.code),
                    "metadata": script.metadata
                } for script in scripts
            ],
            "total_count": len(scripts),
            "last_updated": datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"Failed to get Python scripts: {e}")
        raise HTTPException(status_code=500, detail=f"Scripts retrieval error: {str(e)}")

@app.get("/api/v1/python/scripts/{script_id}")
async def get_python_script(script_id: str):
    """Get a specific Python script"""
    try:
        pipeline_service = registry.get_service("python_analysis_pipeline_service")
        if not pipeline_service:
            raise HTTPException(status_code=503, detail="Python analysis service not available")
        
        script = pipeline_service.scripts.get(script_id)
        if not script:
            raise HTTPException(status_code=404, detail=f"Script {script_id} not found")
        
        return {
            "script_id": script.script_id,
            "name": script.name,
            "code": script.code,
            "language": script.language,
            "version": script.version,
            "dependencies": script.dependencies,
            "metadata": script.metadata,
            "lines_of_code": len(script.code.split('\n')),
            "character_count": len(script.code)
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get Python script {script_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Script retrieval error: {str(e)}")

@app.post("/api/v1/python/scripts/{script_id}/analyze")
async def analyze_python_script(script_id: str, analysis_request: Dict[str, Any]):
    """Run analysis on a Python script"""
    try:
        pipeline_service = registry.get_service("python_analysis_pipeline_service")
        if not pipeline_service:
            raise HTTPException(status_code=503, detail="Python analysis service not available")
        
        from services.python_analysis_pipeline_service import AnalysisType, ExecutionMode
        
        # Parse analysis types
        analysis_types = []
        for analysis_type_str in analysis_request.get("analysis_types", ["syntax_check"]):
            try:
                analysis_types.append(AnalysisType(analysis_type_str))
            except ValueError:
                raise HTTPException(status_code=400, detail=f"Invalid analysis type: {analysis_type_str}")
        
        # Parse execution mode
        execution_mode_str = analysis_request.get("execution_mode", "sandbox")
        try:
            execution_mode = ExecutionMode(execution_mode_str)
        except ValueError:
            raise HTTPException(status_code=400, detail=f"Invalid execution mode: {execution_mode_str}")
        
        timeout = analysis_request.get("timeout", 60)
        
        request_id = await pipeline_service.run_analysis(
            script_id=script_id,
            analysis_types=analysis_types,
            execution_mode=execution_mode,
            timeout=timeout
        )
        
        return {
            "request_id": request_id,
            "script_id": script_id,
            "analysis_types": [at.value for at in analysis_types],
            "execution_mode": execution_mode.value,
            "timeout": timeout,
            "status": "started",
            "started_at": datetime.now(timezone.utc).isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to analyze Python script {script_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Analysis error: {str(e)}")

@app.post("/api/v1/python/scripts/{script_id}/execute")
async def execute_python_script(script_id: str, execution_request: Dict[str, Any]):
    """Execute a Python script"""
    try:
        pipeline_service = registry.get_service("python_analysis_pipeline_service")
        if not pipeline_service:
            raise HTTPException(status_code=503, detail="Python analysis service not available")
        
        from services.python_analysis_pipeline_service import ExecutionMode
        
        # Parse execution mode
        execution_mode_str = execution_request.get("execution_mode", "sandbox")
        try:
            execution_mode = ExecutionMode(execution_mode_str)
        except ValueError:
            raise HTTPException(status_code=400, detail=f"Invalid execution mode: {execution_mode_str}")
        
        parameters = execution_request.get("parameters", {})
        
        result = await pipeline_service.execute_script(
            script_id=script_id,
            execution_mode=execution_mode,
            parameters=parameters
        )
        
        return {
            "execution_id": result.execution_id,
            "script_id": result.script_id,
            "success": result.success,
            "output": result.output,
            "error_output": result.error_output,
            "return_value": result.return_value,
            "execution_time_ms": result.execution_time_ms,
            "memory_peak_mb": result.memory_peak_mb,
            "cpu_usage_percent": result.cpu_usage_percent,
            "timestamp": result.timestamp.isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to execute Python script {script_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Execution error: {str(e)}")

@app.get("/api/v1/python/scripts/{script_id}/results")
async def get_analysis_results(script_id: str):
    """Get analysis results for a script"""
    try:
        pipeline_service = registry.get_service("python_analysis_pipeline_service")
        if not pipeline_service:
            raise HTTPException(status_code=503, detail="Python analysis service not available")
        
        results = await pipeline_service.get_analysis_results(script_id)
        return {
            "script_id": script_id,
            "results": [
                {
                    "request_id": result.request_id,
                    "analysis_type": result.analysis_type.value,
                    "status": result.status.value,
                    "result": result.result,
                    "errors": result.errors,
                    "warnings": result.warnings,
                    "execution_time_ms": result.execution_time_ms,
                    "memory_usage_mb": result.memory_usage_mb,
                    "timestamp": result.timestamp.isoformat()
                } for result in results
            ],
            "total_results": len(results),
            "last_updated": datetime.now(timezone.utc).isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get analysis results for {script_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Results retrieval error: {str(e)}")

@app.get("/api/v1/python/analytics")
async def get_python_analytics(script_id: Optional[str] = None):
    """Get comprehensive Python analysis analytics"""
    try:
        pipeline_service = registry.get_service("python_analysis_pipeline_service")
        if not pipeline_service:
            return {"error": "Python analysis service not available"}
        
        analytics = await pipeline_service.get_script_analytics(script_id)
        return analytics
        
    except Exception as e:
        logger.error(f"Failed to get Python analytics: {e}")
        raise HTTPException(status_code=500, detail=f"Analytics error: {str(e)}")

@app.get("/api/v1/python/pipeline/status")
async def get_pipeline_status():
    """Get Python analysis pipeline status"""
    try:
        pipeline_service = registry.get_service("python_analysis_pipeline_service")
        if not pipeline_service:
            return {"service": "python_analysis_pipeline_service", "status": "not_available"}
        
        status = await pipeline_service.get_pipeline_status()
        return status
        
    except Exception as e:
        logger.error(f"Failed to get pipeline status: {e}")
        raise HTTPException(status_code=500, detail=f"Pipeline status error: {str(e)}")

@app.get("/api/v1/python/service/status")
async def get_python_service_status():
    """Get Python analysis service status"""
    try:
        pipeline_service = registry.get_service("python_analysis_pipeline_service")
        if not pipeline_service:
            return {"service": "python_analysis_pipeline_service", "status": "not_available"}
        
        status = await pipeline_service.get_service_status()
        return status
        
    except Exception as e:
        logger.error(f"Failed to get Python service status: {e}")
        raise HTTPException(status_code=500, detail=f"Python service status error: {str(e)}")

# Mount dashboard and static files
if os.path.exists("dashboard/static"):
    app.mount("/dashboard/static", StaticFiles(directory="dashboard/static"), name="dashboard_static")

if os.path.exists("static"):
    app.mount("/static", StaticFiles(directory="static"), name="static")

# Dashboard endpoints
@app.get("/dashboard", response_class=HTMLResponse)
async def dashboard_home(request: Request):
    """Main dashboard home page"""
    try:
        from dashboard.monorepo_dashboard import dashboard
        overview = await dashboard.get_system_overview()
        
        # Use simple template rendering since we have the HTML content
        with open("dashboard/templates/dashboard.html", "r") as f:
            template_content = f.read()
        
        # Simple template variable replacement
        html_content = template_content.replace("{{ title }}", "MCP Trading Platform Dashboard")
        html_content = html_content.replace("{{ overview.status }}", overview.get("status", "unknown"))
        html_content = html_content.replace("{{ overview.uptime_formatted or '0s' }}", overview.get("uptime_formatted", "0s"))
        html_content = html_content.replace("{{ overview.registry.services_count or 0 }}", str(overview.get("registry", {}).get("services_count", 0)))
        html_content = html_content.replace("{{ overview.registry.connections_count or 0 }}", str(overview.get("registry", {}).get("connections_count", 0)))
        html_content = html_content.replace("{{ overview.version or '2.0.0' }}", overview.get("version", "2.0.0"))
        html_content = html_content.replace("{{ overview.architecture or 'monorepo' }}", overview.get("architecture", "monorepo"))
        html_content = html_content.replace("{{ overview.environment or 'production' }}", overview.get("environment", "production"))
        
        return HTMLResponse(content=html_content)
    except Exception as e:
        return HTMLResponse(content=f"<html><body><h1>Dashboard Error</h1><p>{str(e)}</p></body></html>")

# ===============================================
# ENHANCED DATABASE API ENDPOINTS
# ===============================================

@app.get("/api/v1/dashboard/enhanced-summary")
async def get_enhanced_dashboard_summary(
    enhanced_db: EnhancedDatabaseService = Depends(get_enhanced_database_service)
):
    """Get comprehensive dashboard summary using enhanced database"""
    try:
        # Use solo operator as default user for now
        user_id = "solo_operator"
        summary = await enhanced_db.get_dashboard_summary(user_id)
        return {"success": True, "data": summary}
    except Exception as e:
        logger.error(f"Error getting enhanced dashboard summary: {e}")
        raise HTTPException(status_code=500, detail=f"Dashboard summary error: {str(e)}")

@app.get("/api/v1/blockchain/wallets")
async def get_blockchain_wallets(
    user_id: str = "solo_operator",
    enhanced_db: EnhancedDatabaseService = Depends(get_enhanced_database_service)
):
    """Get all blockchain wallets for a user"""
    try:
        wallets = await enhanced_db.get_user_wallets(user_id)
        return {"success": True, "wallets": wallets}
    except Exception as e:
        logger.error(f"Error getting blockchain wallets: {e}")
        raise HTTPException(status_code=500, detail=f"Wallets error: {str(e)}")

@app.post("/api/v1/blockchain/wallets")
async def create_blockchain_wallet(
    wallet_data: BlockchainWalletModel,
    enhanced_db: EnhancedDatabaseService = Depends(get_enhanced_database_service)
):
    """Create a new blockchain wallet"""
    try:
        result = await enhanced_db.create_blockchain_wallet(wallet_data)
        if result['success']:
            return {"success": True, "wallet": result}
        else:
            raise HTTPException(status_code=400, detail=result['error'])
    except Exception as e:
        logger.error(f"Error creating blockchain wallet: {e}")
        raise HTTPException(status_code=500, detail=f"Wallet creation error: {str(e)}")

@app.get("/api/v1/blockchain/transactions/{wallet_id}")
async def get_wallet_transactions(
    wallet_id: str,
    limit: int = 50,
    enhanced_db: EnhancedDatabaseService = Depends(get_enhanced_database_service)
):
    """Get transactions for a specific wallet"""
    try:
        transactions = await enhanced_db.get_wallet_transactions(wallet_id, limit)
        return {"success": True, "transactions": transactions}
    except Exception as e:
        logger.error(f"Error getting wallet transactions: {e}")
        raise HTTPException(status_code=500, detail=f"Transactions error: {str(e)}")

@app.post("/api/v1/blockchain/transactions")
async def create_blockchain_transaction(
    transaction_data: BlockchainTransactionModel,
    enhanced_db: EnhancedDatabaseService = Depends(get_enhanced_database_service)
):
    """Create a new blockchain transaction"""
    try:
        result = await enhanced_db.create_blockchain_transaction(transaction_data)
        if result['success']:
            return {"success": True, "transaction": result}
        else:
            raise HTTPException(status_code=400, detail=result['error'])
    except Exception as e:
        logger.error(f"Error creating blockchain transaction: {e}")
        raise HTTPException(status_code=500, detail=f"Transaction creation error: {str(e)}")

@app.get("/api/v1/notifications")
async def get_user_notifications(
    user_id: str = "solo_operator",
    unread_only: bool = False,
    limit: int = 50,
    enhanced_db: EnhancedDatabaseService = Depends(get_enhanced_database_service)
):
    """Get notifications for a user"""
    try:
        notifications = await enhanced_db.get_user_notifications(user_id, unread_only, limit)
        return {"success": True, "notifications": notifications}
    except Exception as e:
        logger.error(f"Error getting notifications: {e}")
        raise HTTPException(status_code=500, detail=f"Notifications error: {str(e)}")

@app.post("/api/v1/notifications")
async def create_notification(
    notification_data: NotificationModel,
    enhanced_db: EnhancedDatabaseService = Depends(get_enhanced_database_service)
):
    """Create a new notification"""
    try:
        notification_id = await enhanced_db.create_notification(notification_data)
        if notification_id:
            return {"success": True, "notification_id": notification_id}
        else:
            raise HTTPException(status_code=400, detail="Failed to create notification")
    except Exception as e:
        logger.error(f"Error creating notification: {e}")
        raise HTTPException(status_code=500, detail=f"Notification creation error: {str(e)}")

@app.put("/api/v1/notifications/{notification_id}/read")
async def mark_notification_read(
    notification_id: str,
    enhanced_db: EnhancedDatabaseService = Depends(get_enhanced_database_service)
):
    """Mark a notification as read"""
    try:
        success = await enhanced_db.mark_notification_read(notification_id)
        if success:
            return {"success": True, "message": "Notification marked as read"}
        else:
            raise HTTPException(status_code=400, detail="Failed to mark notification as read")
    except Exception as e:
        logger.error(f"Error marking notification read: {e}")
        raise HTTPException(status_code=500, detail=f"Notification update error: {str(e)}")

@app.get("/api/v1/events/unprocessed")
async def get_unprocessed_events(
    limit: int = 100,
    enhanced_db: EnhancedDatabaseService = Depends(get_enhanced_database_service)
):
    """Get unprocessed system events for real-time streaming"""
    try:
        events = await enhanced_db.get_unprocessed_events(limit)
        return {"success": True, "events": events}
    except Exception as e:
        logger.error(f"Error getting unprocessed events: {e}")
        raise HTTPException(status_code=500, detail=f"Events error: {str(e)}")

@app.post("/api/v1/events")
async def create_system_event(
    event_data: SystemEventModel,
    enhanced_db: EnhancedDatabaseService = Depends(get_enhanced_database_service)
):
    """Create a new system event"""
    try:
        event_id = await enhanced_db.create_system_event(
            event_data.event_type,
            event_data.event_source,
            event_data.source_id,
            event_data.event_data,
            event_data.target_users,
            event_data.broadcast,
            event_data.event_priority
        )
        if event_id:
            return {"success": True, "event_id": event_id}
        else:
            raise HTTPException(status_code=400, detail="Failed to create system event")
    except Exception as e:
        logger.error(f"Error creating system event: {e}")
        raise HTTPException(status_code=500, detail=f"Event creation error: {str(e)}")

@app.get("/api/v1/metrics/realtime")
async def get_realtime_metrics(
    source_type: str = None,
    source_id: str = None,
    metric_name: str = None,
    hours: int = 24,
    enhanced_db: EnhancedDatabaseService = Depends(get_enhanced_database_service)
):
    """Get real-time metrics with optional filtering"""
    try:
        metrics = await enhanced_db.get_recent_metrics(source_type, source_id, metric_name, hours)
        return {"success": True, "metrics": metrics}
    except Exception as e:
        logger.error(f"Error getting realtime metrics: {e}")
        raise HTTPException(status_code=500, detail=f"Metrics error: {str(e)}")

@app.post("/api/v1/metrics/realtime")
async def record_realtime_metric(
    metric_data: RealtimeMetricModel,
    enhanced_db: EnhancedDatabaseService = Depends(get_enhanced_database_service)
):
    """Record a new real-time metric"""
    try:
        success = await enhanced_db.record_realtime_metric(metric_data)
        if success:
            return {"success": True, "message": "Metric recorded successfully"}
        else:
            raise HTTPException(status_code=400, detail="Failed to record metric")
    except Exception as e:
        logger.error(f"Error recording realtime metric: {e}")
        raise HTTPException(status_code=500, detail=f"Metric recording error: {str(e)}")

@app.get("/api/v1/predictions/active")
async def get_active_ml_predictions(
    prediction_type: str = None,
    model_name: str = None,
    enhanced_db: EnhancedDatabaseService = Depends(get_enhanced_database_service)
):
    """Get active ML predictions with optional filtering"""
    try:
        predictions = await enhanced_db.get_active_predictions(prediction_type, model_name)
        return {"success": True, "predictions": predictions}
    except Exception as e:
        logger.error(f"Error getting ML predictions: {e}")
        raise HTTPException(status_code=500, detail=f"Predictions error: {str(e)}")

@app.post("/api/v1/predictions")
async def create_ml_prediction(
    prediction_data: MLPredictionModel,
    enhanced_db: EnhancedDatabaseService = Depends(get_enhanced_database_service)
):
    """Create a new ML prediction"""
    try:
        prediction_id = await enhanced_db.create_ml_prediction(prediction_data)
        if prediction_id:
            return {"success": True, "prediction_id": prediction_id}
        else:
            raise HTTPException(status_code=400, detail="Failed to create prediction")
    except Exception as e:
        logger.error(f"Error creating ML prediction: {e}")
        raise HTTPException(status_code=500, detail=f"Prediction creation error: {str(e)}")

@app.get("/dashboard/api/overview")
async def dashboard_overview():
    """Dashboard overview API"""
    try:
        from dashboard.monorepo_dashboard import dashboard
        return await dashboard.get_system_overview()
    except Exception as e:
        return {"error": str(e), "timestamp": datetime.now(timezone.utc).isoformat()}

# ==========================================
# REAL-TIME PRICE AGGREGATION API ENDPOINTS
# ==========================================

@app.websocket("/ws/prices")
async def websocket_prices(websocket: WebSocket):
    """WebSocket endpoint for real-time price updates"""
    await websocket.accept()
    
    try:
        # Start price aggregator if not running
        price_aggregator = registry.get_service("realtime_price_aggregator")
        if not price_aggregator:
            # Send mock price updates
            while True:
                try:
                    mock_price = {
                        "type": "price_update",
                        "data": {
                            "token_pair": "BTC/USD",
                            "mid_price": 45000.0 + (asyncio.get_event_loop().time() % 1000),
                            "best_bid": 44995.0,
                            "best_ask": 45005.0,
                            "volume_weighted_price": 45001.25,
                            "total_volume": 1250000.0,
                            "price_sources": 3,
                            "timestamp": datetime.now(timezone.utc).isoformat()
                        }
                    }
                    await websocket.send_json(mock_price)
                    await asyncio.sleep(1)
                except:
                    break
        
        if not price_aggregator.running:
            # Start aggregator in background
            asyncio.create_task(price_aggregator.start([
                "BTC/USD", "ETH/USD", "SOL/USD", "USDC/USD"
            ]))
        
        # Subscribe to price updates
        def send_price_update(aggregated_price):
            try:
                from dataclasses import asdict
                asyncio.create_task(websocket.send_json({
                    "type": "price_update",
                    "data": asdict(aggregated_price)
                }))
            except Exception as e:
                logger.error(f"Error sending price update: {e}")
        
        # Subscribe to major pairs
        for pair in ["BTC/USD", "ETH/USD", "SOL/USD", "USDC/USD"]:
            price_aggregator.subscribe(pair, send_price_update)
        
        # Keep connection alive
        while True:
            try:
                await websocket.receive_text()
            except:
                break
                
    except Exception as e:
        logger.error(f"WebSocket error: {e}")
    finally:
        await websocket.close()

@app.websocket("/ws/orchestration")
async def orchestration_websocket(websocket: WebSocket):
    """WebSocket endpoint for real-time orchestration updates"""
    client_info = {
        "connection_time": datetime.now(timezone.utc),
        "client_type": "orchestration_monitor"
    }
    
    await ws_manager.connect(websocket, client_info)
    
    try:
        # Subscribe to orchestration events
        event_system = registry.get_service("enhanced_event_propagation")
        
        if event_system:
            # Create event handler
            async def handle_event(event):
                await websocket.send_json({
                    "type": "orchestration_event",
                    "data": {
                        "event_id": event.event_id,
                        "event_type": event.event_type.value,
                        "timestamp": event.timestamp.isoformat(),
                        "data": event.data
                    }
                })
            
            # Subscribe to all orchestration events
            from services.enhanced_event_propagation import EventType
            subscription_id = await event_system.subscribe(
                subscriber_service="websocket_client",
                event_types=list(EventType),
                handler=handle_event
            )
        
        # Keep connection alive
        while True:
            data = await websocket.receive_text()
            
            # Handle ping/pong
            if data == "ping":
                await websocket.send_text("pong")
            
    except WebSocketDisconnect:
        ws_manager.disconnect(websocket)
        
        # Unsubscribe from events
        if event_system and 'subscription_id' in locals():
            await event_system.unsubscribe(subscription_id)
    except Exception as e:
        logger.error(f"WebSocket error: {e}")
        ws_manager.disconnect(websocket)

@app.websocket("/ws/agui")
async def agui_websocket_endpoint(websocket: WebSocket):
    """AG-UI Protocol v2 WebSocket endpoint for real-time agent communication
    
    Handles exact database schema structures as specified:
    - agent_decisions: UUID agent_id, user_id from auth.users, JSONB decision
    - signals: VARCHAR agent_id, trading signals with metadata
    - agent_paper_trades: UUID agent_id, TEXT account_id
    - realtime_events: All AGUI events for broadcasting
    """
    client_info = {
        "connection_time": datetime.now(timezone.utc),
        "client_type": "agui_client",
        "channels": []
    }
    
    # Default IDs from database verification
    DEFAULT_AGENT_UUID = "32c1b842-f4f6-4275-9804-b8bddedfa56e"
    DEFAULT_USER_UUID = "09c1de86-05fc-4326-a62b-fd5ff1c8b8f3"
    DEFAULT_ACCOUNT_ID = "paper_acc_1751613589.944507_2581ab25"
    
    await websocket_manager.connect(websocket, client_info)
    
    try:
        # Send connection established event
        await websocket.send_json({
            "id": f"conn_{int(datetime.now().timestamp())}",
            "type": "connection.established",
            "data": {
                "client_id": f"client_{id(websocket)}",
                "timestamp": datetime.now(timezone.utc).isoformat()
            },
            "timestamp": int(datetime.now().timestamp() * 1000),
            "source": "backend"
        })
        
        # Start periodic mock event generation
        async def generate_mock_events():
            """Generate mock AG-UI events for development/demo purposes"""
            while True:
                try:
                    await asyncio.sleep(10)  # Send events every 10 seconds
                    
                    # Generate mock agent decision with correct data structure
                    await websocket.send_json({
                        "id": f"agent_decision_{int(datetime.now().timestamp())}",
                        "type": "agent.decision_made",
                        "data": {
                            "agent_id": DEFAULT_AGENT_UUID,  # Correct UUID format
                            "agent_name": "Marcus Momentum",
                            "symbol": "BTC/USD",
                            "decision_type": "trade",
                            "decision": {  # JSONB object, not string
                                "action": "buy",
                                "reasoning": "AGUI detected momentum signal with RSI oversold",
                                "market_data": {
                                    "price": 43250.50,
                                    "rsi": 28.5,
                                    "volume": 1250000
                                }
                            },
                            "confidence": 0.85,
                            "action_taken": True,
                            "timestamp": datetime.now(timezone.utc).isoformat()
                        },
                        "timestamp": int(datetime.now().timestamp() * 1000),
                        "source": "agent_network"
                    })
                    
                    await asyncio.sleep(15)  # Wait 15 seconds
                    
                    # Generate mock trading signal with correct data structure
                    await websocket.send_json({
                        "id": f"trade_signal_{int(datetime.now().timestamp())}",
                        "type": "trade.signal_generated",
                        "data": {
                            "agent_id": DEFAULT_AGENT_UUID,  # UUID format for conversion
                            "symbol": "BTC/USD",
                            "action": "BUY",  # Will be stored as VARCHAR agent_id in signals table
                            "confidence": 0.78,
                            "strength": 0.78,
                            "price": 45000 + (datetime.now().second * 10),
                            "price_target": 46000.0,
                            "strategy": "momentum_following",
                            "timestamp": datetime.now(timezone.utc).isoformat()
                        },
                        "timestamp": int(datetime.now().timestamp() * 1000),
                        "source": "trading_engine"
                    })
                    
                    await asyncio.sleep(12)  # Wait 12 seconds
                    
                    # Generate mock paper trade with correct data structure
                    await websocket.send_json({
                        "id": f"paper_trade_{int(datetime.now().timestamp())}",
                        "type": "trade.order_filled",
                        "data": {
                            "agent_id": DEFAULT_AGENT_UUID,  # UUID format
                            "account_id": DEFAULT_ACCOUNT_ID,  # TEXT format
                            "symbol": "BTC/USD",
                            "side": "buy",
                            "order_type": "market",
                            "quantity": 0.01,
                            "price": 43250.50,
                            "status": "filled",
                            "timestamp": datetime.now(timezone.utc).isoformat()
                        },
                        "timestamp": int(datetime.now().timestamp() * 1000),
                        "source": "trading_engine"
                    })
                    
                    await asyncio.sleep(18)  # Wait 18 seconds
                    
                    # Generate mock portfolio update
                    await websocket.send_json({
                        "id": f"portfolio_{int(datetime.now().timestamp())}",
                        "type": "portfolio.value_updated",
                        "data": {
                            "total_value": 125000 + (datetime.now().second * 100),
                            "change_24h": 2500.50,
                            "change_percentage": 2.04,
                            "timestamp": datetime.now(timezone.utc).isoformat()
                        },
                        "timestamp": int(datetime.now().timestamp() * 1000),
                        "source": "portfolio_service"
                    })
                    
                except Exception as e:
                    logger.error(f"Error generating mock AG-UI events: {e}")
                    break
        
        # Start mock event generation in background
        mock_task = asyncio.create_task(generate_mock_events())
        
        # Keep connection alive and handle AG-UI messages
        while True:
            data = await websocket.receive_text()
            
            try:
                message = json.loads(data)
                message_id = message.get("id", f"msg_{int(datetime.now().timestamp())}")
                message_type = message.get("type", "unknown")
                message_data = message.get("data", {})
                
                logger.debug(f"AG-UI message received: {message_type}")
                
                # Handle different AG-UI message types
                if message_type == "system.notification":
                    # Handle system notifications (including heartbeat)
                    if message_data.get("type") == "heartbeat":
                        # Respond to heartbeat
                        await websocket.send_json({
                            "id": f"heartbeat_{int(datetime.now().timestamp())}",
                            "type": "system.notification",
                            "data": {
                                "type": "heartbeat_ack",
                                "message": "Heartbeat acknowledged",
                                "level": "info",
                                "timestamp": datetime.now(timezone.utc).isoformat()
                            },
                            "timestamp": int(datetime.now().timestamp() * 1000),
                            "source": "backend"
                        })
                
                elif message_type == "agent.decision_made":
                    # Store agent decision in database
                    try:
                        enhanced_db = registry.get_service("enhanced_database")
                        if enhanced_db:
                            # Insert into agent_decisions table (UUID format)
                            await enhanced_db.execute_query(
                                """INSERT INTO agent_decisions 
                                   (agent_id, user_id, symbol, decision_type, decision, confidence_score, executed) 
                                   VALUES ($1, $2, $3, $4, $5, $6, $7)""",
                                message_data.get("agent_id", DEFAULT_AGENT_UUID),  # UUID
                                DEFAULT_USER_UUID,  # user_id from auth.users
                                message_data.get("symbol", "BTC/USD"),
                                message_data.get("decision_type", "trade"),
                                message_data.get("decision", {"action": "buy", "reasoning": "AGUI signal"}),  # JSONB
                                message_data.get("confidence", 0.85),
                                message_data.get("action_taken", True)
                            )
                            
                            # Also store in realtime_events for broadcasting
                            await enhanced_db.execute_query(
                                """INSERT INTO realtime_events 
                                   (event_type, channel, payload, agent_id) 
                                   VALUES ($1, $2, $3, $4)""",
                                "AGUI_AGENT_DECISION",
                                "agui_websocket",
                                {
                                    "agent_id": message_data.get("agent_id"),
                                    "decision": message_data.get("decision"),
                                    "timestamp": datetime.now(timezone.utc).isoformat()
                                },
                                message_data.get("agent_id", DEFAULT_AGENT_UUID)
                            )
                    except Exception as e:
                        logger.error(f"Error storing agent decision: {e}")
                    
                    # Broadcast agent decisions to other clients
                    await websocket_manager.broadcast({
                        "id": message_id,
                        "type": message_type,
                        "data": message_data,
                        "timestamp": int(datetime.now().timestamp() * 1000),
                        "source": "agent_network"
                    }, "agent_decision")
                    
                elif message_type == "trade.signal_generated":
                    # Store trading signal in database
                    try:
                        enhanced_db = registry.get_service("enhanced_database")
                        if enhanced_db:
                            # Convert UUID agent_id to VARCHAR format for signals table
                            agent_uuid = message_data.get("agent_id", DEFAULT_AGENT_UUID)
                            agent_varchar = f"alpha_trader_{agent_uuid[-3:]}" if len(agent_uuid) > 3 else "alpha_trader_001"
                            
                            # Insert into trading.signals table (VARCHAR format)
                            await enhanced_db.execute_query(
                                """INSERT INTO signals 
                                   (agent_id, symbol, action, strength, confidence, price_target, metadata) 
                                   VALUES ($1, $2, $3, $4, $5, $6, $7)""",
                                agent_varchar,  # VARCHAR format
                                message_data.get("symbol", "BTC/USD"),
                                message_data.get("action", "BUY").upper(),
                                message_data.get("confidence", 0.8),
                                message_data.get("confidence", 0.8),
                                message_data.get("price", 45000.0),
                                {
                                    "source": "AGUI_WebSocket",
                                    "protocol": "v2",
                                    "strategy": message_data.get("strategy", "momentum"),
                                    "original_agent_id": agent_uuid
                                }
                            )
                            
                            # Store in realtime_events for broadcasting
                            await enhanced_db.execute_query(
                                """INSERT INTO realtime_events 
                                   (event_type, channel, payload, agent_id) 
                                   VALUES ($1, $2, $3, $4)""",
                                "AGUI_TRADE_SIGNAL",
                                "agui_websocket",
                                {
                                    "agent_id": agent_uuid,
                                    "signal": message_data.get("action", "BUY"),
                                    "symbol": message_data.get("symbol", "BTC/USD"),
                                    "timestamp": datetime.now(timezone.utc).isoformat()
                                },
                                agent_uuid
                            )
                    except Exception as e:
                        logger.error(f"Error storing trading signal: {e}")
                    
                    # Handle trading signals
                    await websocket_manager.broadcast({
                        "id": message_id,
                        "type": message_type,
                        "data": message_data,
                        "timestamp": int(datetime.now().timestamp() * 1000),
                        "source": "trading_engine"
                    }, "trading_signal")
                    
                elif message_type == "trade.order_placed" or message_type == "trade.order_filled":
                    # Handle paper trades
                    try:
                        enhanced_db = registry.get_service("enhanced_database")
                        if enhanced_db:
                            # Insert into agent_paper_trades table (UUID format)
                            await enhanced_db.execute_query(
                                """INSERT INTO agent_paper_trades 
                                   (agent_id, account_id, symbol, side, order_type, quantity, price, status) 
                                   VALUES ($1, $2, $3, $4, $5, $6, $7, $8)""",
                                message_data.get("agent_id", DEFAULT_AGENT_UUID),  # UUID
                                DEFAULT_ACCOUNT_ID,  # Default paper account
                                message_data.get("symbol", "BTC/USD"),
                                message_data.get("side", "buy"),
                                message_data.get("order_type", "market"),
                                message_data.get("quantity", 0.01),
                                message_data.get("price", 45000.0),
                                "filled" if message_type == "trade.order_filled" else "pending"
                            )
                            
                            # Store in realtime_events
                            await enhanced_db.execute_query(
                                """INSERT INTO realtime_events 
                                   (event_type, channel, payload, agent_id) 
                                   VALUES ($1, $2, $3, $4)""",
                                "AGUI_PAPER_TRADE",
                                "agui_websocket",
                                {
                                    "agent_id": message_data.get("agent_id"),
                                    "trade_type": message_type,
                                    "symbol": message_data.get("symbol"),
                                    "side": message_data.get("side"),
                                    "timestamp": datetime.now(timezone.utc).isoformat()
                                },
                                message_data.get("agent_id", DEFAULT_AGENT_UUID)
                            )
                    except Exception as e:
                        logger.error(f"Error storing paper trade: {e}")
                    
                    # Broadcast trade update
                    await websocket_manager.broadcast({
                        "id": message_id,
                        "type": message_type,
                        "data": message_data,
                        "timestamp": int(datetime.now().timestamp() * 1000),
                        "source": "trading_engine"
                    }, "trade_update")
                    
                elif message_type == "portfolio.value_updated":
                    # Handle portfolio updates
                    await websocket_manager.broadcast({
                        "id": message_id,
                        "type": message_type,
                        "data": message_data,
                        "timestamp": int(datetime.now().timestamp() * 1000),
                        "source": "portfolio_service"
                    }, "portfolio_update")
                    
                elif message_type == "orchestration.event":
                    # Handle orchestration events
                    await websocket_manager.broadcast({
                        "id": message_id,
                        "type": message_type,
                        "data": message_data,
                        "timestamp": int(datetime.now().timestamp() * 1000),
                        "source": "orchestration_engine"
                    }, "orchestration_update")
                
                # Send acknowledgment for processed messages
                await websocket.send_json({
                    "id": f"ack_{message_id}",
                    "type": "system.notification",
                    "data": {
                        "type": "message_processed",
                        "original_message_id": message_id,
                        "message": f"Message {message_type} processed successfully",
                        "level": "info",
                        "timestamp": datetime.now(timezone.utc).isoformat()
                    },
                    "timestamp": int(datetime.now().timestamp() * 1000),
                    "source": "backend"
                })
                
            except json.JSONDecodeError:
                # Handle invalid JSON
                await websocket.send_json({
                    "id": f"error_{int(datetime.now().timestamp())}",
                    "type": "system.error",
                    "data": {
                        "error_id": f"json_error_{int(datetime.now().timestamp())}",
                        "message": "Invalid JSON message format",
                        "severity": "medium",
                        "timestamp": datetime.now(timezone.utc).isoformat()
                    },
                    "timestamp": int(datetime.now().timestamp() * 1000),
                    "source": "backend"
                })
            except Exception as e:
                logger.error(f"Error processing AG-UI message: {e}")
                await websocket.send_json({
                    "id": f"error_{int(datetime.now().timestamp())}",
                    "type": "system.error",
                    "data": {
                        "error_id": f"processing_error_{int(datetime.now().timestamp())}",
                        "message": f"Error processing message: {str(e)}",
                        "severity": "high",
                        "timestamp": datetime.now(timezone.utc).isoformat()
                    },
                    "timestamp": int(datetime.now().timestamp() * 1000),
                    "source": "backend"
                })
                
    except WebSocketDisconnect:
        logger.info("AG-UI client disconnected")
        websocket_manager.disconnect(websocket)
        
        # Cancel mock event generation
        if 'mock_task' in locals():
            mock_task.cancel()
        
        # Send disconnection event to other clients
        try:
            await websocket_manager.broadcast({
                "id": f"disconn_{int(datetime.now().timestamp())}",
                "type": "connection.lost",
                "data": {
                    "client_id": f"client_{id(websocket)}",
                    "reason": "Client disconnected",
                    "timestamp": datetime.now(timezone.utc).isoformat()
                },
                "timestamp": int(datetime.now().timestamp() * 1000),
                "source": "backend"
            }, "connection_update")
        except Exception as e:
            logger.error(f"Error broadcasting disconnection: {e}")
            
    except Exception as e:
        logger.error(f"AG-UI WebSocket error: {e}")
        websocket_manager.disconnect(websocket)
        
        # Cancel mock event generation
        if 'mock_task' in locals():
            mock_task.cancel()

@app.get("/api/v1/prices/aggregated")
async def get_aggregated_prices():
    """Get all current aggregated prices"""
    try:
        price_aggregator = registry.get_service("realtime_price_aggregator")
        if not price_aggregator:
            # Return mock aggregated prices
            return {
                "prices": {
                    "BTC/USD": {
                        "token_pair": "BTC/USD",
                        "best_bid": 44995.50,
                        "best_ask": 45005.50,
                        "mid_price": 45000.50,
                        "volume_weighted_price": 45001.25,
                        "total_volume": 1250000.0,
                        "total_liquidity": 5000000.0,
                        "price_sources": 3,
                        "last_update": datetime.now(timezone.utc).isoformat(),
                        "price_by_dex": {
                            "uniswap_v3": {
                                "price": 45000.25,
                                "volume_24h": 800000.0,
                                "liquidity": 2000000.0,
                                "timestamp": datetime.now(timezone.utc).isoformat()
                            },
                            "jupiter": {
                                "price": 45000.75,
                                "volume_24h": 300000.0,
                                "liquidity": 1500000.0,
                                "timestamp": datetime.now(timezone.utc).isoformat()
                            },
                            "hyperliquid_perp": {
                                "price": 45000.50,
                                "volume_24h": 150000.0,
                                "liquidity": 1500000.0,
                                "timestamp": datetime.now(timezone.utc).isoformat()
                            }
                        }
                    },
                    "ETH/USD": {
                        "token_pair": "ETH/USD",
                        "best_bid": 2499.50,
                        "best_ask": 2500.50,
                        "mid_price": 2500.00,
                        "volume_weighted_price": 2500.25,
                        "total_volume": 2500000.0,
                        "total_liquidity": 8000000.0,
                        "price_sources": 4,
                        "last_update": datetime.now(timezone.utc).isoformat(),
                        "price_by_dex": {
                            "uniswap_v3": {
                                "price": 2500.25,
                                "volume_24h": 1500000.0,
                                "liquidity": 3000000.0,
                                "timestamp": datetime.now(timezone.utc).isoformat()
                            },
                            "jupiter": {
                                "price": 2499.75,
                                "volume_24h": 600000.0,
                                "liquidity": 2000000.0,
                                "timestamp": datetime.now(timezone.utc).isoformat()
                            },
                            "hyperliquid_perp": {
                                "price": 2500.00,
                                "volume_24h": 400000.0,
                                "liquidity": 3000000.0,
                                "timestamp": datetime.now(timezone.utc).isoformat()
                            }
                        }
                    }
                }
            }
        
        prices = price_aggregator.get_all_prices()
        
        # Convert to JSON-serializable format
        result = {}
        for pair, aggregated in prices.items():
            if aggregated:
                result[pair] = {
                    "token_pair": aggregated.token_pair,
                    "best_bid": float(aggregated.best_bid),
                    "best_ask": float(aggregated.best_ask),
                    "mid_price": float(aggregated.mid_price),
                    "volume_weighted_price": float(aggregated.volume_weighted_price),
                    "total_volume": float(aggregated.total_volume),
                    "total_liquidity": float(aggregated.total_liquidity),
                    "price_sources": aggregated.price_sources,
                    "last_update": aggregated.last_update.isoformat(),
                    "price_by_dex": {
                        dex: {
                            "price": float(update.price),
                            "volume_24h": float(update.volume_24h),
                            "liquidity": float(update.liquidity),
                            "timestamp": update.timestamp.isoformat()
                        } for dex, update in aggregated.price_by_dex.items()
                    }
                }
        
        return {"prices": result}
        
    except Exception as e:
        logger.error(f"Error getting aggregated prices: {e}")
        return {"error": str(e)}

@app.get("/api/v1/prices/arbitrage")
async def get_arbitrage_opportunities():
    """Get current arbitrage opportunities"""
    try:
        price_aggregator = registry.get_service("realtime_price_aggregator")
        if not price_aggregator:
            # Return mock arbitrage opportunities
            return {
                "opportunities": [
                    {
                        "token_pair": "BTC/USD",
                        "buy_dex": "jupiter",
                        "buy_price": 44995.50,
                        "sell_dex": "hyperliquid_perp",
                        "sell_price": 45005.50,
                        "spread_pct": 0.022,
                        "potential_profit": 10.0,
                        "timestamp": datetime.now(timezone.utc).isoformat()
                    },
                    {
                        "token_pair": "ETH/USD",
                        "buy_dex": "uniswap_v3",
                        "buy_price": 2499.25,
                        "sell_dex": "jupiter",
                        "sell_price": 2500.75,
                        "spread_pct": 0.060,
                        "potential_profit": 1.50,
                        "timestamp": datetime.now(timezone.utc).isoformat()
                    }
                ],
                "count": 2
            }
        
        opportunities = await price_aggregator.get_arbitrage_opportunities(min_spread_pct=0.1)
        
        return {
            "opportunities": opportunities,
            "count": len(opportunities)
        }
        
    except Exception as e:
        logger.error(f"Error getting arbitrage opportunities: {e}")
        return {"error": str(e)}

@app.get("/api/v1/prices/performance")
async def get_price_aggregator_performance():
    """Get price aggregator performance metrics"""
    try:
        price_aggregator = registry.get_service("realtime_price_aggregator")
        if not price_aggregator:
            # Return mock performance metrics
            return {
                "performance": {
                    "avg_latency_ms": 25.5,
                    "p50_latency_ms": 22.0,
                    "p95_latency_ms": 35.0,
                    "p99_latency_ms": 42.0,
                    "total_updates": 15247,
                    "active_feeds": 3,
                    "tracked_pairs": 4
                },
                "status": "healthy"
            }
        
        metrics = price_aggregator.get_performance_metrics()
        
        return {
            "performance": metrics,
            "status": "healthy" if metrics.get("avg_latency_ms", 0) < 50 else "degraded"
        }
        
    except Exception as e:
        logger.error(f"Error getting performance metrics: {e}")
        return {"error": str(e)}

@app.get("/api/v1/prices/{token_pair}")
async def get_token_pair_price(token_pair: str):
    """Get current price for a specific token pair"""
    try:
        price_aggregator = registry.get_service("realtime_price_aggregator")
        if not price_aggregator:
            # Return mock price for specific pair
            if token_pair == "BTC/USD":
                return {
                    "token_pair": "BTC/USD",
                    "best_bid": 44995.50,
                    "best_ask": 45005.50,
                    "mid_price": 45000.50,
                    "volume_weighted_price": 45001.25,
                    "total_volume": 1250000.0,
                    "total_liquidity": 5000000.0,
                    "price_sources": 3,
                    "last_update": datetime.now(timezone.utc).isoformat(),
                    "price_by_dex": {
                        "uniswap_v3": {
                            "price": 45000.25,
                            "volume_24h": 800000.0,
                            "liquidity": 2000000.0,
                            "timestamp": datetime.now(timezone.utc).isoformat()
                        },
                        "jupiter": {
                            "price": 45000.75,
                            "volume_24h": 300000.0,
                            "liquidity": 1500000.0,
                            "timestamp": datetime.now(timezone.utc).isoformat()
                        },
                        "hyperliquid_perp": {
                            "price": 45000.50,
                            "volume_24h": 150000.0,
                            "liquidity": 1500000.0,
                            "timestamp": datetime.now(timezone.utc).isoformat()
                        }
                    }
                }
            else:
                return {"error": f"No price data available for {token_pair}"}
        
        aggregated = price_aggregator.get_price(token_pair)
        
        if not aggregated:
            return {"error": f"No price data available for {token_pair}"}
        
        return {
            "token_pair": aggregated.token_pair,
            "best_bid": float(aggregated.best_bid),
            "best_ask": float(aggregated.best_ask),
            "mid_price": float(aggregated.mid_price),
            "volume_weighted_price": float(aggregated.volume_weighted_price),
            "total_volume": float(aggregated.total_volume),
            "total_liquidity": float(aggregated.total_liquidity),
            "price_sources": aggregated.price_sources,
            "last_update": aggregated.last_update.isoformat(),
            "price_by_dex": {
                dex: {
                    "price": float(update.price),
                    "volume_24h": float(update.volume_24h),
                    "liquidity": float(update.liquidity),
                    "timestamp": update.timestamp.isoformat()
                } for dex, update in aggregated.price_by_dex.items()
            }
        }
        
    except Exception as e:
        logger.error(f"Error getting price for {token_pair}: {e}")
        return {"error": str(e)}

# ==========================================
# AUTONOMOUS AGENT FUNDING API ENDPOINTS
# ==========================================

@app.post("/api/v1/funding/request")
async def request_agent_funding(request_data: Dict[str, Any]):
    """Submit funding request from an agent"""
    try:
        funding_service = registry.get_service("autonomous_agent_funding")
        if not funding_service:
            # Return mock funding request response
            return {
                "request_id": f"req_{request_data.get('agent_id', 'mock')}_{int(datetime.now().timestamp())}",
                "status": "submitted",
                "agent_id": request_data.get("agent_id"),
                "requested_amount": request_data.get("amount", 10000),
                "urgency": request_data.get("urgency", "medium"),
                "estimated_processing_time": "5-15 minutes",
                "auto_approval_eligible": True,
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
        
        request_id = await funding_service.request_funding(
            agent_id=request_data["agent_id"],
            amount=Decimal(str(request_data["amount"])),
            reason=request_data.get("reason", "Funding request"),
            urgency=request_data.get("urgency", "medium"),
            strategy_type=request_data.get("strategy_type", "general"),
            expected_return=Decimal(str(request_data.get("expected_return", 0.05))),
            risk_level=Decimal(str(request_data.get("risk_level", 0.3)))
        )
        
        return {
            "request_id": request_id,
            "status": "submitted",
            "message": "Funding request submitted successfully"
        }
        
    except Exception as e:
        logger.error(f"Error submitting funding request: {e}")
        raise HTTPException(status_code=500, detail=f"Funding request error: {str(e)}")

@app.get("/api/v1/funding/status/{agent_id}")
async def get_agent_funding_status(agent_id: str):
    """Get funding status for a specific agent"""
    try:
        funding_service = registry.get_service("autonomous_agent_funding")
        if not funding_service:
            # Return mock funding status
            return {
                "agent_id": agent_id,
                "total_allocated": 75000.00,
                "available_balance": 42500.00,
                "deployed_capital": 28000.00,
                "reserved_funds": 4500.00,
                "pnl_unrealized": 5200.00,
                "pnl_realized": 12800.00,
                "utilization_rate": 0.78,
                "last_funding": (datetime.now(timezone.utc) - timedelta(hours=8)).isoformat(),
                "pending_requests": 1,
                "funding_approved_today": True,
                "next_review": (datetime.now(timezone.utc) + timedelta(hours=4)).isoformat()
            }
        
        status = await funding_service.get_agent_capital_status(agent_id)
        
        return {
            "agent_id": status.agent_id,
            "total_allocated": float(status.total_allocated),
            "available_balance": float(status.available_balance),
            "deployed_capital": float(status.deployed_capital),
            "reserved_funds": float(status.reserved_funds),
            "pnl_unrealized": float(status.pnl_unrealized),
            "pnl_realized": float(status.pnl_realized),
            "utilization_rate": float(status.utilization_rate),
            "last_funding": status.last_funding.isoformat() if status.last_funding else None,
            "pending_requests": len(status.funding_requests)
        }
        
    except Exception as e:
        logger.error(f"Error getting funding status: {e}")
        raise HTTPException(status_code=500, detail=f"Funding status error: {str(e)}")

@app.get("/api/v1/funding/analytics")
async def get_funding_analytics():
    """Get comprehensive funding analytics"""
    try:
        funding_service = registry.get_service("autonomous_agent_funding")
        if not funding_service:
            # Return mock analytics
            return {
                "total_funds_allocated": 485000.00,
                "successful_allocations": 127,
                "failed_allocations": 23,
                "success_rate": 0.847,
                "active_requests": 8,
                "funding_history_count": 150,
                "strategy_breakdown": {
                    "performance_based": {
                        "count": 85,
                        "total_amount": 325000.00
                    },
                    "opportunity_weighted": {
                        "count": 32,
                        "total_amount": 120000.00
                    },
                    "risk_adjusted": {
                        "count": 10,
                        "total_amount": 40000.00
                    }
                },
                "avg_allocation_size": 3819.69,
                "last_allocation": (datetime.now(timezone.utc) - timedelta(minutes=45)).isoformat(),
                "top_performers": [
                    {"agent_id": "marcus_momentum", "total_allocated": 125000.00, "success_rate": 0.89},
                    {"agent_id": "alex_arbitrage", "total_allocated": 110000.00, "success_rate": 0.84},
                    {"agent_id": "sophia_reversion", "total_allocated": 95000.00, "success_rate": 0.76}
                ]
            }
        
        analytics = await funding_service.get_funding_analytics()
        return analytics
        
    except Exception as e:
        logger.error(f"Error getting funding analytics: {e}")
        raise HTTPException(status_code=500, detail=f"Analytics error: {str(e)}")

@app.post("/api/v1/funding/emergency-stop")
async def emergency_stop_funding(reason: str = "Manual emergency stop"):
    """Emergency stop all funding operations"""
    try:
        funding_service = registry.get_service("autonomous_agent_funding")
        if not funding_service:
            return {
                "status": "emergency_stop",
                "reason": reason,
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "funds_protected": 485000.00,
                "message": "Emergency stop activated (mock mode)"
            }
        
        result = await funding_service.emergency_stop_funding(reason)
        return result
        
    except Exception as e:
        logger.error(f"Error in emergency stop: {e}")
        raise HTTPException(status_code=500, detail=f"Emergency stop error: {str(e)}")

@app.post("/api/v1/funding/review")
async def trigger_funding_review():
    """Manually trigger periodic funding review"""
    try:
        funding_service = registry.get_service("autonomous_agent_funding")
        if not funding_service:
            return {
                "status": "review_completed",
                "requests_processed": 8,
                "allocations_made": 3,
                "rebalances_executed": 2,
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "message": "Funding review completed (mock mode)"
            }
        
        await funding_service.process_periodic_funding_review()
        
        return {
            "status": "review_triggered",
            "message": "Periodic funding review triggered successfully",
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"Error triggering funding review: {e}")
        raise HTTPException(status_code=500, detail=f"Review trigger error: {str(e)}")

@app.get("/api/v1/funding/opportunities")
async def get_funding_opportunities():
    """Get current funding opportunities based on market conditions"""
    try:
        funding_service = registry.get_service("autonomous_agent_funding")
        price_aggregator = registry.get_service("realtime_price_aggregator")
        
        # Mock response if services not available
        if not funding_service or not price_aggregator:
            return {
                "opportunities": [
                    {
                        "agent_id": "marcus_momentum",
                        "strategy": "BTC momentum",
                        "potential_return": 0.08,
                        "risk_level": 0.4,
                        "suggested_allocation": 25000.00,
                        "confidence": 0.85,
                        "market_conditions": "favorable",
                        "timeframe": "24-48 hours"
                    },
                    {
                        "agent_id": "alex_arbitrage",
                        "strategy": "Cross-DEX arbitrage",
                        "potential_return": 0.05,
                        "risk_level": 0.2,
                        "suggested_allocation": 15000.00,
                        "confidence": 0.92,
                        "market_conditions": "optimal",
                        "timeframe": "1-4 hours"
                    }
                ],
                "total_opportunity_value": 40000.00,
                "market_sentiment": "bullish",
                "volatility_index": 0.35,
                "recommended_action": "moderate_increase"
            }
        
        # Get market opportunities
        arbitrage_opps = await price_aggregator.get_arbitrage_opportunities(min_spread_pct=0.1)
        
        opportunities = []
        for opp in arbitrage_opps[:3]:  # Top 3 opportunities
            opportunities.append({
                "agent_id": "alex_arbitrage",  # Arbitrage specialist
                "strategy": f"{opp['token_pair']} arbitrage",
                "potential_return": opp["spread_pct"] / 100,
                "risk_level": 0.3,  # Arbitrage typically low risk
                "suggested_allocation": min(opp["potential_profit"] * 1000, 50000),  # Scale up
                "confidence": 0.8,
                "market_conditions": "arbitrage_available",
                "timeframe": "minutes to hours"
            })
        
        return {
            "opportunities": opportunities,
            "total_opportunity_value": sum(o["suggested_allocation"] for o in opportunities),
            "market_sentiment": "neutral",
            "volatility_index": 0.4,
            "recommended_action": "selective_increase" if len(opportunities) > 0 else "hold"
        }
        
    except Exception as e:
        logger.error(f"Error getting funding opportunities: {e}")
        raise HTTPException(status_code=500, detail=f"Opportunities error: {str(e)}")

# ==========================================
# CROSS-DEX ARBITRAGE ENGINE API ENDPOINTS
# ==========================================

@app.get("/api/v1/arbitrage/opportunities")
async def get_arbitrage_opportunities():
    """Get all active arbitrage opportunities"""
    try:
        arbitrage_engine = registry.get_service("cross_dex_arbitrage_engine")
        if not arbitrage_engine:
            # Return mock arbitrage opportunities
            return {
                "opportunities": [
                    {
                        "opportunity_id": "simple_BTC/USD_jupiter_hyperliquid_perp_1703958245123",
                        "arbitrage_type": "simple_arbitrage",
                        "token_pair": "BTC/USD",
                        "spread_percentage": 0.25,
                        "net_profit": 125.50,
                        "confidence_score": 0.85,
                        "execution_time_estimate": 15.0,
                        "detected_at": (datetime.now(timezone.utc) - timedelta(minutes=2)).isoformat(),
                        "valid_until": (datetime.now(timezone.utc) + timedelta(minutes=3)).isoformat(),
                        "status": "validated"
                    },
                    {
                        "opportunity_id": "triangular_ETH/USD_BTC/ETH_BTC/USD_1703958267845",
                        "arbitrage_type": "triangular_arbitrage",
                        "token_pair": "ETH/USD-BTC/ETH-BTC/USD",
                        "spread_percentage": 0.18,
                        "net_profit": 89.75,
                        "confidence_score": 0.72,
                        "execution_time_estimate": 45.0,
                        "detected_at": (datetime.now(timezone.utc) - timedelta(minutes=1)).isoformat(),
                        "valid_until": (datetime.now(timezone.utc) + timedelta(minutes=2)).isoformat(),
                        "status": "detected"
                    },
                    {
                        "opportunity_id": "cross_chain_SOL/USD_ethereum_solana_1703958289456",
                        "arbitrage_type": "cross_chain_arbitrage",
                        "token_pair": "SOL/USD",
                        "spread_percentage": 0.42,
                        "net_profit": 195.25,
                        "confidence_score": 0.68,
                        "execution_time_estimate": 630.0,
                        "detected_at": (datetime.now(timezone.utc) - timedelta(seconds=30)).isoformat(),
                        "valid_until": (datetime.now(timezone.utc) + timedelta(minutes=14)).isoformat(),
                        "status": "validated"
                    }
                ],
                "total_opportunities": 3,
                "total_potential_profit": 410.50,
                "avg_confidence_score": 0.75,
                "scan_timestamp": datetime.now(timezone.utc).isoformat()
            }
        
        opportunities = await arbitrage_engine.get_active_opportunities()
        
        return {
            "opportunities": opportunities,
            "total_opportunities": len(opportunities),
            "total_potential_profit": sum(opp["net_profit"] for opp in opportunities),
            "avg_confidence_score": sum(opp["confidence_score"] for opp in opportunities) / max(len(opportunities), 1),
            "scan_timestamp": datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"Error getting arbitrage opportunities: {e}")
        raise HTTPException(status_code=500, detail=f"Arbitrage opportunities error: {str(e)}")

@app.get("/api/v1/arbitrage/performance")
async def get_arbitrage_performance():
    """Get arbitrage engine performance metrics"""
    try:
        arbitrage_engine = registry.get_service("cross_dex_arbitrage_engine")
        if not arbitrage_engine:
            # Return mock performance metrics
            return {
                "opportunities_detected": 1247,
                "opportunities_executed": 892,
                "total_profit": 38425.75,
                "success_rate": 0.715,
                "avg_execution_time": 18.5,
                "scan_performance": {
                    "avg_latency_ms": 45.2,
                    "p95_latency_ms": 78.5,
                    "scans_under_100ms": 15847,
                    "total_scans": 16234
                },
                "active_opportunities": 8,
                "market_conditions": {
                    "gas_price_gwei": 28.5,
                    "network_congestion": 0.45,
                    "optimal_threshold": 0.2
                },
                "execution_stats": {
                    "simple_arbitrage": {"count": 654, "success_rate": 0.82, "avg_profit": 45.25},
                    "triangular_arbitrage": {"count": 156, "success_rate": 0.68, "avg_profit": 78.50},
                    "cross_chain_arbitrage": {"count": 82, "success_rate": 0.55, "avg_profit": 145.75}
                }
            }
        
        metrics = await arbitrage_engine.get_performance_metrics()
        return metrics
        
    except Exception as e:
        logger.error(f"Error getting arbitrage performance: {e}")
        raise HTTPException(status_code=500, detail=f"Performance metrics error: {str(e)}")

@app.post("/api/v1/arbitrage/start")
async def start_arbitrage_scanning():
    """Start continuous arbitrage scanning"""
    try:
        arbitrage_engine = registry.get_service("cross_dex_arbitrage_engine")
        if not arbitrage_engine:
            return {
                "status": "started",
                "message": "Arbitrage scanning started (mock mode)",
                "scan_frequency": "50ms",
                "supported_types": ["simple", "triangular", "cross_chain"],
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
        
        # Start arbitrage scanning in background
        asyncio.create_task(arbitrage_engine.start_continuous_scanning())
        
        return {
            "status": "started",
            "message": "Arbitrage scanning started successfully",
            "scan_frequency": "50ms", 
            "supported_types": ["simple", "triangular", "cross_chain"],
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"Error starting arbitrage scanning: {e}")
        raise HTTPException(status_code=500, detail=f"Start scanning error: {str(e)}")

@app.get("/api/v1/arbitrage/execution-history")
async def get_arbitrage_execution_history(limit: int = 50):
    """Get recent arbitrage execution history"""
    try:
        arbitrage_engine = registry.get_service("cross_dex_arbitrage_engine")
        if not arbitrage_engine:
            # Return mock execution history
            mock_history = []
            for i in range(min(limit, 20)):
                mock_history.append({
                    "execution_id": f"exec_simple_BTC/USD_jupiter_hyperliquid_{1703958000 + i * 300}",
                    "opportunity_id": f"simple_BTC/USD_jupiter_hyperliquid_{1703958000 + i * 300}",
                    "agent_id": "arbitrage_agent",
                    "start_time": (datetime.now(timezone.utc) - timedelta(hours=i*2)).isoformat(),
                    "end_time": (datetime.now(timezone.utc) - timedelta(hours=i*2) + timedelta(seconds=15)).isoformat(),
                    "status": "completed" if i % 4 != 0 else "failed",
                    "actual_profit": 85.25 + (i * 10.5) if i % 4 != 0 else 0,
                    "gas_cost": 12.50,
                    "slippage": 0.002,
                    "execution_time_seconds": 15.2 + (i * 0.5)
                })
            
            return {
                "executions": mock_history,
                "total_executions": len(mock_history),
                "successful_executions": len([e for e in mock_history if e["status"] == "completed"]),
                "total_profit": sum(e["actual_profit"] for e in mock_history),
                "avg_execution_time": sum(e["execution_time_seconds"] for e in mock_history) / len(mock_history)
            }
        
        # Get recent executions from arbitrage engine
        history = arbitrage_engine.execution_history[-limit:]
        
        executions = []
        for execution in history:
            executions.append({
                "execution_id": execution.execution_id,
                "opportunity_id": execution.opportunity_id,
                "agent_id": execution.agent_id,
                "start_time": execution.start_time.isoformat(),
                "end_time": execution.end_time.isoformat() if execution.end_time else None,
                "status": execution.status,
                "actual_profit": float(execution.actual_profit) if execution.actual_profit else 0,
                "gas_cost": float(execution.gas_cost) if execution.gas_cost else 0,
                "slippage": float(execution.slippage) if execution.slippage else 0,
                "execution_time_seconds": (execution.end_time - execution.start_time).total_seconds() if execution.end_time else 0
            })
        
        successful_executions = [e for e in executions if e["status"] == "completed"]
        
        return {
            "executions": executions,
            "total_executions": len(executions),
            "successful_executions": len(successful_executions),
            "total_profit": sum(e["actual_profit"] for e in successful_executions),
            "avg_execution_time": sum(e["execution_time_seconds"] for e in successful_executions) / max(len(successful_executions), 1)
        }
        
    except Exception as e:
        logger.error(f"Error getting execution history: {e}")
        raise HTTPException(status_code=500, detail=f"Execution history error: {str(e)}")

@app.post("/api/v1/arbitrage/execute/{opportunity_id}")
async def execute_arbitrage_opportunity(opportunity_id: str):
    """Manually trigger execution of a specific arbitrage opportunity"""
    try:
        arbitrage_engine = registry.get_service("cross_dex_arbitrage_engine")
        if not arbitrage_engine:
            return {
                "execution_id": f"exec_{opportunity_id}_{int(datetime.now().timestamp())}",
                "status": "triggered",
                "opportunity_id": opportunity_id,
                "estimated_completion": (datetime.now(timezone.utc) + timedelta(seconds=30)).isoformat(),
                "message": "Arbitrage execution triggered (mock mode)",
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
        
        # Find the opportunity
        opportunity = arbitrage_engine.opportunities.get(opportunity_id)
        if not opportunity:
            raise HTTPException(status_code=404, detail="Opportunity not found")
        
        # Trigger execution
        await arbitrage_engine._execute_arbitrage(opportunity)
        
        return {
            "execution_id": f"exec_{opportunity_id}_{int(datetime.now().timestamp())}",
            "status": "triggered",
            "opportunity_id": opportunity_id,
            "estimated_completion": (datetime.now(timezone.utc) + timedelta(seconds=int(opportunity.execution_time_estimate.total_seconds()))).isoformat(),
            "message": "Arbitrage execution triggered successfully",
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"Error executing arbitrage opportunity: {e}")
        raise HTTPException(status_code=500, detail=f"Execution error: {str(e)}")

# Main entry point
if __name__ == "__main__":
    print("""
    â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— 
    â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—    â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â• 
    â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•       â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•—
    â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â•â•        â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘
    â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘            â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
    â•šâ•â•     â•šâ•â• â•šâ•â•â•â•â•â•â•šâ•â•            â•šâ•â•   â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â• â•šâ•â•â•šâ•â•  â•šâ•â•â•â• â•šâ•â•â•â•â•â• 
                                                                                            
                    ðŸš€ CONSOLIDATED MONOREPO v2.0.0 - AGENT TRADING READY ðŸš€
    """)
    
    logger.info(f"Starting MCP Trading Platform on port {API_PORT}")
    logger.info(f"Environment: {ENVIRONMENT}")
    logger.info(f"Debug mode: {DEBUG}")
    
    uvicorn.run(
        "main_consolidated:app",
        host="0.0.0.0",
        port=API_PORT,
        reload=DEBUG,
        log_level="info" if not DEBUG else "debug",
        access_log=DEBUG
    )